Chave,Tipo de Item,Ano de Publicação,Autor,Título,DOI,Url,Nota Abstracta,Data,Editor,Título_traduzido,Nota Resumo_traduzido
SBDIBIM8,preprint,2021.0,"Northcutt, Curtis G.; Athalye, Anish; Mueller, Jonas",Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks,,http://arxiv.org/abs/2103.14749,"We identify label errors in the test sets of 10 of the most commonly-used computer vision, natural language, and audio datasets, and subsequently study the potential for these label errors to affect benchmark results. Errors in test sets are numerous and widespread: we estimate an average of at least 3.3% errors across the 10 datasets, where for example label errors comprise at least 6% of the ImageNet validation set. Putative label errors are identified using confident learning algorithms and then human-validated via crowdsourcing (51% of the algorithmically-flagged candidates are indeed erroneously labeled, on average across the datasets). Traditionally, machine learning practitioners choose which model to deploy based on test accuracy - our findings advise caution here, proposing that judging models over correctly labeled test sets may be more useful, especially for noisy real-world datasets. Surprisingly, we find that lower capacity models may be practically more useful than higher capacity models in real-world datasets with high proportions of erroneously labeled data. For example, on ImageNet with corrected labels: ResNet-18 outperforms ResNet-50 if the prevalence of originally mislabeled test examples increases by just 6%. On CIFAR-10 with corrected labels: VGG-11 outperforms VGG-19 if the prevalence of originally mislabeled test examples increases by just 5%. Test set errors across the 10 datasets can be viewed at https://labelerrors.com and all label errors can be reproduced by https://github.com/cleanlab/label-errors.",2021-11-07,arXiv,Erros de Rótulo Pervasivos em Conjuntos de Teste Desestabilizam Referências de Aprendizado de Máquina,"Identificamos erros de rotulagem nos conjuntos de teste de 10 dos conjuntos de dados de visão computacional, linguagem natural e áudio mais comumente usados e, em seguida, estudamos o potencial desses erros de rotulagem para afetar os resultados de referência. Os erros em conjuntos de teste são numerosos e generalizados: estimamos uma média de pelo menos 3,3% de erros nos 10 conjuntos de dados, onde, por exemplo, os erros de rotulagem representam pelo menos 6% do conjunto de validação do ImageNet. Erros de rotulagem putativos são identificados usando algoritmos de aprendizado confiante e, em seguida, validados por humanos via crowdsourcing (51% dos candidatos sinalizados algoritmicamente estão, de fato, rotulados erroneamente, em média, entre os conjuntos de dados). Tradicionalmente, os praticantes de aprendizado de máquina escolhem qual modelo implantar com base na precisão do teste - nossas descobertas aconselham cautela aqui, propondo que julgar modelos sobre conjuntos de teste corretamente rotulados pode ser mais útil, especialmente para conjuntos de dados do mundo real ruidosos. Surpreendentemente, descobrimos que modelos de menor capacidade podem ser praticamente mais úteis do que modelos de maior capacidade em conjuntos de dados do mundo real com altas proporções de dados rotulados erroneamente. Por exemplo, no ImageNet com rótulos corrigidos: ResNet-18 supera ResNet-50 se a prevalência de exemplos de teste originalmente rotulados incorretamente aumentar em apenas 6%. No CIFAR-10 com rótulos corrigidos: VGG-11 supera VGG-19 se a prevalência de exemplos de teste originalmente rotulados incorretamente aumentar em apenas 5%. Os erros do conjunto de teste nos 10 conjuntos de dados podem ser visualizados em https://labelerrors.com e todos os erros de rotulagem podem ser reproduzidos em https://github.com/cleanlab/label-errors."
Z5ZULGPQ,journalArticle,2018.0,"Zhou, Zhi-Hua",A brief introduction to weakly supervised learning,10.1093/nsr/nwx106,https://academic.oup.com/nsr/article/5/1/44/4093912,"Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.",2018-01-01,,Uma breve introdução ao aprendizado fraco supervisionado,"Técnicas de aprendizado supervisionado constroem modelos preditivos aprendendo a partir de um grande número de exemplos de treinamento, onde cada exemplo de treinamento possui um rótulo que indica sua saída verdadeira. Embora as técnicas atuais tenham alcançado grande sucesso, é notável que em muitas tarefas é difícil obter informações de supervisão forte, como rótulos totalmente verdadeiros, devido ao alto custo do processo de rotulagem de dados. Assim, é desejável que as técnicas de aprendizado de máquina funcionem com supervisão fraca. Este artigo revisa alguns avanços de pesquisa em aprendizado fraco supervisionado, focando em três tipos típicos de supervisão fraca: supervisão incompleta, onde apenas um subconjunto dos dados de treinamento é fornecido com rótulos; supervisão imprecisa, onde os dados de treinamento são fornecidos apenas com rótulos de granulação grosseira; e supervisão ineficaz, onde os rótulos fornecidos nem sempre são verdadeiros."
RVFTYNRU,preprint,2022.0,"Zhang, Rongzhi; Yu, Yue; Shetty, Pranav; Song, Le; Zhang, Chao",PRBoost: Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning,,http://arxiv.org/abs/2203.09735,"Weakly-supervised learning (WSL) has shown promising results in addressing label scarcity on many NLP tasks, but manually designing a comprehensive, high-quality labeling rule set is tedious and difficult. We study interactive weakly-supervised learning -- the problem of iteratively and automatically discovering novel labeling rules from data to improve the WSL model. Our proposed model, named PRBoost, achieves this goal via iterative prompt-based rule discovery and model boosting. It uses boosting to identify large-error instances and then discovers candidate rules from them by prompting pre-trained LMs with rule templates. The candidate rules are judged by human experts, and the accepted rules are used to generate complementary weak labels and strengthen the current model. Experiments on four tasks show PRBoost outperforms state-of-the-art WSL baselines up to 7.1% and bridges the gaps with fully supervised models. Our Implementation is available at \url{https://github.com/rz-zhang/PRBoost}.",2022-03-18,arXiv,PRBoost: Descoberta de Regras Baseada em Prompt e Aumento para Aprendizado Interativo Fracamente Supervisionado,"O aprendizado fraco supervisionado (WSL) mostrou resultados promissores na abordagem da escassez de rótulos em muitas tarefas de PNL, mas projetar manualmente um conjunto abrangente e de alta qualidade de regras de rotulagem é tedioso e difícil. Estudamos o aprendizado fraco supervisionado interativo -- o problema de descobrir iterativamente e automaticamente novas regras de rotulagem a partir de dados para melhorar o modelo WSL. Nosso modelo proposto, chamado PRBoost, alcança esse objetivo por meio da descoberta iterativa de regras baseadas em prompts e do reforço do modelo. Ele utiliza o reforço para identificar instâncias com grandes erros e, em seguida, descobre regras candidatas a partir delas, solicitando modelos de linguagem pré-treinados com templates de regras. As regras candidatas são avaliadas por especialistas humanos, e as regras aceitas são usadas para gerar rótulos fracos complementares e fortalecer o modelo atual. Experimentos em quatro tarefas mostram que o PRBoost supera as linhas de base WSL de última geração em até 7,1% e fecha as lacunas com modelos totalmente supervisionados. Nossa implementação está disponível em \url{https://github.com/rz-zhang/PRBoost}."
RHDZNG78,preprint,2019.0,"Varma, Paroma; Sala, Frederic; He, Ann; Ratner, Alexander; Ré, Christopher",Learning Dependency Structures for Weak Supervision Models,,http://arxiv.org/abs/1903.05844,"Labeling training data is a key bottleneck in the modern machine learning pipeline. Recent weak supervision approaches combine labels from multiple noisy sources by estimating their accuracies without access to ground truth labels; however, estimating the dependencies among these sources is a critical challenge. We focus on a robust PCA-based algorithm for learning these dependency structures, establish improved theoretical recovery rates, and outperform existing methods on various real-world tasks. Under certain conditions, we show that the amount of unlabeled data needed can scale sublinearly or even logarithmically with the number of sources $m$, improving over previous efforts that ignore the sparsity pattern in the dependency structure and scale linearly in $m$. We provide an information-theoretic lower bound on the minimum sample complexity of the weak supervision setting. Our method outperforms weak supervision approaches that assume conditionally-independent sources by up to 4.64 F1 points and previous structure learning approaches by up to 4.41 F1 points on real-world relation extraction and image classification tasks.",2019-03-14,arXiv,Aprendendo Estruturas de Dependência para Modelos de Supervisão Fraca,"Rotular dados de treinamento é um gargalo chave no pipeline moderno de aprendizado de máquina. Abordagens recentes de supervisão fraca combinam rótulos de múltiplas fontes ruidosas estimando suas precisões sem acesso a rótulos de verdadeiros; no entanto, estimar as dependências entre essas fontes é um desafio crítico. Focamos em um algoritmo robusto baseado em PCA para aprender essas estruturas de dependência, estabelecemos taxas de recuperação teórica melhoradas e superamos métodos existentes em várias tarefas do mundo real. Sob certas condições, mostramos que a quantidade de dados não rotulados necessária pode escalar de forma sublinear ou até logarítmica com o número de fontes $m$, melhorando em relação a esforços anteriores que ignoram o padrão de esparsidade na estrutura de dependência e escalam linearmente em $m$. Fornecemos um limite inferior teórico de informação sobre a complexidade mínima de amostra do cenário de supervisão fraca. Nosso método supera abordagens de supervisão fraca que assumem fontes condicionalmente independentes em até 4,64 pontos F1 e abordagens anteriores de aprendizado de estrutura em até 4,41 pontos F1 em tarefas de extração de relações e classificação de imagens do mundo real."
VXNEW7WV,preprint,2022.0,"Hsieh, Cheng-Yu; Zhang, Jieyu; Ratner, Alexander",Nemo: Guiding and Contextualizing Weak Supervision for Interactive Data Programming,,http://arxiv.org/abs/2203.01382,"Weak Supervision (WS) techniques allow users to efficiently create large training datasets by programmatically labeling data with heuristic sources of supervision. While the success of WS relies heavily on the provided labeling heuristics, the process of how these heuristics are created in practice has remained under-explored. In this work, we formalize the development process of labeling heuristics as an interactive procedure, built around the existing workflow where users draw ideas from a selected set of development data for designing the heuristic sources. With the formalism, we study two core problems of how to strategically select the development data to guide users in efficiently creating informative heuristics, and how to exploit the information within the development process to contextualize and better learn from the resultant heuristics. Building upon two novel methodologies that effectively tackle the respective problems considered, we present Nemo, an end-to-end interactive system that improves the overall productivity of WS learning pipeline by an average 20% (and up to 47% in one task) compared to the prevailing WS approach.",2022-10-23,arXiv,Nemo: Orientando e Contextualizando Supervisão Fraca para Programação de Dados Interativa,"Técnicas de Supervisão Fraca (WS) permitem que os usuários criem de forma eficiente grandes conjuntos de dados de treinamento, rotulando programaticamente os dados com fontes heurísticas de supervisão. Embora o sucesso da WS dependa fortemente das heurísticas de rotulagem fornecidas, o processo de como essas heurísticas são criadas na prática permanece pouco explorado. Neste trabalho, formalizamos o processo de desenvolvimento de heurísticas de rotulagem como um procedimento interativo, construído em torno do fluxo de trabalho existente, onde os usuários extraem ideias de um conjunto selecionado de dados de desenvolvimento para projetar as fontes heurísticas. Com o formalismo, estudamos dois problemas centrais de como selecionar estrategicamente os dados de desenvolvimento para orientar os usuários na criação eficiente de heurísticas informativas e como explorar as informações dentro do processo de desenvolvimento para contextualizar e aprender melhor com as heurísticas resultantes. Baseando-se em duas metodologias inovadoras que abordam efetivamente os problemas considerados, apresentamos o Nemo, um sistema interativo de ponta a ponta que melhora a produtividade geral do pipeline de aprendizado WS em uma média de 20% (e até 47% em uma tarefa) em comparação com a abordagem WS predominante."
R4ZYBDQP,preprint,2021.0,"Zhang, Jieyu; Yu, Yue; Li, Yinghao; Wang, Yujing; Yang, Yaming; Yang, Mao; Ratner, Alexander",WRENCH: A Comprehensive Benchmark for Weak Supervision,,http://arxiv.org/abs/2109.11377,"Recent Weak Supervision (WS) approaches have had widespread success in easing the bottleneck of labeling training data for machine learning by synthesizing labels from multiple potentially noisy supervision sources. However, proper measurement and analysis of these approaches remain a challenge. First, datasets used in existing works are often private and/or custom, limiting standardization. Second, WS datasets with the same name and base data often vary in terms of the labels and weak supervision sources used, a significant ""hidden"" source of evaluation variance. Finally, WS studies often diverge in terms of the evaluation protocol and ablations used. To address these problems, we introduce a benchmark platform, WRENCH, for thorough and standardized evaluation of WS approaches. It consists of 22 varied real-world datasets for classification and sequence tagging; a range of real, synthetic, and procedurally-generated weak supervision sources; and a modular, extensible framework for WS evaluation, including implementations for popular WS methods. We use WRENCH to conduct extensive comparisons over more than 120 method variants to demonstrate its efficacy as a benchmark platform. The code is available at https://github.com/JieyuZ2/wrench.",2021-10-11,arXiv,WRENCH: Um Benchmark Abrangente para Supervisão Fraca,"Abordagens recentes de Supervisão Fraca (WS) tiveram um sucesso generalizado em aliviar o gargalo da rotulagem de dados de treinamento para aprendizado de máquina, sintetizando rótulos a partir de várias fontes de supervisão potencialmente ruidosas. No entanto, a medição e análise adequadas dessas abordagens continuam sendo um desafio. Primeiro, os conjuntos de dados utilizados em trabalhos existentes são frequentemente privados e/ou personalizados, limitando a padronização. Em segundo lugar, conjuntos de dados WS com o mesmo nome e dados base muitas vezes variam em termos dos rótulos e fontes de supervisão fraca utilizadas, uma fonte significativa de variação de avaliação ""oculta"". Por fim, estudos de WS frequentemente divergem em termos do protocolo de avaliação e das ablações utilizadas. Para abordar esses problemas, introduzimos uma plataforma de benchmark, WRENCH, para avaliação minuciosa e padronizada de abordagens WS. Ela consiste em 22 conjuntos de dados do mundo real variados para classificação e marcação de sequência; uma gama de fontes de supervisão fraca reais, sintéticas e geradas proceduralmente; e uma estrutura modular e extensível para avaliação WS, incluindo implementações para métodos WS populares. Usamos o WRENCH para realizar comparações extensivas em mais de 120 variantes de métodos para demonstrar sua eficácia como uma plataforma de benchmark. O código está disponível em https://github.com/JieyuZ2/wrench."
2NUITXIK,journalArticle,2019.0,"Li, Yu-Feng; Guo, Lan-Zhe; Zhou, Zhi-Hua",Towards Safe Weakly Supervised Learning,10.1109/TPAMI.2019.2922396,https://ieeexplore.ieee.org/document/8735810/,,2019,,Rumo ao Aprendizado Fraco Supervisionado Seguro,nan
TA8H6Q56,preprint,2022.0,"Zhang, Jieyu; Hsieh, Cheng-Yu; Yu, Yue; Zhang, Chao; Ratner, Alexander",A Survey on Programmatic Weak Supervision,,http://arxiv.org/abs/2202.05433,"Labeling training data has become one of the major roadblocks to using machine learning. Among various weak supervision paradigms, programmatic weak supervision (PWS) has achieved remarkable success in easing the manual labeling bottleneck by programmatically synthesizing training labels from multiple potentially noisy supervision sources. This paper presents a comprehensive survey of recent advances in PWS. In particular, we give a brief introduction of the PWS learning paradigm, and review representative approaches for each component within PWS's learning workflow. In addition, we discuss complementary learning paradigms for tackling limited labeled data scenarios and how these related approaches can be used in conjunction with PWS. Finally, we identify several critical challenges that remain under-explored in the area to hopefully inspire future research directions in the field.",2022-02-14,arXiv,Uma Pesquisa sobre Supervisão Fraca Programática,"A rotulagem de dados de treinamento tornou-se um dos principais obstáculos ao uso de aprendizado de máquina. Entre os vários paradigmas de supervisão fraca, a supervisão fraca programática (PWS) alcançou um sucesso notável em aliviar o gargalo da rotulagem manual, sintetizando programaticamente rótulos de treinamento a partir de várias fontes de supervisão potencialmente ruidosas. Este artigo apresenta uma pesquisa abrangente dos avanços recentes em PWS. Em particular, fazemos uma breve introdução ao paradigma de aprendizado PWS e revisamos abordagens representativas para cada componente dentro do fluxo de trabalho de aprendizado da PWS. Além disso, discutimos paradigmas de aprendizado complementares para enfrentar cenários de dados rotulados limitados e como essas abordagens relacionadas podem ser usadas em conjunto com a PWS. Finalmente, identificamos vários desafios críticos que permanecem pouco explorados na área, na esperança de inspirar futuras direções de pesquisa no campo."
2A54V3FF,conferencePaper,2021.0,"Nodet, Pierre; Lemaire, Vincent; Bondu, Alexis; Cornuejols, Antoine; Ouorou, Adam",From Weakly Supervised Learning to Biquality Learning: an Introduction,10.1109/IJCNN52387.2021.9533353,https://ieeexplore.ieee.org/document/9533353/,,2021-07-18,IEEE,De Aprendizado Supervisionado Fraco a Aprendizado Biqualificado: uma Introdução,nan
Z6ZN7CNB,conferencePaper,2009.0,"Mintz, Mike; Bills, Steven; Snow, Rion; Jurafsky, Daniel",Distant supervision for relation extraction without labeled data,,https://aclanthology.org/P09-1113,,2009-08,Association for Computational Linguistics,Supervisão distante para extração de relações sem dados rotulados,nan
CH6BF2S8,conferencePaper,2013.0,"Roth, Benjamin; Barth, Tassilo; Wiegand, Michael; Klakow, Dietrich",A survey of noise reduction methods for distant supervision,10.1145/2509558.2509571,http://dl.acm.org/citation.cfm?doid=2509558.2509571,"We survey recent approaches to noise reduction in distant supervision learning for relation extraction. We group them according to the principles they are based on: at-least-one constraints, topic-based models, or pattern correlations. Besides describing them, we illustrate the fundamental diﬀerences and attempt to give an outlook to potentially fruitful further research. In addition, we identify related work in sentiment analysis which could proﬁt from approaches to noise reduction.",2013,ACM Press,Uma pesquisa sobre métodos de redução de ruído para supervisão distante,"Nós examinamos abordagens recentes para a redução de ruído no aprendizado de supervisão distante para extração de relações. Agrupamos essas abordagens de acordo com os princípios em que se baseiam: restrições de pelo menos um, modelos baseados em tópicos ou correlações de padrões. Além de descrevê-las, ilustramos as diferenças fundamentais e tentamos oferecer uma perspectiva para uma pesquisa futura potencialmente frutífera. Além disso, identificamos trabalhos relacionados em análise de sentimentos que poderiam se beneficiar de abordagens para redução de ruído."
KUE85DEC,journalArticle,2019.0,"Smirnova, Alisa; Cudré-Mauroux, Philippe",Relation Extraction Using Distant Supervision: A Survey,10.1145/3241741,https://dl.acm.org/doi/10.1145/3241741,"Relation extraction is a subtask of information extraction where               semantic relationships               are extracted from natural language text and then classified. In essence, it allows us to acquire structured knowledge from unstructured text. In this article, we present a survey of relation extraction methods that leverage pre-existing structured or semi-structured data to guide the extraction process. We introduce a taxonomy of existing methods and describe distant supervision approaches in detail. We describe, in addition, the evaluation methodologies and the datasets commonly used for quality assessment. Finally, we give a high-level outlook on the field, highlighting open problems as well as the most promising research directions.",2019-09-30,,Extração de Relações Usando Supervisão Distante: Uma Revisão,"A extração de relações é uma subtarefa da extração de informações onde relações semânticas são extraídas de texto em linguagem natural e, em seguida, classificadas. Em essência, permite-nos adquirir conhecimento estruturado a partir de texto não estruturado. Neste artigo, apresentamos uma pesquisa sobre métodos de extração de relações que aproveitam dados estruturados ou semi-estruturados pré-existentes para guiar o processo de extração. Introduzimos uma taxonomia dos métodos existentes e descrevemos em detalhes as abordagens de supervisão distante. Descrevemos, além disso, as metodologias de avaliação e os conjuntos de dados comumente usados para a avaliação da qualidade. Finalmente, damos uma visão geral do campo, destacando problemas em aberto, bem como as direções de pesquisa mais promissoras."
AG56K5QX,conferencePaper,2019.0,"Shi, Yong; Xiao, Yang; Niu, Lingfeng",A Brief Survey of Relation Extraction Based on Distant Supervision,10.1007/978-3-030-22744-9_23,,"As a core task and important part of Information ExtractionEntity Relation Extraction can realize the identification of the semantic relation between entity pairs. And it plays an important role in semantic understanding of sentences and the construction of entity knowledge base. It has the potential of employing distant supervision method, end-to-end model and other deep learning model with the creation of large datasets. In this review, we compare the contributions and defect of the various models that have been used for the task, to help guide the path ahead.",2019,Springer International Publishing,Uma Breve Pesquisa sobre Extração de Relações Baseada em Supervisão Distante,"Como uma tarefa central e parte importante da Extração de Informação, a Extração de Relação entre Entidades pode realizar a identificação da relação semântica entre pares de entidades. E desempenha um papel importante na compreensão semântica de sentenças e na construção de uma base de conhecimento de entidades. Tem o potencial de empregar métodos de supervisão distante, modelos de ponta a ponta e outros modelos de aprendizado profundo com a criação de grandes conjuntos de dados. Nesta revisão, comparamos as contribuições e defeitos dos vários modelos que têm sido usados para a tarefa, para ajudar a guiar o caminho à frente."
2ISMF36G,conferencePaper,2021.0,"Hedderich, Michael A.; Lange, Lukas; Adel, Heike; Strötgen, Jannik; Klakow, Dietrich",A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios,10.18653/v1/2021.naacl-main.201,https://aclanthology.org/2021.naacl-main.201,"Deep neural networks and huge language models are becoming omnipresent in natural language applications. As they are known for requiring large amounts of training data, there is a growing body of work to improve the performance in low-resource settings. Motivated by the recent fundamental changes towards neural models and the popular pre-train and fine-tune paradigm, we survey promising approaches for low-resource natural language processing. After a discussion about the different dimensions of data availability, we give a structured overview of methods that enable learning when training data is sparse. This includes mechanisms to create additional labeled data like data augmentation and distant supervision as well as transfer learning settings that reduce the need for target supervision. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific low-resource setting. Further key aspects of this work are to highlight open issues and to outline promising directions for future research.",2021-06,Association for Computational Linguistics,Uma Pesquisa sobre Abordagens Recentes para Processamento de Linguagem Natural em Cenários de Baixos Recursos,"Redes neurais profundas e grandes modelos de linguagem estão se tornando onipresentes em aplicações de linguagem natural. Como são conhecidos por exigir grandes quantidades de dados de treinamento, há um número crescente de trabalhos para melhorar o desempenho em ambientes com poucos recursos. Motivados pelas recentes mudanças fundamentais em direção a modelos neurais e ao popular paradigma de pré-treinamento e ajuste fino, revisamos abordagens promissoras para o processamento de linguagem natural em ambientes com poucos recursos. Após uma discussão sobre as diferentes dimensões da disponibilidade de dados, fornecemos uma visão geral estruturada de métodos que permitem o aprendizado quando os dados de treinamento são escassos. Isso inclui mecanismos para criar dados rotulados adicionais, como aumento de dados e supervisão distante, bem como configurações de aprendizado por transferência que reduzem a necessidade de supervisão específica. Um dos objetivos da nossa pesquisa é explicar como esses métodos diferem em seus requisitos, pois compreendê-los é essencial para escolher uma técnica adequada para um ambiente específico com poucos recursos. Outros aspectos-chave deste trabalho são destacar questões em aberto e delinear direções promissoras para pesquisas futuras."
YYDYU24X,journalArticle,2021.0,"Algan, Görkem; Ulusoy, Ilkay",Image Classification with Deep Learning in the Presence of Noisy Labels: A Survey,10.1016/j.knosys.2021.106771,http://arxiv.org/abs/1912.05170,"Image classification systems recently made a giant leap with the advancement of deep neural networks. However, these systems require an excessive amount of labeled data to be adequately trained. Gathering a correctly annotated dataset is not always feasible due to several factors, such as the expensiveness of the labeling process or difficulty of correctly classifying data, even for the experts. Because of these practical challenges, label noise is a common problem in real-world datasets, and numerous methods to train deep neural networks with label noise are proposed in the literature. Although deep neural networks are known to be relatively robust to label noise, their tendency to overfit data makes them vulnerable to memorizing even random noise. Therefore, it is crucial to consider the existence of label noise and develop counter algorithms to fade away its adverse effects to train deep neural networks efficiently. Even though an extensive survey of machine learning techniques under label noise exists, the literature lacks a comprehensive survey of methodologies centered explicitly around deep learning in the presence of noisy labels. This paper aims to present these algorithms while categorizing them into one of the two subgroups: noise model based and noise model free methods. Algorithms in the first group aim to estimate the noise structure and use this information to avoid the adverse effects of noisy labels. Differently, methods in the second group try to come up with inherently noise robust algorithms by using approaches like robust losses, regularizers or other learning paradigms.",2021-03,,Classificação de Imagens com Aprendizado Profundo na Presença de Rótulos Ruins: Uma Revisão,"Os sistemas de classificação de imagens recentemente deram um grande salto com o avanço das redes neurais profundas. No entanto, esses sistemas requerem uma quantidade excessiva de dados rotulados para serem adequadamente treinados. Coletar um conjunto de dados corretamente anotado nem sempre é viável devido a vários fatores, como o alto custo do processo de rotulagem ou a dificuldade de classificar corretamente os dados, mesmo para os especialistas. Devido a esses desafios práticos, o ruído de rotulagem é um problema comum em conjuntos de dados do mundo real, e numerosos métodos para treinar redes neurais profundas com ruído de rotulagem são propostos na literatura. Embora as redes neurais profundas sejam conhecidas por serem relativamente robustas ao ruído de rotulagem, sua tendência a se ajustar excessivamente aos dados as torna vulneráveis a memorizar até mesmo ruídos aleatórios. Portanto, é crucial considerar a existência de ruído de rotulagem e desenvolver algoritmos contrários para atenuar seus efeitos adversos a fim de treinar redes neurais profundas de forma eficiente. Embora exista uma extensa pesquisa sobre técnicas de aprendizado de máquina sob ruído de rotulagem, a literatura carece de uma pesquisa abrangente de metodologias centradas explicitamente em aprendizado profundo na presença de rótulos ruidosos. Este artigo tem como objetivo apresentar esses algoritmos enquanto os categoriza em um dos dois subgrupos: métodos baseados em modelo de ruído e métodos livres de modelo de ruído. Os algoritmos no primeiro grupo visam estimar a estrutura do ruído e usar essa informação para evitar os efeitos adversos de rótulos ruidosos. De forma diferente, os métodos no segundo grupo tentam desenvolver algoritmos inerentemente robustos ao ruído utilizando abordagens como perdas robustas, regularizadores ou outros paradigmas de aprendizado."
YES2Q2X2,webpage,2021.0,"Hedderich, Michael A.",A Visual Guide to Low-Resource NLP,,https://towardsdatascience.com/a-visual-guide-to-low-resource-nlp-d7b4c7b1a4bc,An overview of recent approaches that help you train NLP models if you only have limited amounts of labeled data.,2021-09-07,,Um Guia Visual para NLP de Baixos Recursos,Uma visão geral das abordagens recentes que ajudam você a treinar modelos de PNL se você tiver apenas quantidades limitadas de dados rotulados.
KWY3Z769,conferencePaper,2021.0,"Sedova, Anastasiia; Stephan, Andreas; Speranskaya, Marina; Roth, Benjamin",Knodle: Modular Weakly Supervised Learning with PyTorch,10.18653/v1/2021.repl4nlp-1.12,http://arxiv.org/abs/2104.11557,"Strategies for improving the training and prediction quality of weakly supervised machine learning models vary in how much they are tailored to a specific task or integrated with a specific model architecture. In this work, we introduce Knodle, a software framework that treats weak data annotations, deep learning models, and methods for improving weakly supervised training as separate, modular components. This modularization gives the training process access to fine-grained information such as data set characteristics, matches of heuristic rules, or elements of the deep learning model ultimately used for prediction. Hence, our framework can encompass a wide range of training methods for improving weak supervision, ranging from methods that only look at correlations of rules and output classes (independently of the machine learning model trained with the resulting labels), to those that harness the interplay of neural networks and weakly labeled data. We illustrate the benchmarking potential of the framework with a performance comparison of several reference implementations on a selection of datasets that are already available in Knodle. The framework is published as an open-source Python package knodle and available at https://github.com/knodle/knodle.",2021,,Knodle: Aprendizado Modular Fracamente Supervisionado com PyTorch,"Estratégias para melhorar a qualidade do treinamento e da previsão de modelos de aprendizado de máquina fracamente supervisionados variam em quão adaptadas estão a uma tarefa específica ou integradas a uma arquitetura de modelo específica. Neste trabalho, introduzimos o Knodle, uma estrutura de software que trata anotações de dados fracos, modelos de aprendizado profundo e métodos para melhorar o treinamento fracamente supervisionado como componentes separados e modulares. Essa modularização dá ao processo de treinamento acesso a informações detalhadas, como características do conjunto de dados, correspondências de regras heurísticas ou elementos do modelo de aprendizado profundo utilizado para a previsão. Assim, nossa estrutura pode abranger uma ampla gama de métodos de treinamento para melhorar a supervisão fraca, variando de métodos que apenas observam correlações de regras e classes de saída (independentemente do modelo de aprendizado de máquina treinado com os rótulos resultantes) até aqueles que aproveitam a interação de redes neurais e dados fracamente rotulados. Ilustramos o potencial de benchmarking da estrutura com uma comparação de desempenho de várias implementações de referência em uma seleção de conjuntos de dados que já estão disponíveis no Knodle. A estrutura é publicada como um pacote Python de código aberto knodle e está disponível em https://github.com/knodle/knodle."
3W8FBNWW,preprint,2020.0,"Chen, Mayee F.; Fu, Daniel Y.; Sala, Frederic; Wu, Sen; Mullapudi, Ravi Teja; Poms, Fait; Fatahalian, Kayvon; Ré, Christopher",Train and You'll Miss It: Interactive Model Iteration with Weak Supervision and Pre-Trained Embeddings,10.48550/arXiv.2006.15168,http://arxiv.org/abs/2006.15168,"Our goal is to enable machine learning systems to be trained interactively. This requires models that perform well and train quickly, without large amounts of hand-labeled data. We take a step forward in this direction by borrowing from weak supervision (WS), wherein models can be trained with noisy sources of signal instead of hand-labeled data. But WS relies on training downstream deep networks to extrapolate to unseen data points, which can take hours or days. Pre-trained embeddings can remove this requirement. We do not use the embeddings as features as in transfer learning (TL), which requires fine-tuning for high performance, but instead use them to define a distance function on the data and extend WS source votes to nearby points. Theoretically, we provide a series of results studying how performance scales with changes in source coverage, source accuracy, and the Lipschitzness of label distributions in the embedding space, and compare this rate to standard WS without extension and TL without fine-tuning. On six benchmark NLP and video tasks, our method outperforms WS without extension by 4.1 points, TL without fine-tuning by 12.8 points, and traditionally-supervised deep networks by 13.1 points, and comes within 0.7 points of state-of-the-art weakly-supervised deep networks-all while training in less than half a second.",2020-06-26,arXiv,Treine e Você Vai Perder: Iteração de Modelo Interativa com Supervisão Fraca e Embeddings Pré-Treinados,"Nosso objetivo é permitir que sistemas de aprendizado de máquina sejam treinados de forma interativa. Isso requer modelos que tenham um bom desempenho e treinem rapidamente, sem grandes quantidades de dados rotulados manualmente. Damos um passo à frente nessa direção ao nos basearmos na supervisão fraca (WS), onde os modelos podem ser treinados com fontes de sinal ruidosas em vez de dados rotulados manualmente. Mas a WS depende do treinamento de redes profundas a jusante para extrapolar para pontos de dados não vistos, o que pode levar horas ou dias. Embeddings pré-treinados podem eliminar essa exigência. Não usamos os embeddings como características, como na transferência de aprendizado (TL), que requer ajuste fino para alto desempenho, mas sim os utilizamos para definir uma função de distância nos dados e estender os votos das fontes da WS para pontos próximos. Teoricamente, fornecemos uma série de resultados estudando como o desempenho escala com mudanças na cobertura das fontes, precisão das fontes e a Lipschitzness das distribuições de rótulos no espaço de embedding, e comparamos essa taxa com a WS padrão sem extensão e TL sem ajuste fino. Em seis tarefas de referência de NLP e vídeo, nosso método supera a WS sem extensão em 4,1 pontos, TL sem ajuste fino em 12,8 pontos, e redes profundas supervisionadas tradicionalmente em 13,1 pontos, e chega a ficar a 0,7 pontos das redes profundas supervisionadas de forma fraca de última geração - tudo isso enquanto treina em menos de meio segundo."
QXNN7LMJ,journalArticle,,"Ré, Chris",Weak Supervision Overview,,,,,,Visão Geral da Supervisão Fraca,nan
YHJ3IUSM,preprint,2021.0,"Cachay, Salva Rühling; Boecking, Benedikt; Dubrawski, Artur",End-to-End Weak Supervision,10.48550/arXiv.2107.02233,http://arxiv.org/abs/2107.02233,"Aggregating multiple sources of weak supervision (WS) can ease the data-labeling bottleneck prevalent in many machine learning applications, by replacing the tedious manual collection of ground truth labels. Current state of the art approaches that do not use any labeled training data, however, require two separate modeling steps: Learning a probabilistic latent variable model based on the WS sources -- making assumptions that rarely hold in practice -- followed by downstream model training. Importantly, the first step of modeling does not consider the performance of the downstream model. To address these caveats we propose an end-to-end approach for directly learning the downstream model by maximizing its agreement with probabilistic labels generated by reparameterizing previous probabilistic posteriors with a neural network. Our results show improved performance over prior work in terms of end model performance on downstream test sets, as well as in terms of improved robustness to dependencies among weak supervision sources.",2021-11-30,arXiv,Supervisão Fraca de Ponta a Ponta,"Agregar múltiplas fontes de supervisão fraca (SF) pode aliviar o gargalo de rotulagem de dados prevalente em muitas aplicações de aprendizado de máquina, substituindo a tediosa coleta manual de rótulos de verdadeiros. No entanto, as abordagens atuais de ponta que não utilizam dados de treinamento rotulados exigem duas etapas de modelagem separadas: aprender um modelo de variável latente probabilística com base nas fontes de SF - fazendo suposições que raramente se sustentam na prática - seguido pelo treinamento do modelo a montante. É importante ressaltar que a primeira etapa de modelagem não considera o desempenho do modelo a montante. Para abordar essas limitações, propomos uma abordagem de ponta a ponta para aprender diretamente o modelo a montante, maximizando seu acordo com rótulos probabilísticos gerados pela reparametrização de posteriors probabilísticos anteriores com uma rede neural. Nossos resultados mostram desempenho melhorado em relação a trabalhos anteriores em termos de desempenho do modelo final em conjuntos de testes a montante, bem como em termos de maior robustez a dependências entre fontes de supervisão fraca."
K2KN98S7,preprint,2021.0,"Biegel, Samantha; El-Khatib, Rafah; Oliveira, Luiz Otavio Vilas Boas; Baak, Max; Aben, Nanne",Active WeaSuL: Improving Weak Supervision with Active Learning,10.48550/arXiv.2104.14847,http://arxiv.org/abs/2104.14847,"The availability of labelled data is one of the main limitations in machine learning. We can alleviate this using weak supervision: a framework that uses expert-defined rules $\boldsymbol{\lambda}$ to estimate probabilistic labels $p(y|\boldsymbol{\lambda})$ for the entire data set. These rules, however, are dependent on what experts know about the problem, and hence may be inaccurate or may fail to capture important parts of the problem-space. To mitigate this, we propose Active WeaSuL: an approach that incorporates active learning into weak supervision. In Active WeaSuL, experts do not only define rules, but they also iteratively provide the true label for a small set of points where the weak supervision model is most likely to be mistaken, which are then used to better estimate the probabilistic labels. In this way, the weak labels provide a warm start, which active learning then improves upon. We make two contributions: 1) a modification of the weak supervision loss function, such that the expert-labelled data inform and improve the combination of weak labels; and 2) the maxKL divergence sampling strategy, which determines for which data points expert labelling is most beneficial. Our experiments show that when the budget for labelling data is limited (e.g. $\leq 60$ data points), Active WeaSuL outperforms weak supervision, active learning, and competing strategies, with only a handful of labelled data points. This makes Active WeaSuL ideal for situations where obtaining labelled data is difficult.",2021-04-30,arXiv,WeaSuL Ativo: Melhorando a Supervisão Fraca com Aprendizado Ativo,"A disponibilidade de dados rotulados é uma das principais limitações em aprendizado de máquina. Podemos aliviar isso usando supervisão fraca: uma estrutura que utiliza regras definidas por especialistas $\boldsymbol{\lambda}$ para estimar rótulos probabilísticos $p(y|\boldsymbol{\lambda})$ para todo o conjunto de dados. No entanto, essas regras dependem do que os especialistas sabem sobre o problema e, portanto, podem ser imprecisas ou podem falhar em capturar partes importantes do espaço do problema. Para mitigar isso, propomos o Active WeaSuL: uma abordagem que incorpora aprendizado ativo à supervisão fraca. No Active WeaSuL, os especialistas não apenas definem regras, mas também fornecem iterativamente o rótulo verdadeiro para um pequeno conjunto de pontos onde o modelo de supervisão fraca é mais propenso a errar, que são então usados para estimar melhor os rótulos probabilísticos. Dessa forma, os rótulos fracos fornecem um início aquecido, que o aprendizado ativo então melhora. Fazemos duas contribuições: 1) uma modificação da função de perda da supervisão fraca, de modo que os dados rotulados por especialistas informem e melhorem a combinação de rótulos fracos; e 2) a estratégia de amostragem de divergência maxKL, que determina para quais pontos de dados a rotulagem por especialistas é mais benéfica. Nossos experimentos mostram que, quando o orçamento para rotular dados é limitado (por exemplo, $\leq 60$ pontos de dados), o Active WeaSuL supera a supervisão fraca, o aprendizado ativo e estratégias concorrentes, com apenas um punhado de pontos de dados rotulados. Isso torna o Active WeaSuL ideal para situações em que obter dados rotulados é difícil."
YXCNAVLP,preprint,2021.0,"Boecking, Benedikt; Neiswanger, Willie; Xing, Eric; Dubrawski, Artur",Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling,10.48550/arXiv.2012.06046,http://arxiv.org/abs/2012.06046,"Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.",2021-01-25,arXiv,Supervisão Fraca Interativa: Aprendendo Heurísticas Úteis para Rotulagem de Dados,"A obtenção de grandes conjuntos de dados anotados é crítica para treinar modelos de aprendizado de máquina bem-sucedidos e, na prática, muitas vezes é um gargalo. A supervisão fraca oferece uma alternativa promissora para produzir conjuntos de dados rotulados sem anotações de verdade de base, gerando rótulos probabilísticos usando múltiplas heurísticas ruidosas. Esse processo pode escalar para grandes conjuntos de dados e demonstrou desempenho de ponta em diversos domínios, como saúde e comércio eletrônico. Um problema prático ao aprender com heurísticas geradas por usuários é que sua criação requer criatividade, visão de futuro e expertise no domínio por parte daqueles que as elaboram, um processo que pode ser tedioso e subjetivo. Desenvolvemos a primeira estrutura para supervisão fraca interativa, na qual um método propõe heurísticas e aprende com o feedback do usuário dado sobre cada heurística proposta. Nossos experimentos demonstram que apenas um pequeno número de iterações de feedback é necessário para treinar modelos que alcançam um desempenho altamente competitivo em conjuntos de testes sem acesso a rótulos de treinamento de verdade de base. Realizamos estudos com usuários, que mostram que os usuários conseguem fornecer feedback de forma eficaz sobre heurísticas e que os resultados do conjunto de testes acompanham o desempenho de oráculos simulados."
KMK93KHY,preprint,2017.0,"Ratner, Alexander; De Sa, Christopher; Wu, Sen; Selsam, Daniel; Ré, Christopher","Data Programming: Creating Large Training Sets, Quickly",10.48550/arXiv.1605.07723,http://arxiv.org/abs/1605.07723,"Large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques. For some applications, creating labeled training sets is the most time-consuming and expensive part of applying machine learning. We therefore propose a paradigm for the programmatic creation of training sets called data programming in which users express weak supervision strategies or domain heuristics as labeling functions, which are programs that label subsets of the data, but that are noisy and may conflict. We show that by explicitly representing this training set labeling process as a generative model, we can ""denoise"" the generated training set, and establish theoretically that we can recover the parameters of these generative models in a handful of settings. We then show how to modify a discriminative loss function to make it noise-aware, and demonstrate our method over a range of discriminative models including logistic regression and LSTMs. Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data programming would have led to a new winning score, and also show that applying data programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points over a state-of-the-art LSTM baseline (and into second place in the competition). Additionally, in initial user studies we observed that data programming may be an easier way for non-experts to create machine learning models when training data is limited or unavailable.",2017-01-08,arXiv,"Programação de Dados: Criando Grandes Conjuntos de Treinamento, Rápido","Grandes conjuntos de dados rotulados são os blocos de construção críticos dos métodos de aprendizado supervisionado e são habilitadores chave das técnicas de aprendizado profundo. Para algumas aplicações, criar conjuntos de dados rotulados é a parte mais demorada e cara da aplicação de aprendizado de máquina. Portanto, propomos um paradigma para a criação programática de conjuntos de treinamento chamado programação de dados, no qual os usuários expressam estratégias de supervisão fraca ou heurísticas de domínio como funções de rotulagem, que são programas que rotulam subconjuntos dos dados, mas que são ruidosos e podem entrar em conflito. Mostramos que, ao representar explicitamente esse processo de rotulagem de conjuntos de treinamento como um modelo generativo, podemos ""remover o ruído"" do conjunto de treinamento gerado e estabelecer teoricamente que podemos recuperar os parâmetros desses modelos generativos em um punhado de configurações. Em seguida, mostramos como modificar uma função de perda discriminativa para torná-la ciente do ruído e demonstramos nosso método em uma variedade de modelos discriminativos, incluindo regressão logística e LSTMs. Experimentalmente, no desafio de Preenchimento de Slots TAC-KBP 2014, mostramos que a programação de dados teria levado a uma nova pontuação vencedora e também mostramos que aplicar a programação de dados a um modelo LSTM resulta em uma pontuação TAC-KBP quase 6 pontos F1 acima de uma linha de base LSTM de última geração (e em segundo lugar na competição). Além disso, em estudos iniciais com usuários, observamos que a programação de dados pode ser uma maneira mais fácil para não especialistas criarem modelos de aprendizado de máquina quando os dados de treinamento são limitados ou indisponíveis."
TRCMXGEA,conferencePaper,,,Interactive Programmatic Labeling for Weak Supervision,,,,,,Rotulagem Programática Interativa para Supervisão Fraca,nan
FGS6HVUQ,preprint,2019.0,"Fonseca, Eduardo; Font, Frederic; Serra, Xavier",Model-agnostic Approaches to Handling Noisy Labels When Training Sound Event Classifiers,,http://arxiv.org/abs/1910.12004,"Label noise is emerging as a pressing issue in sound event classification. This arises as we move towards larger datasets that are difficult to annotate manually, but it is even more severe if datasets are collected automatically from online repositories, where labels are inferred through automated heuristics applied to the audio content or metadata. While learning from noisy labels has been an active area of research in computer vision, it has received little attention in sound event classification. Most recent computer vision approaches against label noise are relatively complex, requiring complex networks or extra data resources. In this work, we evaluate simple and efficient model-agnostic approaches to handling noisy labels when training sound event classifiers, namely label smoothing regularization, mixup and noise-robust loss functions. The main advantage of these methods is that they can be easily incorporated to existing deep learning pipelines without need for network modifications or extra resources. We report results from experiments conducted with the FSDnoisy18k dataset. We show that these simple methods can be effective in mitigating the effect of label noise, providing up to 2.5\% of accuracy boost when incorporated to two different CNNs, while requiring minimal intervention and computational overhead.",2019-10-26,arXiv,Abordagens independentes de modelo para lidar com rótulos ruidosos ao treinar classificadores de eventos sonoros,"O ruído de rótulo está emergindo como uma questão premente na classificação de eventos sonoros. Isso surge à medida que avançamos em direção a conjuntos de dados maiores que são difíceis de anotar manualmente, mas é ainda mais severo se os conjuntos de dados forem coletados automaticamente de repositórios online, onde os rótulos são inferidos por meio de heurísticas automatizadas aplicadas ao conteúdo de áudio ou metadados. Embora aprender com rótulos ruidosos tenha sido uma área ativa de pesquisa em visão computacional, recebeu pouca atenção na classificação de eventos sonoros. As abordagens mais recentes de visão computacional contra o ruído de rótulo são relativamente complexas, exigindo redes complexas ou recursos de dados extras. Neste trabalho, avaliamos abordagens simples e eficientes, independentes de modelo, para lidar com rótulos ruidosos ao treinar classificadores de eventos sonoros, nomeadamente regularização de suavização de rótulo, mixup e funções de perda robustas ao ruído. A principal vantagem desses métodos é que podem ser facilmente incorporados a pipelines de aprendizado profundo existentes, sem necessidade de modificações na rede ou recursos extras. Relatamos resultados de experimentos realizados com o conjunto de dados FSDnoisy18k. Mostramos que esses métodos simples podem ser eficazes na mitigação do efeito do ruído de rótulo, proporcionando até 2,5% de aumento na precisão quando incorporados a duas CNNs diferentes, enquanto exigem intervenção mínima e sobrecarga computacional."
URS3S7X8,conferencePaper,2020.0,"Lukasik, Michal; Bhojanapalli, Srinadh; Menon, Aditya; Kumar, Sanjiv",Does label smoothing mitigate label noise?,,https://proceedings.mlr.press/v119/lukasik20a.html,"Label smoothing is commonly used in training deep learning models, wherein one-hot training labels are mixed with uniform label vectors. Empirically, smoothing has been shown to improve both predictive performance and model calibration. In this paper, we study whether label smoothing is also effective as a means of coping with label noise. While label smoothing apparently amplifies this problem — being equivalent to injecting symmetric noise to the labels — we show how it relates to a general family of loss-correction techniques from the label noise literature. Building on this connection, we show that label smoothing is competitive with loss-correction under label noise. Further, we show that when distilling models from noisy data, label smoothing of the teacher is beneficial; this is in contrast to recent findings for noise-free problems, and sheds further light on settings where label smoothing is beneficial.",2020-11-21,PMLR,A suavização de rótulos mitiga o ruído de rótulos?,"O suavização de rótulos é comumente usada no treinamento de modelos de aprendizado profundo, onde rótulos de treinamento one-hot são misturados com vetores de rótulos uniformes. Empiricamente, a suavização demonstrou melhorar tanto o desempenho preditivo quanto a calibração do modelo. Neste artigo, estudamos se a suavização de rótulos também é eficaz como um meio de lidar com o ruído nos rótulos. Embora a suavização de rótulos aparentemente amplifique esse problema — sendo equivalente a injetar ruído simétrico nos rótulos — mostramos como ela se relaciona a uma família geral de técnicas de correção de perda da literatura sobre ruído nos rótulos. Baseando-se nessa conexão, mostramos que a suavização de rótulos é competitiva com a correção de perda sob ruído nos rótulos. Além disso, mostramos que, ao destilar modelos a partir de dados ruidosos, a suavização de rótulos do professor é benéfica; isso contrasta com descobertas recentes para problemas sem ruído e lança mais luz sobre configurações onde a suavização de rótulos é benéfica."
TZKW4WXL,preprint,2022.0,"Wei, Jiaheng; Liu, Hangyu; Liu, Tongliang; Niu, Gang; Sugiyama, Masashi; Liu, Yang",To Smooth or Not? When Label Smoothing Meets Noisy Labels,10.48550/arXiv.2106.04149,http://arxiv.org/abs/2106.04149,"Label smoothing (LS) is an arising learning paradigm that uses the positively weighted average of both the hard training labels and uniformly distributed soft labels. It was shown that LS serves as a regularizer for training data with hard labels and therefore improves the generalization of the model. Later it was reported LS even helps with improving robustness when learning with noisy labels. However, we observed that the advantage of LS vanishes when we operate in a high label noise regime. Intuitively speaking, this is due to the increased entropy of $\mathbb{P}(\text{noisy label}|X)$ when the noise rate is high, in which case, further applying LS tends to ""over-smooth"" the estimated posterior. We proceeded to discover that several learning-with-noisy-labels solutions in the literature instead relate more closely to negative/not label smoothing (NLS), which acts counter to LS and defines as using a negative weight to combine the hard and soft labels! We provide understandings for the properties of LS and NLS when learning with noisy labels. Among other established properties, we theoretically show NLS is considered more beneficial when the label noise rates are high. We provide extensive experimental results on multiple benchmarks to support our findings too. Code is publicly available at https://github.com/UCSC-REAL/negative-label-smoothing.",2022-06-24,arXiv,Suavizar ou Não? Quando a Suavização de Rótulos Encontra Rótulos Ruins,"A suavização de rótulos (LS) é um paradigma de aprendizado emergente que utiliza a média ponderada positivamente de rótulos de treinamento rígidos e rótulos suaves distribuídos uniformemente. Foi demonstrado que a LS atua como um regularizador para dados de treinamento com rótulos rígidos e, portanto, melhora a generalização do modelo. Posteriormente, foi relatado que a LS até ajuda a melhorar a robustez ao aprender com rótulos ruidosos. No entanto, observamos que a vantagem da LS desaparece quando operamos em um regime de alta taxa de ruído de rótulo. Intuitivamente, isso se deve ao aumento da entropia de $\mathbb{P}(\text{rótulo ruidoso}|X)$ quando a taxa de ruído é alta, caso em que a aplicação adicional da LS tende a ""suavizar demais"" a posteriori estimada. Prosseguimos para descobrir que várias soluções de aprendizado com rótulos ruidosos na literatura se relacionam mais estreitamente com a suavização negativa/não de rótulo (NLS), que age em contraposição à LS e é definida como o uso de um peso negativo para combinar os rótulos rígidos e suaves! Fornecemos compreensões sobre as propriedades da LS e da NLS ao aprender com rótulos ruidosos. Entre outras propriedades estabelecidas, mostramos teoricamente que a NLS é considerada mais benéfica quando as taxas de ruído de rótulo são altas. Também fornecemos resultados experimentais extensivos em múltiplos benchmarks para apoiar nossas descobertas. O código está disponível publicamente em https://github.com/UCSC-REAL/negative-label-smoothing."
MK7N9PJC,conferencePaper,2021.0,"Lison, Pierre; Barnes, Jeremy; Hubin, Aliaksandr",skweak: Weak Supervision Made Easy for NLP,10.18653/v1/2021.acl-demo.40,http://arxiv.org/abs/2104.09683,"We present skweak, a versatile, Python-based software toolkit enabling NLP developers to apply weak supervision to a wide range of NLP tasks. Weak supervision is an emerging machine learning paradigm based on a simple idea: instead of labelling data points by hand, we use labelling functions derived from domain knowledge to automatically obtain annotations for a given dataset. The resulting labels are then aggregated with a generative model that estimates the accuracy (and possible confusions) of each labelling function. The skweak toolkit makes it easy to implement a large spectrum of labelling functions (such as heuristics, gazetteers, neural models or linguistic constraints) on text data, apply them on a corpus, and aggregate their results in a fully unsupervised fashion. skweak is especially designed to facilitate the use of weak supervision for NLP tasks such as text classification and sequence labelling. We illustrate the use of skweak for NER and sentiment analysis. skweak is released under an open-source license and is available at: https://github.com/NorskRegnesentral/skweak",2021,,skweak: Supervisão Fraca Facilitada para PNL,"Apresentamos o skweak, um conjunto de ferramentas de software versátil, baseado em Python, que permite aos desenvolvedores de PNL aplicar supervisão fraca a uma ampla gama de tarefas de PNL. A supervisão fraca é um paradigma emergente de aprendizado de máquina baseado em uma ideia simples: em vez de rotular pontos de dados manualmente, usamos funções de rotulagem derivadas do conhecimento do domínio para obter automaticamente anotações para um determinado conjunto de dados. Os rótulos resultantes são então agregados com um modelo generativo que estima a precisão (e possíveis confusões) de cada função de rotulagem. O conjunto de ferramentas skweak facilita a implementação de um grande espectro de funções de rotulagem (como heurísticas, dicionários, modelos neurais ou restrições linguísticas) em dados textuais, aplicá-las em um corpus e agregar seus resultados de forma totalmente não supervisionada. O skweak é especialmente projetado para facilitar o uso de supervisão fraca para tarefas de PNL, como classificação de texto e rotulagem de sequências. Ilustramos o uso do skweak para NER e análise de sentimentos. O skweak é lançado sob uma licença de código aberto e está disponível em: https://github.com/NorskRegnesentral/skweak"
L6PXDS3Z,preprint,2022.0,"Tunstall, Lewis; Reimers, Nils; Jo, Unso Eun Seo; Bates, Luke; Korat, Daniel; Wasserblat, Moshe; Pereg, Oren",Efficient Few-Shot Learning Without Prompts,10.48550/arXiv.2209.11055,http://arxiv.org/abs/2209.11055,"Recent few-shot methods, such as parameter-efficient fine-tuning (PEFT) and pattern exploiting training (PET), have achieved impressive results in label-scarce settings. However, they are difficult to employ since they are subject to high variability from manually crafted prompts, and typically require billion-parameter language models to achieve high accuracy. To address these shortcomings, we propose SetFit (Sentence Transformer Fine-tuning), an efficient and prompt-free framework for few-shot fine-tuning of Sentence Transformers (ST). SetFit works by first fine-tuning a pretrained ST on a small number of text pairs, in a contrastive Siamese manner. The resulting model is then used to generate rich text embeddings, which are used to train a classification head. This simple framework requires no prompts or verbalizers, and achieves high accuracy with orders of magnitude less parameters than existing techniques. Our experiments show that SetFit obtains comparable results with PEFT and PET techniques, while being an order of magnitude faster to train. We also show that SetFit can be applied in multilingual settings by simply switching the ST body. Our code is available at https://github.com/huggingface/setfit and our datasets at https://huggingface.co/setfit .",2022-09-22,arXiv,Aprendizado Eficiente de Poucos Exemplos Sem Prompts,"Métodos recentes de few-shot, como ajuste fino eficiente em parâmetros (PEFT) e treinamento que explora padrões (PET), alcançaram resultados impressionantes em configurações com escassez de rótulos. No entanto, eles são difíceis de empregar, pois estão sujeitos a alta variabilidade devido a prompts elaborados manualmente e geralmente requerem modelos de linguagem com bilhões de parâmetros para alcançar alta precisão. Para abordar essas limitações, propomos o SetFit (Ajuste Fino de Transformadores de Sentença), uma estrutura eficiente e sem prompts para ajuste fino de poucos exemplos de Transformadores de Sentença (ST). O SetFit funciona primeiro ajustando um ST pré-treinado em um pequeno número de pares de texto, de maneira contrastiva e siamesa. O modelo resultante é então usado para gerar embeddings de texto ricos, que são usados para treinar uma cabeça de classificação. Esta estrutura simples não requer prompts ou verbalizadores e alcança alta precisão com ordens de magnitude menos parâmetros do que as técnicas existentes. Nossos experimentos mostram que o SetFit obtém resultados comparáveis com as técnicas PEFT e PET, enquanto é uma ordem de magnitude mais rápido para treinar. Também mostramos que o SetFit pode ser aplicado em configurações multilíngues simplesmente trocando o corpo do ST. Nosso código está disponível em https://github.com/huggingface/setfit e nossos conjuntos de dados em https://huggingface.co/setfit."
YZ875CN6,preprint,2022.0,"Northcutt, Curtis G.; Jiang, Lu; Chuang, Isaac L.",Confident Learning: Estimating Uncertainty in Dataset Labels,10.48550/arXiv.1911.00068,http://arxiv.org/abs/1911.00068,"Learning exists in the context of data, yet notions of confidence typically focus on model predictions, not label quality. Confident learning (CL) is an alternative approach which focuses instead on label quality by characterizing and identifying label errors in datasets, based on the principles of pruning noisy data, counting with probabilistic thresholds to estimate noise, and ranking examples to train with confidence. Whereas numerous studies have developed these principles independently, here, we combine them, building on the assumption of a class-conditional noise process to directly estimate the joint distribution between noisy (given) labels and uncorrupted (unknown) labels. This results in a generalized CL which is provably consistent and experimentally performant. We present sufficient conditions where CL exactly finds label errors, and show CL performance exceeding seven recent competitive approaches for learning with noisy labels on the CIFAR dataset. Uniquely, the CL framework is not coupled to a specific data modality or model (e.g., we use CL to find several label errors in the presumed error-free MNIST dataset and improve sentiment classification on text data in Amazon Reviews). We also employ CL on ImageNet to quantify ontological class overlap (e.g., estimating 645 ""missile"" images are mislabeled as their parent class ""projectile""), and moderately increase model accuracy (e.g., for ResNet) by cleaning data prior to training. These results are replicable using the open-source cleanlab release.",2022-08-21,arXiv,Aprendizado Confiante: Estimando Incerteza nas Etiquetas de Conjuntos de Dados,"A aprendizagem existe no contexto de dados, no entanto, as noções de confiança geralmente se concentram nas previsões do modelo, e não na qualidade dos rótulos. A aprendizagem confiante (CL) é uma abordagem alternativa que se concentra na qualidade dos rótulos, caracterizando e identificando erros de rótulos em conjuntos de dados, com base nos princípios de poda de dados ruidosos, contando com limiares probabilísticos para estimar o ruído e classificando exemplos para treinar com confiança. Enquanto numerosos estudos desenvolveram esses princípios de forma independente, aqui, combinamos esses princípios, baseando-nos na suposição de um processo de ruído condicional à classe para estimar diretamente a distribuição conjunta entre rótulos ruidosos (dado) e rótulos não corrompidos (desconhecidos). Isso resulta em uma CL generalizada que é provadamente consistente e experimentalmente eficaz. Apresentamos condições suficientes onde a CL encontra exatamente erros de rótulos e mostramos que o desempenho da CL supera sete abordagens competitivas recentes para aprendizagem com rótulos ruidosos no conjunto de dados CIFAR. De forma única, a estrutura da CL não está vinculada a uma modalidade de dados ou modelo específico (por exemplo, usamos CL para encontrar vários erros de rótulos no conjunto de dados MNIST presumidamente livre de erros e melhorar a classificação de sentimentos em dados de texto nas Avaliações da Amazon). Também empregamos CL no ImageNet para quantificar a sobreposição de classes ontológicas (por exemplo, estimando que 645 imagens de ""míssil"" estão rotuladas incorretamente como sua classe pai ""projétil"") e aumentamos moderadamente a precisão do modelo (por exemplo, para ResNet) ao limpar os dados antes do treinamento. Esses resultados são replicáveis usando a versão open-source cleanlab."
JLZ8IBAG,preprint,2020.0,"Mukherjee, Subhabrata; Awadallah, Ahmed Hassan",Uncertainty-aware Self-training for Text Classification with Few Labels,10.48550/arXiv.2006.15315,http://arxiv.org/abs/2006.15315,"Recent success of large-scale pre-trained language models crucially hinge on fine-tuning them on large amounts of labeled data for the downstream task, that are typically expensive to acquire. In this work, we study self-training as one of the earliest semi-supervised learning approaches to reduce the annotation bottleneck by making use of large-scale unlabeled data for the target task. Standard self-training mechanism randomly samples instances from the unlabeled pool to pseudo-label and augment labeled data. In this work, we propose an approach to improve self-training by incorporating uncertainty estimates of the underlying neural network leveraging recent advances in Bayesian deep learning. Specifically, we propose (i) acquisition functions to select instances from the unlabeled pool leveraging Monte Carlo (MC) Dropout, and (ii) learning mechanism leveraging model confidence for self-training. As an application, we focus on text classification on five benchmark datasets. We show our methods leveraging only 20-30 labeled samples per class for each task for training and for validation can perform within 3% of fully supervised pre-trained language models fine-tuned on thousands of labeled instances with an aggregate accuracy of 91% and improving by upto 12% over baselines.",2020-06-27,arXiv,Auto-treinamento ciente da incerteza para classificação de texto com poucas etiquetas,"O sucesso recente de modelos de linguagem pré-treinados em larga escala depende crucialmente do ajuste fino desses modelos em grandes quantidades de dados rotulados para a tarefa subsequente, que normalmente são caros de adquirir. Neste trabalho, estudamos o auto-treinamento como uma das primeiras abordagens de aprendizado semi-supervisionado para reduzir o gargalo de anotação, fazendo uso de dados não rotulados em larga escala para a tarefa-alvo. O mecanismo padrão de auto-treinamento amostra aleatoriamente instâncias do conjunto não rotulado para pseudo-rotular e aumentar os dados rotulados. Neste trabalho, propomos uma abordagem para melhorar o auto-treinamento incorporando estimativas de incerteza da rede neural subjacente, aproveitando os avanços recentes em aprendizado profundo bayesiano. Especificamente, propomos (i) funções de aquisição para selecionar instâncias do conjunto não rotulado aproveitando o Monte Carlo (MC) Dropout, e (ii) um mecanismo de aprendizado aproveitando a confiança do modelo para auto-treinamento. Como aplicação, focamos na classificação de texto em cinco conjuntos de dados de referência. Mostramos que nossos métodos, utilizando apenas 20-30 amostras rotuladas por classe para cada tarefa de treinamento e validação, podem performar dentro de 3% de modelos de linguagem pré-treinados totalmente supervisionados ajustados em milhares de instâncias rotuladas, com uma precisão agregada de 91% e melhorando em até 12% em relação às linhas de base."
5XVEYIA2,journalArticle,2022.0,"Chen, Li-Ming; Xiu, Bao-Xin; Ding, Zhao-Yun",Multiple weak supervision for short text classification,10.1007/s10489-021-02958-3,https://doi.org/10.1007/s10489-021-02958-3,"For short text classification, insufficient labeled data, data sparsity, and imbalanced classification have become three major challenges. For this, we proposed multiple weak supervision, which can label unlabeled data automatically. Different from prior work, the proposed method can generate probabilistic labels through conditional independent model. What’s more, experiments were conducted to verify the effectiveness of multiple weak supervision. According to experimental results on public dadasets, real datasets and synthetic datasets, unlabeled imbalanced short text classification problem can be solved effectively by multiple weak supervision. Notably, without reducing precision, recall, and F1-score can be improved by adding distant supervision clustering, which can be used to meet different application needs.",2022-06-01,,Supervisão fraca múltipla para classificação de textos curtos,"Para a classificação de textos curtos, a escassez de dados rotulados, a escassez de dados e a classificação desbalanceada tornaram-se três grandes desafios. Para isso, propusemos múltiplas supervisões fracas, que podem rotular dados não rotulados automaticamente. Diferente de trabalhos anteriores, o método proposto pode gerar rótulos probabilísticos através de um modelo de independência condicional. Além disso, experimentos foram realizados para verificar a eficácia da múltipla supervisão fraca. De acordo com os resultados experimentais em conjuntos de dados públicos, conjuntos de dados reais e conjuntos de dados sintéticos, o problema da classificação de textos curtos não rotulados e desbalanceados pode ser resolvido efetivamente pela múltipla supervisão fraca. Notavelmente, sem reduzir a precisão, o recall e a F1-score podem ser melhorados ao adicionar agrupamento de supervisão distante, que pode ser utilizado para atender a diferentes necessidades de aplicação."
LWZEPDAT,conferencePaper,2020.0,"Mekala, Dheeraj; Shang, Jingbo",Contextualized Weak Supervision for Text Classification,10.18653/v1/2020.acl-main.30,https://aclanthology.org/2020.acl-main.30,"Weakly supervised text classification based on a few user-provided seed words has recently attracted much attention from researchers. Existing methods mainly generate pseudo-labels in a context-free manner (e.g., string matching), therefore, the ambiguous, context-dependent nature of human language has been long overlooked. In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification. Specifically, we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus. This contextualized corpus is further utilized to train the classifier and expand seed words in an iterative manner. This process not only adds new contextualized, highly label-indicative keywords but also disambiguates initial seed words, making our weak supervision fully contextualized. Extensive experiments and case studies on real-world datasets demonstrate the necessity and significant advantages of using contextualized weak supervision, especially when the class labels are fine-grained.",2020-07,Association for Computational Linguistics,Supervisão Fraca Contextualizada para Classificação de Texto,"A classificação de texto com supervisão fraca baseada em algumas palavras-chave fornecidas pelo usuário atraiu recentemente muita atenção dos pesquisadores. Os métodos existentes geram principalmente pseudo-rótulos de maneira independente de contexto (por exemplo, correspondência de strings), portanto, a natureza ambígua e dependente de contexto da linguagem humana tem sido há muito negligenciada. Neste artigo, propomos uma nova estrutura chamada ConWea, que fornece supervisão fraca contextualizada para a classificação de texto. Especificamente, aproveitamos representações contextualizadas das ocorrências de palavras e informações sobre palavras-chave para diferenciar automaticamente múltiplas interpretações da mesma palavra e, assim, criar um corpus contextualizado. Este corpus contextualizado é utilizado para treinar o classificador e expandir as palavras-chave de maneira iterativa. Este processo não apenas adiciona novas palavras-chave contextualizadas e altamente indicativas de rótulos, mas também desambigua as palavras-chave iniciais, tornando nossa supervisão fraca totalmente contextualizada. Experimentos extensivos e estudos de caso em conjuntos de dados do mundo real demonstram a necessidade e as vantagens significativas de usar supervisão fraca contextualizada, especialmente quando os rótulos de classe são finamente detalhados."
B7N6IEUK,preprint,2022.0,"Metzenthin, Emanuel; Bartz, Christian; Meinel, Christoph",Weakly Supervised Scene Text Detection using Deep Reinforcement Learning,10.48550/arXiv.2201.04866,http://arxiv.org/abs/2201.04866,"The challenging field of scene text detection requires complex data annotation, which is time-consuming and expensive. Techniques, such as weak supervision, can reduce the amount of data needed. In this paper we propose a weak supervision method for scene text detection, which makes use of reinforcement learning (RL). The reward received by the RL agent is estimated by a neural network, instead of being inferred from ground-truth labels. First, we enhance an existing supervised RL approach to text detection with several training optimizations, allowing us to close the performance gap to regression-based algorithms. We then use our proposed system in a weakly- and semi-supervised training on real-world data. Our results show that training in a weakly supervised setting is feasible. However, we find that using our model in a semi-supervised setting , e.g. when combining labeled synthetic data with unannotated real-world data, produces the best results.",2022-01-13,arXiv,Detecção de Texto em Cena Supervisionada de Forma Fraca Usando Aprendizado por Reforço Profundo,"O desafiador campo da detecção de texto em cena requer anotação de dados complexa, que é demorada e cara. Técnicas, como supervisão fraca, podem reduzir a quantidade de dados necessária. Neste artigo, propomos um método de supervisão fraca para detecção de texto em cena, que utiliza aprendizado por reforço (RL). A recompensa recebida pelo agente de RL é estimada por uma rede neural, em vez de ser inferida a partir de rótulos verdadeiros. Primeiro, aprimoramos uma abordagem existente de RL supervisionado para detecção de texto com várias otimizações de treinamento, permitindo-nos fechar a lacuna de desempenho em relação a algoritmos baseados em regressão. Em seguida, usamos nosso sistema proposto em um treinamento fraco e semi-supervisionado em dados do mundo real. Nossos resultados mostram que o treinamento em um ambiente de supervisão fraca é viável. No entanto, descobrimos que usar nosso modelo em um ambiente semi-supervisionado, por exemplo, ao combinar dados sintéticos rotulados com dados do mundo real não anotados, produz os melhores resultados."
ZLNIWP78,preprint,2020.0,"Robinson, Joshua; Jegelka, Stefanie; Sra, Suvrit",Strength from Weakness: Fast Learning Using Weak Supervision,,http://arxiv.org/abs/2002.08483,"We study generalization properties of weakly supervised learning. That is, learning where only a few ""strong"" labels (the actual target of our prediction) are present but many more ""weak"" labels are available. In particular, we show that having access to weak labels can significantly accelerate the learning rate for the strong task to the fast rate of $\mathcal{O}(\nicefrac1n)$, where $n$ denotes the number of strongly labeled data points. This acceleration can happen even if by itself the strongly labeled data admits only the slower $\mathcal{O}(\nicefrac{1}{\sqrt{n}})$ rate. The actual acceleration depends continuously on the number of weak labels available, and on the relation between the two tasks. Our theoretical results are reflected empirically across a range of tasks and illustrate how weak labels speed up learning on the strong task.",2020-02-19,arXiv,Força da Fraqueza: Aprendizado Rápido Usando Supervisão Fraca,"Estudamos as propriedades de generalização do aprendizado fraco supervisionado. Ou seja, aprendizado onde apenas algumas ""etiquetas fortes"" (o alvo real da nossa previsão) estão presentes, mas muitas mais ""etiquetas fracas"" estão disponíveis. Em particular, mostramos que ter acesso a etiquetas fracas pode acelerar significativamente a taxa de aprendizado para a tarefa forte para a taxa rápida de $\mathcal{O}(\nicefrac1n)$, onde $n$ denota o número de pontos de dados fortemente rotulados. Essa aceleração pode ocorrer mesmo se, por si só, os dados fortemente rotulados admitirem apenas a taxa mais lenta de $\mathcal{O}(\nicefrac{1}{\sqrt{n}})$. A aceleração real depende continuamente do número de etiquetas fracas disponíveis e da relação entre as duas tarefas. Nossos resultados teóricos são refletidos empiricamente em uma variedade de tarefas e ilustram como as etiquetas fracas aceleram o aprendizado na tarefa forte."
8IMMUIHM,book,2022.0,"Tok, Wee-Hyong; Bahree, Amit; Filipi, Senja",Practical weak supervision: doing more with less data,,,,2022,O'Reilly,Supervisão fraca prática: fazendo mais com menos dados,nan
DD3V83B2,bookSection,2020.0,"Zhang, Minqing; Gao, Jiantao; Lyu, Zhen; Zhao, Weibing; Wang, Qin; Ding, Weizhen; Wang, Sheng; Li, Zhen; Cui, Shuguang",Characterizing Label Errors: Confident Learning for Noisy-Labeled Image Segmentation,,https://link.springer.com/10.1007/978-3-030-59710-8_70,,2020,Springer International Publishing,Caracterizando Erros de Rótulo: Aprendizado Confiante para Segmentação de Imagem com Rótulos Ruins,nan
Z4MB2WAC,journalArticle,2022.0,"Zhang, Jing",Knowledge Learning With Crowdsourcing: A Brief Review and Systematic Perspective,10.1109/JAS.2022.105434,,"Big data have the characteristics of enormous volume, high velocity, diversity, value-sparsity, and uncertainty, which lead the knowledge learning from them full of challenges. With the emergence of crowdsourcing, versatile information can be obtained on-demand so that the wisdom of crowds is easily involved to facilitate the knowledge learning process. During the past thirteen years, researchers in the AI community made great efforts to remove the obstacles in the field of learning from crowds. This concentrated survey paper comprehensively reviews the technical progress in crowdsourcing learning from a systematic perspective that includes three dimensions of data, models, and learning processes. In addition to reviewing existing important work, the paper places a particular emphasis on providing some promising blueprints on each dimension as well as discussing the lessons learned from our past research work, which will light up the way for new researchers and encourage them to pursue new contributions.",2022-05,,Aprendizado de Conhecimento com Crowdsourcing: Uma Breve Revisão e Perspectiva Sistemática,"Os grandes dados têm as características de um volume enorme, alta velocidade, diversidade, escassez de valor e incerteza, o que torna o aprendizado de conhecimento a partir deles cheio de desafios. Com o surgimento do crowdsourcing, informações versáteis podem ser obtidas sob demanda, de modo que a sabedoria das multidões é facilmente envolvida para facilitar o processo de aprendizado de conhecimento. Durante os últimos treze anos, pesquisadores da comunidade de IA fizeram grandes esforços para remover os obstáculos no campo do aprendizado a partir de multidões. Este artigo de pesquisa concentrado revisa de forma abrangente o progresso técnico no aprendizado por meio de crowdsourcing a partir de uma perspectiva sistemática que inclui três dimensões: dados, modelos e processos de aprendizado. Além de revisar trabalhos importantes existentes, o artigo coloca uma ênfase particular em fornecer alguns planos promissores em cada dimensão, bem como discutir as lições aprendidas com nosso trabalho de pesquisa anterior, que iluminará o caminho para novos pesquisadores e os incentivará a buscar novas contribuições."
3IZM6KAA,bookSection,2021.0,"Zhou, Zhi-Hua",Semi-Supervised Learning,,https://link.springer.com/10.1007/978-981-15-1967-3_13,,2021,Springer Singapore,Aprendizado Semi-Supervisionado,nan
QZJYKJ8F,conferencePaper,2021.0,"Yu, Yue; Zuo, Simiao; Jiang, Haoming; Ren, Wendi; Zhao, Tuo; Zhang, Chao",Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach,10.18653/v1/2021.naacl-main.84,https://aclanthology.org/2021.naacl-main.84,"Fine-tuned pre-trained language models (LMs) have achieved enormous success in many natural language processing (NLP) tasks, but they still require excessive labeled data in the fine-tuning stage. We study the problem of fine-tuning pre-trained LMs using only weak supervision, without any labeled data. This problem is challenging because the high capacity of LMs makes them prone to overfitting the noisy labels generated by weak supervision. To address this problem, we develop a contrastive self-training framework, COSINE, to enable fine-tuning LMs with weak supervision. Underpinned by contrastive regularization and confidence-based reweighting, our framework gradually improves model fitting while effectively suppressing error propagation. Experiments on sequence, token, and sentence pair classification tasks show that our model outperforms the strongest baseline by large margins and achieves competitive performance with fully-supervised fine-tuning methods. Our implementation is available on https://github.com/yueyu1030/COSINE.",2021-06,Association for Computational Linguistics,Ajuste Fino de Modelo de Linguagem Pré-treinado com Supervisão Fraca: Uma Abordagem de Auto-treinamento Regularizada por Contraste,"Modelos de linguagem (LMs) pré-treinados e ajustados finamente alcançaram um enorme sucesso em muitas tarefas de processamento de linguagem natural (NLP), mas ainda requerem dados rotulados excessivos na fase de ajuste fino. Estudamos o problema de ajustar finamente LMs pré-treinados usando apenas supervisão fraca, sem nenhum dado rotulado. Este problema é desafiador porque a alta capacidade dos LMs os torna propensos ao sobreajuste das etiquetas ruidosas geradas pela supervisão fraca. Para abordar esse problema, desenvolvemos uma estrutura de auto-treinamento contrastivo, COSINE, para permitir o ajuste fino de LMs com supervisão fraca. Fundamentada pela regularização contrastiva e reponderação baseada em confiança, nossa estrutura melhora gradualmente o ajuste do modelo enquanto suprime efetivamente a propagação de erros. Experimentos em tarefas de classificação de sequência, token e pares de sentenças mostram que nosso modelo supera a linha de base mais forte por grandes margens e alcança desempenho competitivo com métodos de ajuste fino totalmente supervisionados. Nossa implementação está disponível em https://github.com/yueyu1030/COSINE."
EJH2XBH3,preprint,2022.0,"Wei, Jiaheng; Liu, Hangyu; Liu, Tongliang; Niu, Gang; Sugiyama, Masashi; Liu, Yang",To Smooth or Not? When Label Smoothing Meets Noisy Labels,10.48550/arXiv.2106.04149,http://arxiv.org/abs/2106.04149,"Label smoothing (LS) is an arising learning paradigm that uses the positively weighted average of both the hard training labels and uniformly distributed soft labels. It was shown that LS serves as a regularizer for training data with hard labels and therefore improves the generalization of the model. Later it was reported LS even helps with improving robustness when learning with noisy labels. However, we observed that the advantage of LS vanishes when we operate in a high label noise regime. Intuitively speaking, this is due to the increased entropy of $\mathbb{P}(\text{noisy label}|X)$ when the noise rate is high, in which case, further applying LS tends to ""over-smooth"" the estimated posterior. We proceeded to discover that several learning-with-noisy-labels solutions in the literature instead relate more closely to negative/not label smoothing (NLS), which acts counter to LS and defines as using a negative weight to combine the hard and soft labels! We provide understandings for the properties of LS and NLS when learning with noisy labels. Among other established properties, we theoretically show NLS is considered more beneficial when the label noise rates are high. We provide extensive experimental results on multiple benchmarks to support our findings too. Code is publicly available at https://github.com/UCSC-REAL/negative-label-smoothing.",2022-06-24,arXiv,Suavizar ou Não? Quando a Suavização de Rótulos Encontra Rótulos Ruidosos,"A suavização de rótulos (LS) é um paradigma de aprendizado emergente que utiliza a média ponderada positivamente tanto dos rótulos de treinamento rígidos quanto dos rótulos suaves distribuídos uniformemente. Foi demonstrado que a LS serve como um regularizador para dados de treinamento com rótulos rígidos e, portanto, melhora a generalização do modelo. Mais tarde, foi relatado que a LS até ajuda a melhorar a robustez ao aprender com rótulos ruidosos. No entanto, observamos que a vantagem da LS desaparece quando operamos em um regime de alto ruído de rótulos. Intuitivamente, isso se deve ao aumento da entropia de $\mathbb{P}(\text{rótulo ruidoso}|X)$ quando a taxa de ruído é alta, caso em que a aplicação adicional da LS tende a ""suavizar demais"" a posterior estimada. Prosseguimos para descobrir que várias soluções de aprendizado com rótulos ruidosos na literatura se relacionam mais de perto com a suavização negativa/não de rótulos (NLS), que age em contraposição à LS e define como usar um peso negativo para combinar os rótulos rígidos e suaves! Fornecemos compreensões sobre as propriedades da LS e da NLS ao aprender com rótulos ruidosos. Entre outras propriedades estabelecidas, mostramos teoricamente que a NLS é considerada mais benéfica quando as taxas de ruído de rótulos são altas. Também fornecemos resultados experimentais extensivos em múltiplos benchmarks para apoiar nossas descobertas. O código está disponível publicamente em https://github.com/UCSC-REAL/negative-label-smoothing."
IQQVHU9V,journalArticle,2017.0,"Ratner, Alexander; Bach, Stephen H.; Ehrenberg, Henry; Fries, Jason; Wu, Sen; Ré, Christopher",Snorkel: Rapid Training Data Creation with Weak Supervision,10.14778/3157794.3157797,http://arxiv.org/abs/1711.10160,"Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a first-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research labs. In a user study, subject matter experts build models 2.8x faster and increase predictive performance an average 45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 1.8x speedup per pipeline execution. In two collaborations, with the U.S. Department of Veterans Affairs and the U.S. Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60% of the predictive performance of large hand-curated training sets.",2017-11,,Snorkel: Criação Rápida de Dados de Treinamento com Supervisão Fraca,"A rotulagem de dados de treinamento está se tornando cada vez mais o maior gargalo na implementação de sistemas de aprendizado de máquina. Apresentamos o Snorkel, um sistema pioneiro que permite aos usuários treinar modelos de ponta sem rotular manualmente nenhum dado de treinamento. Em vez disso, os usuários escrevem funções de rotulagem que expressam heurísticas arbitrárias, que podem ter precisões e correlações desconhecidas. O Snorkel remove o ruído de suas saídas sem acesso à verdade fundamental, incorporando a primeira implementação de ponta a ponta do nosso recente paradigma de aprendizado de máquina, programação de dados. Apresentamos uma camada de interface flexível para escrever funções de rotulagem com base em nossa experiência ao longo do último ano colaborando com empresas, agências e laboratórios de pesquisa. Em um estudo com usuários, especialistas em assuntos construíram modelos 2,8 vezes mais rápido e aumentaram o desempenho preditivo em média 45,5% em comparação com sete horas de rotulagem manual. Estudamos os trade-offs de modelagem neste novo cenário e propomos um otimizador para automatizar decisões de trade-off que proporciona até 1,8 vezes mais rapidez por execução de pipeline. Em duas colaborações, com o Departamento de Assuntos de Veteranos dos EUA e a Administração de Alimentos e Medicamentos dos EUA, e em quatro conjuntos de dados abertos de texto e imagem representativos de outras implementações, o Snorkel oferece melhorias médias de 132% no desempenho preditivo em relação a abordagens heurísticas anteriores e chega a uma média de 3,60% do desempenho preditivo de grandes conjuntos de dados de treinamento curados manualmente."
2GXT7DQV,preprint,2020.0,"Ma, Xingjun; Huang, Hanxun; Wang, Yisen; Romano, Simone; Erfani, Sarah; Bailey, James",Normalized Loss Functions for Deep Learning with Noisy Labels,10.48550/arXiv.2006.13554,http://arxiv.org/abs/2006.13554,"Robust loss functions are essential for training accurate deep neural networks (DNNs) in the presence of noisy (incorrect) labels. It has been shown that the commonly used Cross Entropy (CE) loss is not robust to noisy labels. Whilst new loss functions have been designed, they are only partially robust. In this paper, we theoretically show by applying a simple normalization that: any loss can be made robust to noisy labels. However, in practice, simply being robust is not sufficient for a loss function to train accurate DNNs. By investigating several robust loss functions, we find that they suffer from a problem of underfitting. To address this, we propose a framework to build robust loss functions called Active Passive Loss (APL). APL combines two robust loss functions that mutually boost each other. Experiments on benchmark datasets demonstrate that the family of new loss functions created by our APL framework can consistently outperform state-of-the-art methods by large margins, especially under large noise rates such as 60% or 80% incorrect labels.",2020-06-24,arXiv,Funções de Perda Normalizadas para Aprendizado Profundo com Rótulos Ruidosos,"Funções de perda robustas são essenciais para treinar redes neurais profundas (DNNs) precisas na presença de rótulos ruidosos (incorretos). Foi demonstrado que a função de perda de Entropia Cruzada (CE), comumente utilizada, não é robusta a rótulos ruidosos. Embora novas funções de perda tenham sido projetadas, elas são apenas parcialmente robustas. Neste artigo, mostramos teoricamente, aplicando uma normalização simples, que: qualquer perda pode ser tornada robusta a rótulos ruidosos. No entanto, na prática, simplesmente ser robusto não é suficiente para que uma função de perda treine DNNs precisas. Ao investigar várias funções de perda robustas, descobrimos que elas sofrem de um problema de subajuste. Para resolver isso, propomos uma estrutura para construir funções de perda robustas chamada Active Passive Loss (APL). APL combina duas funções de perda robustas que se impulsionam mutuamente. Experimentos em conjuntos de dados de referência demonstram que a família de novas funções de perda criada pela nossa estrutura APL pode consistentemente superar métodos de ponta por grandes margens, especialmente sob altas taxas de ruído, como 60% ou 80% de rótulos incorretos."
RBBRBHCP,preprint,2019.0,"Wang, Yisen; Ma, Xingjun; Chen, Zaiyi; Luo, Yuan; Yi, Jinfeng; Bailey, James",Symmetric Cross Entropy for Robust Learning with Noisy Labels,10.48550/arXiv.1908.06112,http://arxiv.org/abs/1908.06112,"Training accurate deep neural networks (DNNs) in the presence of noisy labels is an important and challenging task. Though a number of approaches have been proposed for learning with noisy labels, many open issues remain. In this paper, we show that DNN learning with Cross Entropy (CE) exhibits overfitting to noisy labels on some classes (""easy"" classes), but more surprisingly, it also suffers from significant under learning on some other classes (""hard"" classes). Intuitively, CE requires an extra term to facilitate learning of hard classes, and more importantly, this term should be noise tolerant, so as to avoid overfitting to noisy labels. Inspired by the symmetric KL-divergence, we propose the approach of \textbf{Symmetric cross entropy Learning} (SL), boosting CE symmetrically with a noise robust counterpart Reverse Cross Entropy (RCE). Our proposed SL approach simultaneously addresses both the under learning and overfitting problem of CE in the presence of noisy labels. We provide a theoretical analysis of SL and also empirically show, on a range of benchmark and real-world datasets, that SL outperforms state-of-the-art methods. We also show that SL can be easily incorporated into existing methods in order to further enhance their performance.",2019-08-16,arXiv,Entropia Cruzada Simétrica para Aprendizado Robusto com Rótulos Ruins,"Treinar redes neurais profundas (DNNs) precisas na presença de rótulos ruidosos é uma tarefa importante e desafiadora. Embora várias abordagens tenham sido propostas para aprender com rótulos ruidosos, muitas questões em aberto permanecem. Neste artigo, mostramos que o aprendizado de DNN com Entropia Cruzada (CE) apresenta sobreajuste a rótulos ruidosos em algumas classes (""classes fáceis""), mas, mais surpreendentemente, também sofre de subaprendizado significativo em algumas outras classes (""classes difíceis""). Intuitivamente, a CE requer um termo extra para facilitar o aprendizado de classes difíceis e, mais importante, esse termo deve ser tolerante ao ruído, a fim de evitar sobreajuste a rótulos ruidosos. Inspirados pela divergência KL simétrica, propomos a abordagem de \textbf{Aprendizado de Entropia Cruzada Simétrica} (SL), impulsionando a CE simetricamente com um contraparte robusto ao ruído, a Entropia Cruzada Reversa (RCE). Nossa abordagem SL proposta aborda simultaneamente tanto o problema de subaprendizado quanto o de sobreajuste da CE na presença de rótulos ruidosos. Fornecemos uma análise teórica do SL e também mostramos empiricamente, em uma variedade de conjuntos de dados de referência e do mundo real, que o SL supera métodos de última geração. Também mostramos que o SL pode ser facilmente incorporado em métodos existentes para melhorar ainda mais seu desempenho."
EIZG72RT,conferencePaper,2021.0,"Karamanolakis, Giannis; Mukherjee, Subhabrata (Subho); Zheng, Guoqing; Awadallah, Ahmed H.",Self-training with Weak Supervision,,https://www.microsoft.com/en-us/research/publication/self-training-weak-supervision-astra/,"State-of-the-art deep neural networks require large-scale labeled training data that is often expensive to obtain or not available for many tasks. Weak supervision in the form of domainspecific rules has been shown to be useful in such settings to automatically generate weakly labeled training data. However, learning with weak rules is challenging due to their inherent heuristic and noisy nature. An additional challenge is rule coverage and overlap, where prior work on weak supervision only considers instances that are covered by weak rules, thus leaving valuable unlabeled data behind. In this work, we develop a weak supervision framework (ASTRA) that leverages all the available data for a given task. To this end, we leverage task-specific unlabeled data through self-training with a model (student) that considers contextualized representations and predicts pseudo-labels for instances that may not be covered by weak rules. We further develop a rule attention network (teacher) that learns how to aggregate student pseudo-labels with weak rule labels, conditioned on their fidelity and the underlying context of an instance. Finally, we construct a semi-supervised learning objective for end-to-end training with unlabeled data, domain-specific rules, and a small amount of labeled data. Extensive experiments on six benchmark datasets for text classification demonstrate the effectiveness of our approach with significant improvements over state-of-the-art baselines.",2021-05,NAACL 2021,Auto-treinamento com Supervisão Fraca,"Redes neurais profundas de última geração requerem grandes volumes de dados de treinamento rotulados que muitas vezes são caros de obter ou não estão disponíveis para muitas tarefas. A supervisão fraca na forma de regras específicas de domínio tem se mostrado útil nesses contextos para gerar automaticamente dados de treinamento fracamente rotulados. No entanto, aprender com regras fracas é desafiador devido à sua natureza heurística e ruidosa. Um desafio adicional é a cobertura e sobreposição de regras, onde trabalhos anteriores sobre supervisão fraca consideram apenas instâncias que são cobertas por regras fracas, deixando assim dados não rotulados valiosos para trás. Neste trabalho, desenvolvemos uma estrutura de supervisão fraca (ASTRA) que aproveita todos os dados disponíveis para uma determinada tarefa. Para isso, utilizamos dados não rotulados específicos da tarefa por meio de auto-treinamento com um modelo (aluno) que considera representações contextualizadas e prevê pseudo-rótulos para instâncias que podem não estar cobertas por regras fracas. Além disso, desenvolvemos uma rede de atenção de regras (professor) que aprende a agregar pseudo-rótulos do aluno com rótulos de regras fracas, condicionados à sua fidelidade e ao contexto subjacente de uma instância. Finalmente, construímos um objetivo de aprendizado semi-supervisionado para treinamento de ponta a ponta com dados não rotulados, regras específicas de domínio e uma pequena quantidade de dados rotulados. Experimentos extensivos em seis conjuntos de dados de referência para classificação de texto demonstram a eficácia de nossa abordagem com melhorias significativas em relação a linhas de base de última geração."
MNSZCVY8,thesis,,"Northcutt, Curtis George",Confident Learning for Machines and Humans,,,"The coupling of machine intelligence and human intelligence has the potential to empower humans with augmented capabilities (e.g., improving rhyme-density while writing song lyrics, enhancing empathy via emotion detection, and personalizing learning in online courses). Unfortunately, humans operate in an uncertain world – where the performance of even the most sophisticated model-centric artificially intelligent system often depends on its data-centric ability to deal with the uncertainty in the labels upon which it is trained.",,,Aprendizado Confiante para Máquinas e Humanos,"A combinação da inteligência de máquina e da inteligência humana tem o potencial de capacitar os humanos com habilidades aumentadas (por exemplo, melhorar a densidade de rimas ao escrever letras de músicas, aumentar a empatia por meio da detecção de emoções e personalizar o aprendizado em cursos online). Infelizmente, os humanos operam em um mundo incerto – onde o desempenho até mesmo do sistema de inteligência artificial centrado em modelos mais sofisticados muitas vezes depende de sua capacidade centrada em dados de lidar com a incerteza nos rótulos sobre os quais é treinado."
NTU9DKG8,preprint,2022.0,"Goh, Hui Wen; Tkachenko, Ulyana; Mueller, Jonas",Utilizing supervised models to infer consensus labels and their quality from data with multiple annotators,10.48550/arXiv.2210.06812,http://arxiv.org/abs/2210.06812,"Real-world data for classification is often labeled by multiple annotators. For analyzing such data, we introduce CROWDLAB, a straightforward approach to estimate: (1) A consensus label for each example that aggregates the individual annotations (more accurately than aggregation via majority-vote or other algorithms used in crowdsourcing); (2) A confidence score for how likely each consensus label is correct (via well-calibrated estimates that account for the number of annotations for each example and their agreement, prediction-confidence from a trained classifier, and trustworthiness of each annotator vs. the classifier); (3) A rating for each annotator quantifying the overall correctness of their labels. While many algorithms have been proposed to estimate related quantities in crowdsourcing, these often rely on sophisticated generative models with iterative inference schemes, whereas CROWDLAB is based on simple weighted ensembling. Many algorithms also rely solely on annotator statistics, ignoring the features of the examples from which the annotations derive. CROWDLAB in contrast utilizes any classifier model trained on these features, which can generalize between examples with similar features. In evaluations on real-world multi-annotator image data, our proposed method provides superior estimates for (1)-(3) than many alternative algorithms.",2022-10-13,arXiv,Utilizando modelos supervisionados para inferir rótulos de consenso e sua qualidade a partir de dados com múltiplos anotadores.,"Dados do mundo real para classificação são frequentemente rotulados por múltiplos anotadores. Para analisar tais dados, introduzimos o CROWDLAB, uma abordagem simples para estimar: (1) Um rótulo de consenso para cada exemplo que agrega as anotações individuais (mais precisamente do que a agregação via voto majoritário ou outros algoritmos usados em crowdsourcing); (2) Uma pontuação de confiança sobre quão provável é que cada rótulo de consenso esteja correto (por meio de estimativas bem calibradas que levam em conta o número de anotações para cada exemplo e seu acordo, a confiança na previsão de um classificador treinado e a confiabilidade de cada anotador em relação ao classificador); (3) Uma classificação para cada anotador quantificando a correção geral de seus rótulos. Embora muitos algoritmos tenham sido propostos para estimar quantidades relacionadas em crowdsourcing, estes frequentemente dependem de modelos generativos sofisticados com esquemas de inferência iterativa, enquanto o CROWDLAB é baseado em um simples ensemble ponderado. Muitos algoritmos também se baseiam exclusivamente em estatísticas de anotadores, ignorando as características dos exemplos das quais as anotações derivam. O CROWDLAB, em contraste, utiliza qualquer modelo de classificador treinado nessas características, que pode generalizar entre exemplos com características semelhantes. Em avaliações de dados de imagem do mundo real com múltiplos anotadores, nosso método proposto fornece estimativas superiores para (1)-(3) do que muitos algoritmos alternativos."
WW2TDG6J,webpage,2023.0,,"Class Imbalance, Outliers, and Distribution Shift",,https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/,,2023-01-26,,"Desequilíbrio de Classe, Outliers e Mudança de Distribuição",nan
ED3PAS9Y,preprint,2021.0,"Coleman, Cody; Chou, Edward; Katz-Samuels, Julian; Culatana, Sean; Bailis, Peter; Berg, Alexander C.; Nowak, Robert; Sumbaly, Roshan; Zaharia, Matei; Yalniz, I. Zeki",Similarity Search for Efficient Active Learning and Search of Rare Concepts,10.48550/arXiv.2007.00077,http://arxiv.org/abs/2007.00077,"Many active learning and search approaches are intractable for large-scale industrial settings with billions of unlabeled examples. Existing approaches search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. In this paper, we improve the computational efficiency of active learning and search methods by restricting the candidate pool for labeling to the nearest neighbors of the currently labeled set instead of scanning over all of the unlabeled data. We evaluate several selection strategies in this setting on three large-scale computer vision datasets: ImageNet, OpenImages, and a de-identified and aggregated dataset of 10 billion images provided by a large internet company. Our approach achieved similar mean average precision and recall as the traditional global approach while reducing the computational cost of selection by up to three orders of magnitude, thus enabling web-scale active learning.",2021-07-22,arXiv,Busca de Similaridade para Aprendizado Ativo Eficiente e Busca de Conceitos Raros,"Muitos métodos de aprendizado ativo e busca são intratáveis para configurações industriais em larga escala com bilhões de exemplos não rotulados. Os métodos existentes buscam globalmente pelos exemplos ótimos a serem rotulados, escalando linear ou até quadraticamente com os dados não rotulados. Neste artigo, melhoramos a eficiência computacional dos métodos de aprendizado ativo e busca ao restringir o conjunto de candidatos para rotulagem aos vizinhos mais próximos do conjunto atualmente rotulado, em vez de escanear todos os dados não rotulados. Avaliamos várias estratégias de seleção nesse contexto em três conjuntos de dados de visão computacional em larga escala: ImageNet, OpenImages e um conjunto de dados desidentificado e agregado de 10 bilhões de imagens fornecido por uma grande empresa da internet. Nossa abordagem alcançou precisão média e recall semelhantes ao método global tradicional, enquanto reduziu o custo computacional da seleção em até três ordens de magnitude, permitindo assim o aprendizado ativo em escala web."
2UYE8P4G,preprint,2021.0,"Renggli, Cedric; Rimanic, Luka; Gürel, Nezihe Merve; Karlaš, Bojan; Wu, Wentao; Zhang, Ce",A Data Quality-Driven View of MLOps,10.48550/arXiv.2102.07750,http://arxiv.org/abs/2102.07750,"Developing machine learning models can be seen as a process similar to the one established for traditional software development. A key difference between the two lies in the strong dependency between the quality of a machine learning model and the quality of the data used to train or perform evaluations. In this work, we demonstrate how different aspects of data quality propagate through various stages of machine learning development. By performing a joint analysis of the impact of well-known data quality dimensions and the downstream machine learning process, we show that different components of a typical MLOps pipeline can be efficiently designed, providing both a technical and theoretical perspective.",2021-02-15,arXiv,Uma Visão de MLOps Orientada pela Qualidade dos Dados,"Desenvolver modelos de aprendizado de máquina pode ser visto como um processo semelhante ao estabelecido para o desenvolvimento de software tradicional. Uma diferença chave entre os dois reside na forte dependência entre a qualidade de um modelo de aprendizado de máquina e a qualidade dos dados utilizados para treinar ou realizar avaliações. Neste trabalho, demonstramos como diferentes aspectos da qualidade dos dados se propagam através de várias etapas do desenvolvimento de aprendizado de máquina. Ao realizar uma análise conjunta do impacto de dimensões de qualidade de dados bem conhecidas e do processo de aprendizado de máquina subsequente, mostramos que diferentes componentes de um pipeline típico de MLOps podem ser projetados de forma eficiente, fornecendo tanto uma perspectiva técnica quanto teórica."
WGNVBPDV,conferencePaper,2022.0,"Patel, Hima; Guttula, Shanmukha; Mittal, Ruhi Sharma; Manwani, Naresh; Berti-Equille, Laure; Manatkar, Abhijit","Advances in Exploratory Data Analysis, Visualisation and Quality for Data Centric AI Systems",10.1145/3534678.3542604,https://doi.org/10.1145/3534678.3542604,"It is widely accepted that data preparation is one of the most time-consuming steps of the machine learning (ML) lifecycle. It is also one of the most important steps, as the quality of data directly influences the quality of a model. In this tutorial, we will discuss the importance and the role of exploratory data analysis (EDA) and data visualisation techniques to find data quality issues and for data preparation, relevant to building ML pipelines. We will also discuss the latest advances in these fields and bring out areas that need innovation. To make the tutorial actionable for practitioners, we will also discuss the most popular open-source packages that one can get started with along with their strengths and weaknesses. Finally, we will discuss on the challenges posed by industry workloads and the gaps to be addressed to make data-centric AI real in industry settings.",2022-08-14,Association for Computing Machinery,"Avanços em Análise Exploratória de Dados, Visualização e Qualidade para Sistemas de IA Centrada em Dados","É amplamente aceito que a preparação de dados é uma das etapas mais demoradas do ciclo de vida do aprendizado de máquina (ML). Também é uma das etapas mais importantes, pois a qualidade dos dados influencia diretamente a qualidade de um modelo. Neste tutorial, discutiremos a importância e o papel da análise exploratória de dados (EDA) e das técnicas de visualização de dados para encontrar problemas de qualidade dos dados e para a preparação de dados, relevantes para a construção de pipelines de ML. Também discutiremos os últimos avanços nesses campos e destacaremos áreas que precisam de inovação. Para tornar o tutorial acionável para os profissionais, também discutiremos os pacotes de código aberto mais populares com os quais se pode começar, juntamente com seus pontos fortes e fracos. Por fim, discutiremos os desafios impostos pelas cargas de trabalho da indústria e as lacunas a serem abordadas para tornar a IA centrada em dados uma realidade em ambientes industriais."
TMVYZ67W,book,,"Monarch, Robert; Manning, Christopher D.",Human-in-the-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI,,,,,,Aprendizado de Máquina com o Humano no Processo: Aprendizado Ativo e Anotação para IA Centrada no Humano,nan
2PS3BWL8,journalArticle,,"Chen, Mayee; Sala, Frederic; Re, Chris",Lecture Notes on Weak Supervision,,,,,,Notas de Aula sobre Supervisão Fraca,nan
H486FBBX,preprint,2022.0,"Narayan, Avanika; Chami, Ines; Orr, Laurel; Arora, Simran; Ré, Christopher",Can Foundation Models Wrangle Your Data?,,http://arxiv.org/abs/2205.09911,"Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast five data cleaning and integration tasks as prompting tasks and evaluate the performance of FMs on these tasks. We find that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks. We identify specific research challenges and opportunities that these models present, including challenges with private and domain specific data, and opportunities to make data management systems more accessible to non-experts. We make our code and experiments publicly available at: https://github.com/HazyResearch/fm_data_tasks.",2022-12-24,arXiv,Modelos de Fundação Podem Manipular Seus Dados?,"Modelos de Fundação (FMs) são modelos treinados em grandes corpora de dados que, em escala muito grande, podem generalizar para novas tarefas sem qualquer ajuste específico para a tarefa. À medida que esses modelos continuam a crescer em tamanho, inovações continuam a expandir os limites do que esses modelos podem fazer em tarefas de linguagem e imagem. Este artigo tem como objetivo entender uma área pouco explorada dos FMs: tarefas clássicas de dados, como limpeza e integração. Como prova de conceito, apresentamos cinco tarefas de limpeza e integração de dados como tarefas de solicitação e avaliamos o desempenho dos FMs nessas tarefas. Descobrimos que grandes FMs generalizam e alcançam desempenho de estado da arte em tarefas de limpeza e integração de dados, mesmo não tendo sido treinados para essas tarefas de dados. Identificamos desafios e oportunidades específicas de pesquisa que esses modelos apresentam, incluindo desafios com dados privados e específicos de domínio, e oportunidades para tornar os sistemas de gerenciamento de dados mais acessíveis para não especialistas. Tornamos nosso código e experimentos disponíveis publicamente em: https://github.com/HazyResearch/fm_data_tasks."
LPFICFMS,preprint,2022.0,"Lang, Hunter; Vijayaraghavan, Aravindan; Sontag, David",Training Subset Selection for Weak Supervision,,http://arxiv.org/abs/2206.02914,"Existing weak supervision approaches use all the data covered by weak signals to train a classifier. We show both theoretically and empirically that this is not always optimal. Intuitively, there is a tradeoff between the amount of weakly-labeled data and the precision of the weak labels. We explore this tradeoff by combining pretrained data representations with the cut statistic (Muhlenbach et al., 2004) to select (hopefully) high-quality subsets of the weakly-labeled training data. Subset selection applies to any label model and classifier and is very simple to plug in to existing weak supervision pipelines, requiring just a few lines of code. We show our subset selection method improves the performance of weak supervision for a wide range of label models, classifiers, and datasets. Using less weakly-labeled data improves the accuracy of weak supervision pipelines by up to 19% (absolute) on benchmark tasks.",2022-06-06,arXiv,Seleção de Subconjunto de Treinamento para Supervisão Fraca,"As abordagens existentes de supervisão fraca utilizam todos os dados cobertos por sinais fracos para treinar um classificador. Mostramos, tanto teoricamente quanto empiricamente, que isso nem sempre é ideal. Intuitivamente, há um trade-off entre a quantidade de dados fracamente rotulados e a precisão das etiquetas fracas. Exploramos esse trade-off combinando representações de dados pré-treinadas com a estatística de corte (Muhlenbach et al., 2004) para selecionar (esperançosamente) subconjuntos de alta qualidade dos dados de treinamento fracamente rotulados. A seleção de subconjuntos se aplica a qualquer modelo de etiqueta e classificador e é muito simples de integrar em pipelines de supervisão fraca existentes, exigindo apenas algumas linhas de código. Mostramos que nosso método de seleção de subconjuntos melhora o desempenho da supervisão fraca para uma ampla gama de modelos de etiqueta, classificadores e conjuntos de dados. Usar menos dados fracamente rotulados melhora a precisão dos pipelines de supervisão fraca em até 19% (absoluto) em tarefas de referência."
WBE9X79K,preprint,2022.0,"Vishwakarma, Harit; Roberts, Nicholas; Sala, Frederic",Lifting Weak Supervision To Structured Prediction,,http://arxiv.org/abs/2211.13375,"Weak supervision (WS) is a rich set of techniques that produce pseudolabels by aggregating easily obtained but potentially noisy label estimates from a variety of sources. WS is theoretically well understood for binary classification, where simple approaches enable consistent estimation of pseudolabel noise rates. Using this result, it has been shown that downstream models trained on the pseudolabels have generalization guarantees nearly identical to those trained on clean labels. While this is exciting, users often wish to use WS for structured prediction, where the output space consists of more than a binary or multi-class label set: e.g. rankings, graphs, manifolds, and more. Do the favorable theoretical properties of WS for binary classification lift to this setting? We answer this question in the affirmative for a wide range of scenarios. For labels taking values in a finite metric space, we introduce techniques new to weak supervision based on pseudo-Euclidean embeddings and tensor decompositions, providing a nearly-consistent noise rate estimator. For labels in constant-curvature Riemannian manifolds, we introduce new invariants that also yield consistent noise rate estimation. In both cases, when using the resulting pseudolabels in concert with a flexible downstream model, we obtain generalization guarantees nearly identical to those for models trained on clean data. Several of our results, which can be viewed as robustness guarantees in structured prediction with noisy labels, may be of independent interest. Empirical evaluation validates our claims and shows the merits of the proposed method.",2022-11-23,arXiv,Elevando a Supervisão Fraca para Predição Estruturada,"A supervisão fraca (WS) é um conjunto rico de técnicas que produzem pseudorótulos ao agregar estimativas de rótulos facilmente obtidas, mas potencialmente ruidosas, de uma variedade de fontes. A WS é teoricamente bem compreendida para classificação binária, onde abordagens simples permitem a estimativa consistente das taxas de ruído dos pseudorótulos. Usando esse resultado, foi demonstrado que modelos subsequentes treinados com os pseudorótulos têm garantias de generalização quase idênticas àquelas treinadas com rótulos limpos. Embora isso seja empolgante, os usuários muitas vezes desejam usar a WS para predição estruturada, onde o espaço de saída consiste em mais do que um conjunto de rótulos binários ou multiclasses: por exemplo, rankings, gráficos, variedades e mais. As propriedades teóricas favoráveis da WS para classificação binária se aplicam a esse contexto? Respondemos a essa pergunta de forma afirmativa para uma ampla gama de cenários. Para rótulos que assumem valores em um espaço métrico finito, introduzimos técnicas novas para supervisão fraca baseadas em incorporações pseudo-euclidianas e decomposições tensorais, fornecendo um estimador de taxa de ruído quase consistente. Para rótulos em variedades riemannianas de curvatura constante, introduzimos novos invariantes que também proporcionam uma estimativa consistente da taxa de ruído. Em ambos os casos, ao usar os pseudorótulos resultantes em conjunto com um modelo flexível subsequente, obtemos garantias de generalização quase idênticas àquelas para modelos treinados com dados limpos. Vários de nossos resultados, que podem ser vistos como garantias de robustez na predição estruturada com rótulos ruidosos, podem ser de interesse independente. A avaliação empírica valida nossas afirmações e mostra os méritos do método proposto."
CU7B75YS,preprint,2022.0,"Shin, Changho; Li, Winfred; Vishwakarma, Harit; Roberts, Nicholas; Sala, Frederic",Universalizing Weak Supervision,,http://arxiv.org/abs/2112.03865,"Weak supervision (WS) frameworks are a popular way to bypass hand-labeling large datasets for training data-hungry models. These approaches synthesize multiple noisy but cheaply-acquired estimates of labels into a set of high-quality pseudolabels for downstream training. However, the synthesis technique is specific to a particular kind of label, such as binary labels or sequences, and each new label type requires manually designing a new synthesis algorithm. Instead, we propose a universal technique that enables weak supervision over any label type while still offering desirable properties, including practical flexibility, computational efficiency, and theoretical guarantees. We apply this technique to important problems previously not tackled by WS frameworks including learning to rank, regression, and learning in hyperbolic space. Theoretically, our synthesis approach produces a consistent estimators for learning some challenging but important generalizations of the exponential family model. Experimentally, we validate our framework and show improvement over baselines in diverse settings including real-world learning-to-rank and regression problems along with learning on hyperbolic manifolds.",2022-03-17,arXiv,Universalizando a Supervisão Fraca,"As estruturas de supervisão fraca (WS) são uma maneira popular de contornar a rotulagem manual de grandes conjuntos de dados para treinar modelos que consomem muitos dados. Essas abordagens sintetizam múltiplas estimativas ruidosas, mas adquiridas de forma barata, de rótulos em um conjunto de pseudorótulos de alta qualidade para treinamento posterior. No entanto, a técnica de síntese é específica para um determinado tipo de rótulo, como rótulos binários ou sequências, e cada novo tipo de rótulo requer o design manual de um novo algoritmo de síntese. Em vez disso, propomos uma técnica universal que permite a supervisão fraca sobre qualquer tipo de rótulo, enquanto ainda oferece propriedades desejáveis, incluindo flexibilidade prática, eficiência computacional e garantias teóricas. Aplicamos essa técnica a problemas importantes que anteriormente não foram abordados por estruturas WS, incluindo aprendizado de classificação, regressão e aprendizado em espaço hiperbólico. Teoricamente, nossa abordagem de síntese produz estimadores consistentes para aprender algumas generalizações desafiadoras, mas importantes, do modelo da família exponencial. Experimentalmente, validamos nossa estrutura e mostramos melhorias em relação às linhas de base em configurações diversas, incluindo problemas de aprendizado de classificação e regressão do mundo real, juntamente com aprendizado em variedades hiperbólicas."
N2UAW9BW,preprint,2022.0,"Vishwakarma, Harit; Lin, Heguang; Sala, Frederic; Vinayak, Ramya Korlakai",Good Data from Bad Models : Foundations of Threshold-based Auto-labeling,,http://arxiv.org/abs/2211.12620,"Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Auto-labeling systems are a promising way to reduce reliance on manual labeling for dataset construction. Threshold-based auto-labeling, where validation data obtained from humans is used to find a threshold for confidence above which the data is machine-labeled, is emerging as a popular solution used widely in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. In this work, we analyze threshold-based auto-labeling systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two insights. First, reasonable chunks of the unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of threshold-based auto-labeling systems is potentially prohibitive validation data usage. Together, these insights describe the promise and pitfalls of using such systems. We validate our theoretical guarantees with simulations and study the efficacy of threshold-based auto-labeling on real datasets.",2022-11-22,arXiv,Dados Bons de Modelos Ruins: Fundamentos da Autoetiquetagem Baseada em Limiares,"Criar conjuntos de dados rotulados de alta qualidade em larga escala é um grande gargalo nos fluxos de trabalho de aprendizado de máquina supervisionado. Sistemas de auto-rotulagem são uma maneira promissora de reduzir a dependência da rotulagem manual para a construção de conjuntos de dados. A auto-rotulagem baseada em limiar, onde dados de validação obtidos de humanos são usados para encontrar um limiar de confiança acima do qual os dados são rotulados por máquina, está emergindo como uma solução popular amplamente utilizada na prática. Dada a longa vida útil e o uso diversificado dos conjuntos de dados resultantes, entender quando os dados obtidos por tais sistemas de auto-rotulagem podem ser confiáveis é crucial. Neste trabalho, analisamos sistemas de auto-rotulagem baseados em limiar e derivamos limites de complexidade de amostra sobre a quantidade de dados de validação rotulados por humanos necessários para garantir a qualidade dos dados rotulados por máquina. Nossos resultados fornecem duas percepções. Primeiro, blocos razoáveis de dados não rotulados podem ser rotulados automaticamente e com precisão por modelos aparentemente ruins. Segundo, um lado oculto dos sistemas de auto-rotulagem baseados em limiar é o uso potencialmente proibitivo de dados de validação. Juntas, essas percepções descrevem a promessa e as armadilhas do uso de tais sistemas. Validamos nossas garantias teóricas com simulações e estudamos a eficácia da auto-rotulagem baseada em limiar em conjuntos de dados reais."
P247PN5H,conferencePaper,2022.0,"Kwon, Yongchan; Zou, James",Beta Shapley: a Unified and Noise-reduced Data Valuation Framework for Machine Learning,,https://proceedings.mlr.press/v151/kwon22a.html,"Data Shapley has recently been proposed as a principled framework to quantify the contribution of individual datum in machine learning. It can effectively identify helpful or harmful data points for a learning algorithm. In this paper, we propose Beta Shapley, which is a substantial generalization of Data Shapley. Beta Shapley arises naturally by relaxing the efficiency axiom of the Shapley value, which is not critical for machine learning settings. Beta Shapley unifies several popular data valuation methods and includes data Shapley as a special case. Moreover, we prove that Beta Shapley has several desirable statistical properties and propose efficient algorithms to estimate it. We demonstrate that Beta Shapley outperforms state-of-the-art data valuation methods on several downstream ML tasks such as: 1) detecting mislabeled training data; 2) learning with subsamples; and 3) identifying points whose addition or removal have the largest positive or negative impact on the model.",2022-05-03,PMLR,Beta Shapley: uma Estrutura Unificada e Reduzida de Ruído para Valoração de Dados em Aprendizado de Máquina,"Data Shapley foi recentemente proposto como uma estrutura fundamentada para quantificar a contribuição de dados individuais em aprendizado de máquina. Ele pode identificar efetivamente pontos de dados úteis ou prejudiciais para um algoritmo de aprendizado. Neste artigo, propomos o Beta Shapley, que é uma generalização substancial do Data Shapley. O Beta Shapley surge naturalmente ao relaxar o axioma de eficiência do valor de Shapley, que não é crítico para configurações de aprendizado de máquina. O Beta Shapley unifica vários métodos populares de avaliação de dados e inclui o Data Shapley como um caso especial. Além disso, provamos que o Beta Shapley possui várias propriedades estatísticas desejáveis e propomos algoritmos eficientes para estimá-lo. Demonstramos que o Beta Shapley supera métodos de avaliação de dados de ponta em várias tarefas de ML subsequentes, como: 1) detectar dados de treinamento rotulados incorretamente; 2) aprender com subsamples; e 3) identificar pontos cuja adição ou remoção tenha o maior impacto positivo ou negativo no modelo."
YCCPZ8WW,preprint,2022.0,"Klie, Jan-Christoph; Webber, Bonnie; Gurevych, Iryna",Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future,10.48550/arXiv.2206.02280,http://arxiv.org/abs/2206.02280,"Annotated data is an essential ingredient in natural language processing for training and evaluating machine learning models. It is therefore very desirable for the annotations to be of high quality. Recent work, however, has shown that several popular datasets contain a surprising amount of annotation errors or inconsistencies. To alleviate this issue, many methods for annotation error detection have been devised over the years. While researchers show that their approaches work well on their newly introduced datasets, they rarely compare their methods to previous work or on the same datasets. This raises strong concerns on methods' general performance and makes it difficult to asses their strengths and weaknesses. We therefore reimplement 18 methods for detecting potential annotation errors and evaluate them on 9 English datasets for text classification as well as token and span labeling. In addition, we define a uniform evaluation setup including a new formalization of the annotation error detection task, evaluation protocol and general best practices. To facilitate future research and reproducibility, we release our datasets and implementations in an easy-to-use and open source software package.",2022-09-25,arXiv,Detecção de Erros de Anotação: Analisando o Passado e o Presente para um Futuro Mais Coerente,"Dados anotados são um ingrediente essencial no processamento de linguagem natural para treinar e avaliar modelos de aprendizado de máquina. Portanto, é muito desejável que as anotações sejam de alta qualidade. No entanto, trabalhos recentes mostraram que vários conjuntos de dados populares contêm uma quantidade surpreendente de erros ou inconsistências nas anotações. Para aliviar esse problema, muitos métodos para detecção de erros de anotação foram desenvolvidos ao longo dos anos. Embora os pesquisadores demonstrem que suas abordagens funcionam bem em seus conjuntos de dados recém-introduzidos, raramente comparam seus métodos com trabalhos anteriores ou nos mesmos conjuntos de dados. Isso levanta fortes preocupações sobre o desempenho geral dos métodos e torna difícil avaliar seus pontos fortes e fracos. Portanto, reimplementamos 18 métodos para detectar potenciais erros de anotação e os avaliamos em 9 conjuntos de dados em inglês para classificação de texto, bem como rotulagem de tokens e spans. Além disso, definimos uma configuração de avaliação uniforme, incluindo uma nova formalização da tarefa de detecção de erros de anotação, protocolo de avaliação e melhores práticas gerais. Para facilitar pesquisas futuras e reprodutibilidade, liberamos nossos conjuntos de dados e implementações em um pacote de software de código aberto e fácil de usar."
BIASX3JC,journalArticle,1988.0,"Angluin, Dana; Laird, Philip",Learning from noisy examples,10.1007/BF00116829,http://link.springer.com/10.1007/BF00116829,"The basic question addressed in this paper is: how can a learning algorithm cope with incorrect training examples? Specifically, how can algorithms that produce an ""approximately correct"" identification with ""high probability"" for reliable data be adapted to handle noisy data? We show that when the teacher may make independent random errors in classifying the example data, the strategy of selecting the most consistent rule for the sample is sufficient, and usually requires a feasibly small number of examples, provided noise affects less than half the examples on average. In this setting we are able to estimate the rate of noise using only the knowledge that the rate is less than one half. The basic ideas extend to other types of random noise as well. We also show that the search problem associated with this strategy is intractable in general. However, for particular classes of rules the target rule may be efficiently identified if we use techniques specific to that class. For an important class of formulas - the k-CNF formulas studied by Valiant - we present a polynomial-time algorithm that identifies concepts in this form when the rate of classification errors is less than one half.",1988-04,,Aprendendo com exemplos ruidosos,"A questão básica abordada neste artigo é: como um algoritmo de aprendizado pode lidar com exemplos de treinamento incorretos? Especificamente, como os algoritmos que produzem uma identificação ""aproximadamente correta"" com ""alta probabilidade"" para dados confiáveis podem ser adaptados para lidar com dados ruidosos? Mostramos que, quando o professor pode cometer erros aleatórios independentes na classificação dos dados de exemplo, a estratégia de selecionar a regra mais consistente para a amostra é suficiente e geralmente requer um número viavelmente pequeno de exemplos, desde que o ruído afete menos da metade dos exemplos em média. Nesse contexto, somos capazes de estimar a taxa de ruído usando apenas o conhecimento de que a taxa é inferior a um meio. As ideias básicas se estendem a outros tipos de ruído aleatório também. Também mostramos que o problema de busca associado a essa estratégia é intratável em geral. No entanto, para classes particulares de regras, a regra alvo pode ser identificada de forma eficiente se usarmos técnicas específicas para essa classe. Para uma classe importante de fórmulas - as fórmulas k-CNF estudadas por Valiant - apresentamos um algoritmo em tempo polinomial que identifica conceitos nessa forma quando a taxa de erros de classificação é inferior a um meio."
AXZ74RP5,conferencePaper,2019.0,"Ménard, Pierre André; Mougeot, Antoine",Turning silver into gold: error-focused corpus reannotation with active learning,10.26615/978-954-452-056-4_088,https://aclanthology.org/R19-1088,"While high quality gold standard annotated corpora are crucial for most tasks in natural language processing, many annotated corpora published in recent years, created by annotators or tools, contains noisy annotations. These corpora can be viewed as more silver than gold standards, even if they are used in evaluation campaigns or to compare systems' performances. As upgrading a silver corpus to gold level is still a challenge, we explore the application of active learning techniques to detect errors using four datasets designed for document classification and part-of-speech tagging. Our results show that the proposed method for the seeding step improves the chance of finding incorrect annotations by a factor of 2.73 when compared to random selection, a 14.71% increase from the baseline methods. Our query method provides an increase in the error detection precision on average by a factor of 1.78 against random selection, an increase of 61.82% compared to other query approaches.",2019-09,INCOMA Ltd.,Transformando prata em ouro: reanotação de corpus focada em erros com aprendizado ativo,"Embora corpora anotados de alta qualidade e padrão ouro sejam cruciais para a maioria das tarefas em processamento de linguagem natural, muitos corpora anotados publicados nos últimos anos, criados por anotadores ou ferramentas, contêm anotações ruidosas. Esses corpora podem ser vistos como mais prata do que padrões ouro, mesmo que sejam usados em campanhas de avaliação ou para comparar o desempenho de sistemas. Como atualizar um corpus prata para o nível ouro ainda é um desafio, exploramos a aplicação de técnicas de aprendizado ativo para detectar erros usando quatro conjuntos de dados projetados para classificação de documentos e etiquetagem de partes do discurso. Nossos resultados mostram que o método proposto para a etapa de semeadura melhora a chance de encontrar anotações incorretas em um fator de 2,73 quando comparado à seleção aleatória, um aumento de 14,71% em relação aos métodos de linha de base. Nosso método de consulta proporciona um aumento na precisão da detecção de erros, em média, em um fator de 1,78 em relação à seleção aleatória, um aumento de 61,82% em comparação com outras abordagens de consulta."
TBU35FV7,conferencePaper,2014.0,"Rehbein, Ines",POS error detection in automatically annotated corpora,10.3115/v1/W14-4903,https://aclanthology.org/W14-4903,,2014-08,Association for Computational Linguistics and Dublin City University,Detecção de erros de POS em corpora anotados automaticamente,nan
RTH8URBK,conferencePaper,2000.0,"van Halteren, Hans",The Detection of Inconsistency in Manually Tagged Text,,https://aclanthology.org/W00-1907,,2000-08,International Committee on Computational Linguistics,A Detecção de Inconsistência em Texto Marcado Manualmente,nan
MVDYD5XZ,preprint,2023.0,"Goh, Hui Wen; Tkachenko, Ulyana; Mueller, Jonas",CROWDLAB: Supervised learning to infer consensus labels and quality scores for data with multiple annotators,10.48550/arXiv.2210.06812,http://arxiv.org/abs/2210.06812,"Real-world data for classification is often labeled by multiple annotators. For analyzing such data, we introduce CROWDLAB, a straightforward approach to utilize any trained classifier to estimate: (1) A consensus label for each example that aggregates the available annotations; (2) A confidence score for how likely each consensus label is correct; (3) A rating for each annotator quantifying the overall correctness of their labels. Existing algorithms to estimate related quantities in crowdsourcing often rely on sophisticated generative models with iterative inference. CROWDLAB instead uses a straightforward weighted ensemble. Existing algorithms often rely solely on annotator statistics, ignoring the features of the examples from which the annotations derive. CROWDLAB utilizes any classifier model trained on these features, and can thus better generalize between examples with similar features. On real-world multi-annotator image data, our proposed method provides superior estimates for (1)-(3) than existing algorithms like Dawid-Skene/GLAD.",2023-01-27,arXiv,CROWDLAB: Aprendizado supervisionado para inferir rótulos de consenso e pontuações de qualidade para dados com múltiplos anotadores,"Dados do mundo real para classificação são frequentemente rotulados por múltiplos anotadores. Para analisar tais dados, introduzimos o CROWDLAB, uma abordagem simples para utilizar qualquer classificador treinado para estimar: (1) Um rótulo de consenso para cada exemplo que agrega as anotações disponíveis; (2) Uma pontuação de confiança sobre quão provável é que cada rótulo de consenso esteja correto; (3) Uma avaliação para cada anotador quantificando a correção geral de seus rótulos. Algoritmos existentes para estimar quantidades relacionadas em crowdsourcing frequentemente dependem de modelos generativos sofisticados com inferência iterativa. O CROWDLAB, por sua vez, utiliza um ensemble ponderado simples. Algoritmos existentes muitas vezes se baseiam apenas em estatísticas de anotadores, ignorando as características dos exemplos dos quais as anotações derivam. O CROWDLAB utiliza qualquer modelo de classificador treinado nessas características e, assim, pode generalizar melhor entre exemplos com características semelhantes. Em dados de imagem do mundo real com múltiplos anotadores, nosso método proposto fornece estimativas superiores para (1)-(3) em comparação com algoritmos existentes como Dawid-Skene/GLAD."
BEPRBUPN,preprint,2022.0,"Wang, Jiaxi; Wu, Ji; Huang, Lei",Understanding the Failure of Batch Normalization for Transformers in NLP,10.48550/arXiv.2210.05153,http://arxiv.org/abs/2210.05153,"Batch Normalization (BN) is a core and prevalent technique in accelerating the training of deep neural networks and improving the generalization on Computer Vision (CV) tasks. However, it fails to defend its position in Natural Language Processing (NLP), which is dominated by Layer Normalization (LN). In this paper, we are trying to answer why BN usually performs worse than LN in NLP tasks with Transformer models. We find that the inconsistency between training and inference of BN is the leading cause that results in the failure of BN in NLP. We define Training Inference Discrepancy (TID) to quantitatively measure this inconsistency and reveal that TID can indicate BN's performance, supported by extensive experiments, including image classification, neural machine translation, language modeling, sequence labeling, and text classification tasks. We find that BN can obtain much better test performance than LN when TID keeps small through training. To suppress the explosion of TID, we propose Regularized BN (RBN) that adds a simple regularization term to narrow the gap between batch statistics and population statistics of BN. RBN improves the performance of BN consistently and outperforms or is on par with LN on 17 out of 20 settings, involving ten datasets and two common variants of Transformer Our code is available at https://github.com/wjxts/RegularizedBN.",2022-10-11,,Compreendendo a Falha da Normalização em Lote para Transformers em PNL,"A Normalização em Lote (BN) é uma técnica central e prevalente na aceleração do treinamento de redes neurais profundas e na melhoria da generalização em tarefas de Visão Computacional (CV). No entanto, ela não consegue defender sua posição em Processamento de Linguagem Natural (NLP), que é dominado pela Normalização de Camada (LN). Neste artigo, tentamos responder por que a BN geralmente apresenta desempenho inferior ao da LN em tarefas de NLP com modelos Transformer. Descobrimos que a inconsistência entre o treinamento e a inferência da BN é a principal causa que resulta na falha da BN em NLP. Definimos a Discrepância de Inferência de Treinamento (TID) para medir quantitativamente essa inconsistência e revelamos que a TID pode indicar o desempenho da BN, apoiados por experimentos extensivos, incluindo classificação de imagens, tradução automática neural, modelagem de linguagem, rotulagem de sequência e tarefas de classificação de texto. Descobrimos que a BN pode obter um desempenho de teste muito melhor do que a LN quando a TID permanece pequena durante o treinamento. Para suprimir a explosão da TID, propomos a BN Regularizada (RBN), que adiciona um termo de regularização simples para reduzir a diferença entre as estatísticas de lote e as estatísticas populacionais da BN. A RBN melhora consistentemente o desempenho da BN e supera ou está à altura da LN em 17 de 20 configurações, envolvendo dez conjuntos de dados e duas variantes comuns do Transformer. Nosso código está disponível em https://github.com/wjxts/RegularizedBN."
W9DUB2CN,preprint,2022.0,"Roberts, Nicholas; Li, Xintong; Huang, Tzu-Heng; Adila, Dyah; Schoenberg, Spencer; Liu, Cheng-Yu; Pick, Lauren; Ma, Haotian; Albarghouthi, Aws; Sala, Frederic",AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels,10.48550/arXiv.2208.14362,http://arxiv.org/abs/2208.14362,"Weak supervision (WS) is a powerful method to build labeled datasets for training supervised models in the face of little-to-no labeled data. It replaces hand-labeling data with aggregating multiple noisy-but-cheap label estimates expressed by labeling functions (LFs). While it has been used successfully in many domains, weak supervision's application scope is limited by the difficulty of constructing labeling functions for domains with complex or high-dimensional features. To address this, a handful of methods have proposed automating the LF design process using a small set of ground truth labels. In this work, we introduce AutoWS-Bench-101: a framework for evaluating automated WS (AutoWS) techniques in challenging WS settings -- a set of diverse application domains on which it has been previously difficult or impossible to apply traditional WS techniques. While AutoWS is a promising direction toward expanding the application-scope of WS, the emergence of powerful methods such as zero-shot foundation models reveals the need to understand how AutoWS techniques compare or cooperate with modern zero-shot or few-shot learners. This informs the central question of AutoWS-Bench-101: given an initial set of 100 labels for each task, we ask whether a practitioner should use an AutoWS method to generate additional labels or use some simpler baseline, such as zero-shot predictions from a foundation model or supervised learning. We observe that in many settings, it is necessary for AutoWS methods to incorporate signal from foundation models if they are to outperform simple few-shot baselines, and AutoWS-Bench-101 promotes future research in this direction. We conclude with a thorough ablation study of AutoWS methods.",2022-08-30,arXiv,AutoWS-Bench-101: Avaliação da Supervisão Fraca Automatizada com 100 Rótulos,"A supervisão fraca (WS) é um método poderoso para construir conjuntos de dados rotulados para treinar modelos supervisionados diante de poucos ou nenhum dado rotulado. Ela substitui a rotulagem manual de dados pela agregação de múltiplas estimativas de rótulos ruidosas, mas baratas, expressas por funções de rotulagem (LFs). Embora tenha sido utilizada com sucesso em muitos domínios, o escopo de aplicação da supervisão fraca é limitado pela dificuldade de construir funções de rotulagem para domínios com características complexas ou de alta dimensão. Para abordar isso, um punhado de métodos propôs automatizar o processo de design de LFs usando um pequeno conjunto de rótulos de verdade de base. Neste trabalho, introduzimos o AutoWS-Bench-101: uma estrutura para avaliar técnicas de WS automatizada (AutoWS) em configurações desafiadoras de WS - um conjunto de domínios de aplicação diversos nos quais anteriormente era difícil ou impossível aplicar técnicas tradicionais de WS. Embora o AutoWS seja uma direção promissora para expandir o escopo de aplicação da WS, o surgimento de métodos poderosos, como modelos de fundação zero-shot, revela a necessidade de entender como as técnicas de AutoWS se comparam ou cooperam com aprendizes modernos zero-shot ou few-shot. Isso informa a questão central do AutoWS-Bench-101: dado um conjunto inicial de 100 rótulos para cada tarefa, perguntamos se um praticante deve usar um método de AutoWS para gerar rótulos adicionais ou usar alguma linha de base mais simples, como previsões zero-shot de um modelo de fundação ou aprendizado supervisionado. Observamos que em muitos contextos, é necessário que os métodos de AutoWS incorporem sinal de modelos de fundação se desejarem superar linhas de base simples de few-shot, e o AutoWS-Bench-101 promove futuras pesquisas nessa direção. Concluímos com um estudo de ablação minucioso dos métodos de AutoWS."
LEV8BIZ6,conferencePaper,2022.0,"Kuang, Zhaobin; Arachie, Chidubem G.; Liang, Bangyong; Narayana, Pradyumna; Desalvo, Giulia; Quinn, Michael S.; Huang, Bert; Downs, Geoffrey; Yang, Yang",Firebolt: Weak Supervision Under Weaker Assumptions,,https://proceedings.mlr.press/v151/kuang22a.html,"Modern machine learning demands a large amount of training data. Weak supervision is a promising approach to meet this demand. It aggregates multiple labeling functions (LFs)–noisy, user-provided labeling heuristics—to rapidly and cheaply curate probabilistic labels for large-scale unlabeled data. However, standard assumptions in weak supervision—such as user-specified class balance, similar accuracy of an LF in classifying different classes, and full knowledge of LF dependency at inference time—might be undesirable in practice. In response, we present Firebolt, a new weak supervision framework that seeks to operate under weaker assumptions. In particular, Firebolt learns the class balance and class-specific accuracy of LFs jointly from unlabeled data. It carries out inference in an efficient and interpretable manner. We analyze the parameter estimation error of Firebolt and characterize its impact on downstream model performance. Furthermore, we show that on five publicly available datasets, Firebolt outperforms a state-of-the-art weak supervision method by up to 5.8 points in AUC. We also provide a case study in the production setting of a tech company, where a Firebolt-supervised model outperforms the existing weakly-supervised production model by 1.3 points in AUC and speedup label model training and inference from one hour to three minutes.",2022-05-03,PMLR,Firebolt: Supervisão Fraca Sob Suposições Mais Fracas,"O aprendizado de máquina moderno exige uma grande quantidade de dados de treinamento. A supervisão fraca é uma abordagem promissora para atender a essa demanda. Ela agrega várias funções de rotulagem (LFs) – heurísticas de rotulagem ruidosas fornecidas pelo usuário – para rapidamente e de forma econômica curar rótulos probabilísticos para dados não rotulados em larga escala. No entanto, suposições padrão na supervisão fraca – como o equilíbrio de classes especificado pelo usuário, precisão semelhante de uma LF na classificação de diferentes classes e conhecimento completo da dependência da LF no momento da inferência – podem ser indesejáveis na prática. Em resposta, apresentamos o Firebolt, uma nova estrutura de supervisão fraca que busca operar sob suposições mais fracas. Em particular, o Firebolt aprende o equilíbrio de classes e a precisão específica de classes das LFs de forma conjunta a partir de dados não rotulados. Ele realiza a inferência de maneira eficiente e interpretável. Analisamos o erro de estimativa de parâmetros do Firebolt e caracterizamos seu impacto no desempenho do modelo subsequente. Além disso, mostramos que em cinco conjuntos de dados publicamente disponíveis, o Firebolt supera um método de supervisão fraca de ponta em até 5,8 pontos em AUC. Também fornecemos um estudo de caso no ambiente de produção de uma empresa de tecnologia, onde um modelo supervisionado pelo Firebolt supera o modelo de produção existente com supervisão fraca em 1,3 pontos em AUC e acelera o treinamento e a inferência do modelo de rótulo de uma hora para três minutos."
2HYA76XH,preprint,2022.0,"Abhishek, Guttu Sai; Ingole, Harshad; Laturia, Parth; Dorna, Vineeth; Maheshwari, Ayush; Iyer, Rishabh; Ramakrishnan, Ganesh",SPEAR : Semi-supervised Data Programming in Python,10.48550/arXiv.2108.00373,http://arxiv.org/abs/2108.00373,"We present SPEAR, an open-source python library for data programming with semi supervision. The package implements several recent data programming approaches including facility to programmatically label and build training data. SPEAR facilitates weak supervision in the form of heuristics (or rules) and association of noisy labels to the training dataset. These noisy labels are aggregated to assign labels to the unlabeled data for downstream tasks. We have implemented several label aggregation approaches that aggregate the noisy labels and then train using the noisily labeled set in a cascaded manner. Our implementation also includes other approaches that jointly aggregate and train the model for text classification tasks. Thus, in our python package, we integrate several cascade and joint data-programming approaches while also providing the facility of data programming by letting the user define labeling functions or rules. The code and tutorial notebooks are available at https://github.com/decile-team/spear. Further, extensive documentation can be found at https://spear-decile.readthedocs.io/. Video tutorials demonstrating the usage of our package are available here. We also present some real-world use cases of SPEAR.",2022-10-05,arXiv,SPEAR: Programação de Dados Semi-supervisionada em Python,"Apresentamos o SPEAR, uma biblioteca python de código aberto para programação de dados com semi-supervisão. O pacote implementa várias abordagens recentes de programação de dados, incluindo a capacidade de rotular programaticamente e construir dados de treinamento. O SPEAR facilita a supervisão fraca na forma de heurísticas (ou regras) e a associação de rótulos ruidosos ao conjunto de dados de treinamento. Esses rótulos ruidosos são agregados para atribuir rótulos aos dados não rotulados para tarefas subsequentes. Implementamos várias abordagens de agregação de rótulos que agregam os rótulos ruidosos e, em seguida, treinam usando o conjunto rotulado de forma ruidosa de maneira em cascata. Nossa implementação também inclui outras abordagens que agregam e treinam o modelo conjuntamente para tarefas de classificação de texto. Assim, em nosso pacote python, integramos várias abordagens de programação de dados em cascata e conjuntas, ao mesmo tempo em que fornecemos a possibilidade de programação de dados permitindo que o usuário defina funções ou regras de rotulagem. O código e os notebooks de tutoriais estão disponíveis em https://github.com/decile-team/spear. Além disso, a documentação extensa pode ser encontrada em https://spear-decile.readthedocs.io/. Tutoriais em vídeo demonstrando o uso de nosso pacote estão disponíveis aqui. Também apresentamos alguns casos de uso do mundo real do SPEAR."
39CJFHAN,preprint,2022.0,"Zhang, Jieyu; Song, Linxin; Ratner, Alexander",Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision,10.48550/arXiv.2210.02724,http://arxiv.org/abs/2210.02724,"Programmatic Weak Supervision (PWS) has emerged as a widespread paradigm to synthesize training labels efficiently. The core component of PWS is the label model, which infers true labels by aggregating the outputs of multiple noisy supervision sources abstracted as labeling functions (LFs). Existing statistical label models typically rely only on the outputs of LF, ignoring the instance features when modeling the underlying generative process. In this paper, we attempt to incorporate the instance features into a statistical label model via the proposed FABLE. In particular, it is built on a mixture of Bayesian label models, each corresponding to a global pattern of correlation, and the coefficients of the mixture components are predicted by a Gaussian Process classifier based on instance features. We adopt an auxiliary variable-based variational inference algorithm to tackle the non-conjugate issue between the Gaussian Process and Bayesian label models. Extensive empirical comparison on eleven benchmark datasets sees FABLE achieving the highest averaged performance across nine baselines.",2022-10-09,arXiv,Aproveitando Recursos de Instância para Agregação de Rótulos em Supervisão Fraca Programática,"A Supervisão Fraca Programática (PWS) surgiu como um paradigma amplamente utilizado para sintetizar rótulos de treinamento de forma eficiente. O componente central da PWS é o modelo de rótulo, que infere rótulos verdadeiros agregando as saídas de várias fontes de supervisão ruidosas abstraídas como funções de rotulagem (LFs). Os modelos de rótulo estatísticos existentes geralmente se baseiam apenas nas saídas da LF, ignorando as características das instâncias ao modelar o processo gerador subjacente. Neste artigo, tentamos incorporar as características das instâncias em um modelo de rótulo estatístico por meio do FABLE proposto. Em particular, ele é construído sobre uma mistura de modelos de rótulo bayesianos, cada um correspondendo a um padrão global de correlação, e os coeficientes dos componentes da mistura são previstos por um classificador de Processo Gaussiano baseado em características das instâncias. Adotamos um algoritmo de inferência variacional baseado em variáveis auxiliares para lidar com a questão não conjugada entre o Processo Gaussiano e os modelos de rótulo bayesianos. Uma extensa comparação empírica em onze conjuntos de dados de referência mostra que o FABLE alcança o melhor desempenho médio entre nove linhas de base."
P6BTUWS8,preprint,2019.0,"Chen, Pengfei; Liao, Benben; Chen, Guangyong; Zhang, Shengyu",Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels,10.48550/arXiv.1905.05040,http://arxiv.org/abs/1905.05040,"Noisy labels are ubiquitous in real-world datasets, which poses a challenge for robustly training deep neural networks (DNNs) as DNNs usually have the high capacity to memorize the noisy labels. In this paper, we find that the test accuracy can be quantitatively characterized in terms of the noise ratio in datasets. In particular, the test accuracy is a quadratic function of the noise ratio in the case of symmetric noise, which explains the experimental findings previously published. Based on our analysis, we apply cross-validation to randomly split noisy datasets, which identifies most samples that have correct labels. Then we adopt the Co-teaching strategy which takes full advantage of the identified samples to train DNNs robustly against noisy labels. Compared with extensive state-of-the-art methods, our strategy consistently improves the generalization performance of DNNs under both synthetic and real-world training noise.",2019-05-13,,Compreendendo e Utilizando Redes Neurais Profundas Treinadas com Rótulos Ruins,"Rótulos ruidosos são onipresentes em conjuntos de dados do mundo real, o que representa um desafio para o treinamento robusto de redes neurais profundas (DNNs), uma vez que as DNNs geralmente têm alta capacidade de memorizar os rótulos ruidosos. Neste artigo, descobrimos que a precisão do teste pode ser caracterizada quantitativamente em termos da razão de ruído nos conjuntos de dados. Em particular, a precisão do teste é uma função quadrática da razão de ruído no caso de ruído simétrico, o que explica as descobertas experimentais publicadas anteriormente. Com base em nossa análise, aplicamos validação cruzada para dividir aleatoriamente conjuntos de dados ruidosos, o que identifica a maioria das amostras que possuem rótulos corretos. Em seguida, adotamos a estratégia de Co-ensino, que aproveita ao máximo as amostras identificadas para treinar DNNs de forma robusta contra rótulos ruidosos. Comparado com métodos de ponta extensivos, nossa estratégia melhora consistentemente o desempenho de generalização das DNNs sob ruído de treinamento tanto sintético quanto do mundo real."
38TF88DE,preprint,2023.0,"Goh, Hui Wen; Mueller, Jonas",ActiveLab: Active Learning with Re-Labeling by Multiple Annotators,10.48550/arXiv.2301.11856,http://arxiv.org/abs/2301.11856,"In real-world data labeling applications, annotators often provide imperfect labels. It is thus common to employ multiple annotators to label data with some overlap between their examples. We study active learning in such settings, aiming to train an accurate classifier by collecting a dataset with the fewest total annotations. Here we propose ActiveLab, a practical method to decide what to label next that works with any classifier model and can be used in pool-based batch active learning with one or multiple annotators. ActiveLab automatically estimates when it is more informative to re-label examples vs. labeling entirely new ones. This is a key aspect of producing high quality labels and trained models within a limited annotation budget. In experiments on image and tabular data, ActiveLab reliably trains more accurate classifiers with far fewer annotations than a wide variety of popular active learning methods.",2023-01-27,arXiv,ActiveLab: Aprendizado Ativo com Reetiquetagem por Múltiplos Anotadores,"Em aplicações de rotulagem de dados do mundo real, os anotadores frequentemente fornecem rótulos imperfeitos. Assim, é comum empregar múltiplos anotadores para rotular dados com alguma sobreposição entre seus exemplos. Estudamos o aprendizado ativo em tais configurações, visando treinar um classificador preciso coletando um conjunto de dados com o menor número total de anotações. Aqui propomos o ActiveLab, um método prático para decidir o que rotular a seguir que funciona com qualquer modelo de classificador e pode ser usado em aprendizado ativo em lote baseado em pool com um ou múltiplos anotadores. O ActiveLab estima automaticamente quando é mais informativo re-rotular exemplos em vez de rotular completamente novos. Este é um aspecto chave para produzir rótulos de alta qualidade e modelos treinados dentro de um orçamento de anotações limitado. Em experimentos com dados de imagem e tabulares, o ActiveLab treina de forma confiável classificadores mais precisos com muito menos anotações do que uma ampla variedade de métodos populares de aprendizado ativo."
37KKX8V4,preprint,2022.0,"Zhan, Xueying; Wang, Qingzhong; Huang, Kuan-hao; Xiong, Haoyi; Dou, Dejing; Chan, Antoni B.",A Comparative Survey of Deep Active Learning,10.48550/arXiv.2203.13450,http://arxiv.org/abs/2203.13450,"While deep learning (DL) is data-hungry and usually relies on extensive labeled data to deliver good performance, Active Learning (AL) reduces labeling costs by selecting a small proportion of samples from unlabeled data for labeling and training. Therefore, Deep Active Learning (DAL) has risen as a feasible solution for maximizing model performance under a limited labeling cost/budget in recent years. Although abundant methods of DAL have been developed and various literature reviews conducted, the performance evaluation of DAL methods under fair comparison settings is not yet available. Our work intends to fill this gap. In this work, We construct a DAL toolkit, DeepAL+, by re-implementing 19 highly-cited DAL methods. We survey and categorize DAL-related works and construct comparative experiments across frequently used datasets and DAL algorithms. Additionally, we explore some factors (e.g., batch size, number of epochs in the training process) that influence the efficacy of DAL, which provides better references for researchers to design their DAL experiments or carry out DAL-related applications.",2022-07-19,,Uma Pesquisa Comparativa de Aprendizado Ativo Profundo,"Embora o aprendizado profundo (DL) exija muitos dados e geralmente dependa de um extenso conjunto de dados rotulados para oferecer um bom desempenho, o Aprendizado Ativo (AL) reduz os custos de rotulagem ao selecionar uma pequena proporção de amostras de dados não rotulados para rotulagem e treinamento. Portanto, o Aprendizado Ativo Profundo (DAL) surgiu como uma solução viável para maximizar o desempenho do modelo sob um custo/orçamento de rotulagem limitado nos últimos anos. Embora abundantes métodos de DAL tenham sido desenvolvidos e várias revisões da literatura tenham sido realizadas, a avaliação de desempenho dos métodos DAL em configurações de comparação justa ainda não está disponível. Nosso trabalho pretende preencher essa lacuna. Neste trabalho, construímos um kit de ferramentas DAL, DeepAL+, reimplementando 19 métodos DAL altamente citados. Pesquisamos e categorizamos trabalhos relacionados ao DAL e construímos experimentos comparativos em conjuntos de dados frequentemente usados e algoritmos DAL. Além disso, exploramos alguns fatores (por exemplo, tamanho do lote, número de épocas no processo de treinamento) que influenciam a eficácia do DAL, o que fornece melhores referências para pesquisadores projetarem seus experimentos DAL ou realizarem aplicações relacionadas ao DAL."
XDZCA7GV,preprint,2018.0,"Ratner, Alexander; Hancock, Braden; Dunnmon, Jared; Sala, Frederic; Pandey, Shreyash; Ré, Christopher",Training Complex Models with Multi-Task Weak Supervision,,http://arxiv.org/abs/1810.02840,"As machine learning models continue to increase in complexity, collecting large hand-labeled training sets has become one of the biggest roadblocks in practice. Instead, weaker forms of supervision that provide noisier but cheaper labels are often used. However, these weak supervision sources have diverse and unknown accuracies, may output correlated labels, and may label different tasks or apply at different levels of granularity. We propose a framework for integrating and modeling such weak supervision sources by viewing them as labeling different related sub-tasks of a problem, which we refer to as the multi-task weak supervision setting. We show that by solving a matrix completion-style problem, we can recover the accuracies of these multi-task sources given their dependency structure, but without any labeled data, leading to higher-quality supervision for training an end model. Theoretically, we show that the generalization error of models trained with this approach improves with the number of unlabeled data points, and characterize the scaling with respect to the task and dependency structures. On three fine-grained classification problems, we show that our approach leads to average gains of 20.2 points in accuracy over a traditional supervised approach, 6.8 points over a majority vote baseline, and 4.1 points over a previously proposed weak supervision method that models tasks separately.",2018-12-07,arXiv,Treinamento de Modelos Complexos com Supervisão Fraca de Múltiplas Tarefas,"À medida que os modelos de aprendizado de máquina continuam a aumentar em complexidade, a coleta de grandes conjuntos de treinamento rotulados manualmente se tornou um dos maiores obstáculos na prática. Em vez disso, formas mais fracas de supervisão que fornecem rótulos mais barulhentos, mas mais baratos, são frequentemente utilizadas. No entanto, essas fontes de supervisão fraca têm precisões diversas e desconhecidas, podem gerar rótulos correlacionados e podem rotular diferentes tarefas ou se aplicar em diferentes níveis de granularidade. Propomos uma estrutura para integrar e modelar essas fontes de supervisão fraca, considerando-as como rotulando diferentes subtarefas relacionadas de um problema, que chamamos de configuração de supervisão fraca multitarefa. Mostramos que, ao resolver um problema de estilo de completude de matriz, podemos recuperar as precisões dessas fontes multitarefa, dadas suas estruturas de dependência, mas sem nenhum dado rotulado, levando a uma supervisão de maior qualidade para treinar um modelo final. Teoricamente, mostramos que o erro de generalização de modelos treinados com essa abordagem melhora com o número de pontos de dados não rotulados e caracterizamos a escalabilidade em relação às estruturas de tarefa e dependência. Em três problemas de classificação de alta granularidade, mostramos que nossa abordagem leva a ganhos médios de 20,2 pontos em precisão em relação a uma abordagem supervisionada tradicional, 6,8 pontos em relação a uma linha de base de voto da maioria e 4,1 pontos em relação a um método de supervisão fraca previamente proposto que modela tarefas separadamente."
Z6IGENDD,preprint,2022.0,"Maheshwari, Ayush; Killamsetty, Krishnateja; Ramakrishnan, Ganesh; Iyer, Rishabh; Danilevsky, Marina; Popa, Lucian",Learning to Robustly Aggregate Labeling Functions for Semi-supervised Data Programming,10.48550/arXiv.2109.11410,http://arxiv.org/abs/2109.11410,"A critical bottleneck in supervised machine learning is the need for large amounts of labeled data which is expensive and time consuming to obtain. However, it has been shown that a small amount of labeled data, while insufficient to re-train a model, can be effectively used to generate human-interpretable labeling functions (LFs). These LFs, in turn, have been used to generate a large amount of additional noisy labeled data, in a paradigm that is now commonly referred to as data programming. However, previous approaches to automatically generate LFs make no attempt to further use the given labeled data for model training, thus giving up opportunities for improved performance. Moreover, since the LFs are generated from a relatively small labeled dataset, they are prone to being noisy, and naively aggregating these LFs can lead to very poor performance in practice. In this work, we propose an LF based reweighting framework \ouralgo{} to solve these two critical limitations. Our algorithm learns a joint model on the (same) labeled dataset used for LF induction along with any unlabeled data in a semi-supervised manner, and more critically, reweighs each LF according to its goodness, influencing its contribution to the semi-supervised loss using a robust bi-level optimization algorithm. We show that our algorithm significantly outperforms prior approaches on several text classification datasets.",2022-03-10,arXiv,Aprendendo a Agregar Robustamente Funções de Rotulagem para Programação de Dados Semi-supervisionada,"Um gargalo crítico no aprendizado de máquina supervisionado é a necessidade de grandes quantidades de dados rotulados, que são caros e demorados para obter. No entanto, foi demonstrado que uma pequena quantidade de dados rotulados, embora insuficiente para re-treinar um modelo, pode ser usada efetivamente para gerar funções de rotulagem interpretáveis por humanos (LFs). Essas LFs, por sua vez, têm sido usadas para gerar uma grande quantidade de dados rotulados adicionais ruidosos, em um paradigma que agora é comumente referido como programação de dados. No entanto, abordagens anteriores para gerar automaticamente LFs não tentam utilizar os dados rotulados fornecidos para o treinamento do modelo, desistindo assim de oportunidades para melhorar o desempenho. Além disso, uma vez que as LFs são geradas a partir de um conjunto de dados rotulados relativamente pequeno, elas são propensas a serem ruidosas, e agregar essas LFs de maneira ingênua pode levar a um desempenho muito ruim na prática. Neste trabalho, propomos uma estrutura de reponderação baseada em LFs \ouralgo{} para resolver essas duas limitações críticas. Nosso algoritmo aprende um modelo conjunto no (mesmo) conjunto de dados rotulados usado para indução de LFs, juntamente com quaisquer dados não rotulados de maneira semi-supervisionada e, mais criticamente, repondera cada LF de acordo com sua qualidade, influenciando sua contribuição para a perda semi-supervisionada usando um algoritmo robusto de otimização bi-nível. Mostramos que nosso algoritmo supera significativamente abordagens anteriores em vários conjuntos de dados de classificação de texto."
ELUP4URQ,journalArticle,2022.0,"Hsieh, Cheng-Yu; Zhang, Jieyu; Ratner, Alexander",Nemo: Guiding and Contextualizing Weak Supervision for Interactive Data Programming,10.14778/3565838.3565859,https://dl.acm.org/doi/10.14778/3565838.3565859,"Weak Supervision (WS) techniques allow users to e ciently create large training datasets by programmatically labeling data with heuristic sources of supervision. While the success of WS relies heavily on the provided labeling heuristics, the process of how these heuristics are created in practice has remained under-explored. In this work, we formalize the development process of labeling heuristics as an interactive procedure, built around the existing work ow where users draw ideas from a selected set of development data for designing the heuristic sources. With the formalism, shown in Figure 1, we study two core problems of (1) how to strategically select the development data to guide users in e ciently creating informative heuristics, and (2) how to exploit the information within the development process to contextualize and better learn from the resultant heuristics. Building upon two novel methodologies that e ectively tackle the respective problems considered, we present Nemo, an end-to-end interactive system that improves the overall productivity of WS learning pipeline by an average 20% (and up to 47% in one task) compared to the prevailing WS approach.",2022-09,,Nemo: Orientando e Contextualizando Supervisão Fraca para Programação de Dados Interativa,"Técnicas de Supervisão Fraca (WS) permitem que os usuários criem de forma eficiente grandes conjuntos de dados de treinamento, rotulando programaticamente os dados com fontes heurísticas de supervisão. Embora o sucesso da WS dependa fortemente das heurísticas de rotulagem fornecidas, o processo de como essas heurísticas são criadas na prática permaneceu pouco explorado. Neste trabalho, formalizamos o processo de desenvolvimento de heurísticas de rotulagem como um procedimento interativo, construído em torno do fluxo de trabalho existente onde os usuários extraem ideias de um conjunto selecionado de dados de desenvolvimento para projetar as fontes heurísticas. Com o formalismo, mostrado na Figura 1, estudamos dois problemas centrais: (1) como selecionar estrategicamente os dados de desenvolvimento para guiar os usuários na criação eficiente de heurísticas informativas, e (2) como explorar a informação dentro do processo de desenvolvimento para contextualizar e aprender melhor com as heurísticas resultantes. Baseando-se em duas metodologias inovadoras que abordam efetivamente os problemas considerados, apresentamos o Nemo, um sistema interativo de ponta a ponta que melhora a produtividade geral do pipeline de aprendizado WS em uma média de 20% (e até 47% em uma tarefa) em comparação com a abordagem WS predominante."
ZU66TCFU,preprint,2022.0,"Oyen, Diane; Kucer, Michal; Hengartner, Nick; Singh, Har Simrat",Robustness to Label Noise Depends on the Shape of the Noise Distribution in Feature Space,10.48550/arXiv.2206.01106,http://arxiv.org/abs/2206.01106,"Machine learning classifiers have been demonstrated, both empirically and theoretically, to be robust to label noise under certain conditions -- notably the typical assumption is that label noise is independent of the features given the class label. We provide a theoretical framework that generalizes beyond this typical assumption by modeling label noise as a distribution over feature space. We show that both the scale and the shape of the noise distribution influence the posterior likelihood; and the shape of the noise distribution has a stronger impact on classification performance if the noise is concentrated in feature space where the decision boundary can be moved. For the special case of uniform label noise (independent of features and the class label), we show that the Bayes optimal classifier for $c$ classes is robust to label noise until the ratio of noisy samples goes above $\frac{c-1}{c}$ (e.g. 90% for 10 classes), which we call the tipping point. However, for the special case of class-dependent label noise (independent of features given the class label), the tipping point can be as low as 50%. Most importantly, we show that when the noise distribution targets decision boundaries (label noise is directly dependent on feature space), classification robustness can drop off even at a small scale of noise. Even when evaluating recent label-noise mitigation methods we see reduced accuracy when label noise is dependent on features. These findings explain why machine learning often handles label noise well if the noise distribution is uniform in feature-space; yet it also points to the difficulty of overcoming label noise when it is concentrated in a region of feature space where a decision boundary can move.",2022-06-02,arXiv,A Robustez ao Ruído de Rótulo Depende da Forma da Distribuição de Ruído no Espaço de Características,"Classificadores de aprendizado de máquina têm demonstrado, tanto empiricamente quanto teoricamente, serem robustos ao ruído de rótulo sob certas condições -- notavelmente, a suposição típica é que o ruído de rótulo é independente das características dadas as classes. Fornecemos uma estrutura teórica que generaliza além dessa suposição típica, modelando o ruído de rótulo como uma distribuição sobre o espaço de características. Mostramos que tanto a escala quanto a forma da distribuição de ruído influenciam a verossimilhança posterior; e a forma da distribuição de ruído tem um impacto mais forte no desempenho da classificação se o ruído estiver concentrado no espaço de características onde a fronteira de decisão pode ser movida. Para o caso especial de ruído de rótulo uniforme (independente das características e do rótulo da classe), mostramos que o classificador ótimo de Bayes para $c$ classes é robusto ao ruído de rótulo até que a proporção de amostras ruidosas ultrapasse $\frac{c-1}{c}$ (por exemplo, 90% para 10 classes), que chamamos de ponto de inflexão. No entanto, para o caso especial de ruído de rótulo dependente da classe (independente das características dadas o rótulo da classe), o ponto de inflexão pode ser tão baixo quanto 50%. O mais importante, mostramos que quando a distribuição de ruído visa as fronteiras de decisão (o ruído de rótulo é diretamente dependente do espaço de características), a robustez da classificação pode cair mesmo com uma pequena escala de ruído. Mesmo ao avaliar métodos recentes de mitigação de ruído de rótulo, vemos uma precisão reduzida quando o ruído de rótulo é dependente das características. Essas descobertas explicam por que o aprendizado de máquina frequentemente lida bem com o ruído de rótulo se a distribuição de ruído for uniforme no espaço de características; no entanto, também aponta para a dificuldade de superar o ruído de rótulo quando está concentrado em uma região do espaço de características onde uma fronteira de decisão pode se mover."
IU8J2WNK,preprint,2022.0,"Zhang, Jieyu; Wang, Yujing; Yang, Yaming; Luo, Yang; Ratner, Alexander",Binary Classification with Positive Labeling Sources,10.48550/arXiv.2208.01704,http://arxiv.org/abs/2208.01704,"To create a large amount of training labels for machine learning models effectively and efficiently, researchers have turned to Weak Supervision (WS), which uses programmatic labeling sources rather than manual annotation. Existing works of WS for binary classification typically assume the presence of labeling sources that are able to assign both positive and negative labels to data in roughly balanced proportions. However, for many tasks of interest where there is a minority positive class, negative examples could be too diverse for developers to generate indicative labeling sources. Thus, in this work, we study the application of WS on binary classification tasks with positive labeling sources only. We propose WEAPO, a simple yet competitive WS method for producing training labels without negative labeling sources. On 10 benchmark datasets, we show WEAPO achieves the highest averaged performance in terms of both the quality of synthesized labels and the performance of the final classifier supervised with these labels. We incorporated the implementation of \method into WRENCH, an existing benchmarking platform.",2022-08-02,arXiv,Classificação Binária com Fontes de Rotulagem Positiva,"Para criar uma grande quantidade de rótulos de treinamento para modelos de aprendizado de máquina de forma eficaz e eficiente, os pesquisadores recorreram à Supervisão Fraca (WS), que utiliza fontes de rotulagem programáticas em vez de anotação manual. Trabalhos existentes de WS para classificação binária geralmente assumem a presença de fontes de rotulagem que são capazes de atribuir rótulos positivos e negativos aos dados em proporções aproximadamente equilibradas. No entanto, para muitas tarefas de interesse onde há uma classe positiva minoritária, exemplos negativos podem ser muito diversos para que os desenvolvedores gerem fontes de rotulagem indicativas. Assim, neste trabalho, estudamos a aplicação de WS em tarefas de classificação binária com fontes de rotulagem positivas apenas. Propomos o WEAPO, um método de WS simples, mas competitivo, para produzir rótulos de treinamento sem fontes de rotulagem negativas. Em 10 conjuntos de dados de referência, mostramos que o WEAPO alcança o melhor desempenho médio em termos tanto da qualidade dos rótulos sintetizados quanto do desempenho do classificador final supervisionado com esses rótulos. Incorporamos a implementação do \method no WRENCH, uma plataforma de benchmarking existente."
ZLJND4US,preprint,2023.0,"Boecking, Benedikt; Roberts, Nicholas; Neiswanger, Willie; Ermon, Stefano; Sala, Frederic; Dubrawski, Artur",Generative Modeling Helps Weak Supervision (and Vice Versa),10.48550/arXiv.2203.12023,http://arxiv.org/abs/2203.12023,"Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak supervision and generative modeling. While these techniques would seem to be usable in concert, improving one another, how to build an interface between them is not well-understood. In this work, we propose a model fusing programmatic weak supervision and generative adversarial networks and provide theoretical justification motivating this fusion. The proposed approach captures discrete latent variables in the data alongside the weak supervision derived label estimate. Alignment of the two allows for better modeling of sample-dependent accuracies of the weak supervision sources, improving the estimate of unobserved labels. It is the first approach to enable data augmentation through weakly supervised synthetic images and pseudolabels. Additionally, its learned latent variables can be inspected qualitatively. The model outperforms baseline weak supervision label models on a number of multiclass image classification datasets, improves the quality of generated images, and further improves end-model performance through data augmentation with synthetic samples.",2023-03-11,arXiv,Modelagem Generativa Ajuda a Supervisão Fraca (e Vice-Versa),"Muitas aplicações promissoras de aprendizado de máquina supervisionado enfrentam obstáculos na aquisição de dados rotulados em quantidade e qualidade suficientes, criando um gargalo caro. Para superar tais limitações, técnicas que não dependem de rótulos de verdade terrestre têm sido estudadas, incluindo supervisão fraca e modelagem generativa. Embora essas técnicas pareçam utilizáveis em conjunto, melhorando uma à outra, como construir uma interface entre elas não é bem compreendido. Neste trabalho, propomos um modelo que funde supervisão fraca programática e redes adversariais generativas e fornecemos uma justificativa teórica que motiva essa fusão. A abordagem proposta captura variáveis latentes discretas nos dados juntamente com a estimativa de rótulo derivada da supervisão fraca. O alinhamento dos dois permite uma melhor modelagem das precisões dependentes da amostra das fontes de supervisão fraca, melhorando a estimativa de rótulos não observados. É a primeira abordagem a permitir a augmentação de dados por meio de imagens sintéticas supervisionadas de forma fraca e pseudorótulos. Além disso, suas variáveis latentes aprendidas podem ser inspecionadas qualitativamente. O modelo supera os modelos de rótulos de supervisão fraca de referência em vários conjuntos de dados de classificação de imagens multiclasse, melhora a qualidade das imagens geradas e ainda melhora o desempenho do modelo final por meio da augmentação de dados com amostras sintéticas."
XJJZT6WS,preprint,2023.0,"Wu, Renzhi; Chen, Shen-En; Zhang, Jieyu; Chu, Xu",Learning Hyper Label Model for Programmatic Weak Supervision,10.48550/arXiv.2207.13545,http://arxiv.org/abs/2207.13545,"To reduce the human annotation efforts, the programmatic weak supervision (PWS) paradigm abstracts weak supervision sources as labeling functions (LFs) and involves a label model to aggregate the output of multiple LFs to produce training labels. Most existing label models require a parameter learning step for each dataset. In this work, we present a hyper label model that (once learned) infers the ground-truth labels for each dataset in a single forward pass without dataset-specific parameter learning. The hyper label model approximates an optimal analytical (yet computationally intractable) solution of the ground-truth labels. We train the model on synthetic data generated in the way that ensures the model approximates the analytical optimal solution, and build the model upon Graph Neural Network (GNN) to ensure the model prediction being invariant (or equivariant) to the permutation of LFs (or data points). On 14 real-world datasets, our hyper label model outperforms the best existing methods in both accuracy (by 1.4 points on average) and efficiency (by six times on average). Our code is available at https://github.com/wurenzhi/hyper_label_model",2023-03-08,arXiv,Aprendendo o Modelo Hyper Label para Supervisão Fraca Programática,"Para reduzir os esforços de anotação humana, o paradigma de supervisão fraca programática (PWS) abstrai fontes de supervisão fraca como funções de rotulagem (LFs) e envolve um modelo de rótulo para agregar a saída de múltiplas LFs para produzir rótulos de treinamento. A maioria dos modelos de rótulo existentes requer uma etapa de aprendizado de parâmetros para cada conjunto de dados. Neste trabalho, apresentamos um modelo de hiper rótulo que (uma vez aprendido) infere os rótulos verdadeiros para cada conjunto de dados em uma única passagem para frente, sem aprendizado de parâmetros específico do conjunto de dados. O modelo de hiper rótulo aproxima uma solução analítica ótima (embora computacionalmente intratável) dos rótulos verdadeiros. Treinamos o modelo em dados sintéticos gerados de forma a garantir que o modelo aproxime a solução analítica ótima e construímos o modelo sobre Redes Neurais Gráficas (GNN) para garantir que a predição do modelo seja invariante (ou equivariável) à permutação de LFs (ou pontos de dados). Em 14 conjuntos de dados do mundo real, nosso modelo de hiper rótulo supera os melhores métodos existentes tanto em precisão (em média, 1,4 pontos a mais) quanto em eficiência (em média, seis vezes mais rápido). Nosso código está disponível em https://github.com/wurenzhi/hyper_label_model"
B2TYL6IY,preprint,2022.0,"Stephan, Andreas; Kougia, Vasiliki; Roth, Benjamin",SepLL: Separating Latent Class Labels from Weak Supervision Noise,10.48550/arXiv.2210.13898,http://arxiv.org/abs/2210.13898,"In the weakly supervised learning paradigm, labeling functions automatically assign heuristic, often noisy, labels to data samples. In this work, we provide a method for learning from weak labels by separating two types of complementary information associated with the labeling functions: information related to the target label and information specific to one labeling function only. Both types of information are reflected to different degrees by all labeled instances. In contrast to previous works that aimed at correcting or removing wrongly labeled instances, we learn a branched deep model that uses all data as-is, but splits the labeling function information in the latent space. Specifically, we propose the end-to-end model SepLL which extends a transformer classifier by introducing a latent space for labeling function specific and task-specific information. The learning signal is only given by the labeling functions matches, no pre-processing or label model is required for our method. Notably, the task prediction is made from the latent layer without any direct task signal. Experiments on Wrench text classification tasks show that our model is competitive with the state-of-the-art, and yields a new best average performance.",2022-10-25,arXiv,SepLL: Separando Rótulos de Classe Latente do Ruído de Supervisão Fraca,"No paradigma de aprendizado fraco supervisionado, funções de rotulagem atribuem automaticamente rótulos heurísticos, muitas vezes ruidosos, a amostras de dados. Neste trabalho, fornecemos um método para aprender a partir de rótulos fracos, separando dois tipos de informações complementares associadas às funções de rotulagem: informações relacionadas ao rótulo alvo e informações específicas de uma única função de rotulagem. Ambos os tipos de informações são refletidos em diferentes graus por todas as instâncias rotuladas. Em contraste com trabalhos anteriores que visavam corrigir ou remover instâncias rotuladas incorretamente, aprendemos um modelo profundo ramificado que utiliza todos os dados como estão, mas divide as informações da função de rotulagem no espaço latente. Especificamente, propomos o modelo end-to-end SepLL, que estende um classificador transformer ao introduzir um espaço latente para informações específicas da função de rotulagem e informações específicas da tarefa. O sinal de aprendizado é dado apenas pelas correspondências das funções de rotulagem, nenhum pré-processamento ou modelo de rótulo é necessário para nosso método. Notavelmente, a previsão da tarefa é feita a partir da camada latente sem nenhum sinal direto da tarefa. Experimentos em tarefas de classificação de texto Wrench mostram que nosso modelo é competitivo com o estado da arte e apresenta um novo melhor desempenho médio."
I85Q7N65,webpage,2023.0,,On the relative value of weak information of supervision for learning generative models: An empirical study | Elsevier Enhanced Reader,,https://reader.elsevier.com/reader/sd/pii/S0888613X22001244?token=1D7996D01A31ADEE02BD86237F984A1F2117C6C3BF133FB30175D4B4719D99BF9F69E0E233509ACF3243062B7E85E782&originRegion=us-east-1&originCreation=20230415123828,,2023-04-15,,Sobre o valor relativo de informações fracas de supervisão para o aprendizado de modelos generativos: Um estudo empírico | Leitor Aprimorado da Elsevier,nan
WHYGSBWB,conferencePaper,2022.0,"Yu, Peilin; Ding, Tiffany; Bach, Stephen H.",Learning from Multiple Noisy Partial Labelers,,https://proceedings.mlr.press/v151/yu22c.html,"Programmatic weak supervision creates models without hand-labeled training data by combining the outputs of heuristic labelers. Existing frameworks make the restrictive assumption that labelers output a single class label. Enabling users to create partial labelers that output subsets of possible class labels would greatly expand the expressivity of programmatic weak supervision. We introduce this capability by defining a probabilistic generative model that can estimate the underlying accuracies of multiple noisy partial labelers without ground truth labels. We show how to scale up learning, for example learning on 100k examples in one minute, a 300××\times speed up compared to a naive implementation. We also prove that this class of models is generically identifiable up to label swapping under mild conditions. We evaluate our framework on three text classification and six object classification tasks. On text tasks, adding partial labels increases average accuracy by 8.6 percentage points. On image tasks, we show that partial labels allow us to approach some zero-shot object classification problems with programmatic weak supervision by using class attributes as partial labelers. On these tasks, our framework has accuracy comparable to recent embedding-based zero-shot learning methods, while using only pre-trained attribute detectors.",2022-05-03,PMLR,Aprendendo com Múltiplos Rotuladores Parciais Ruidosos,"A supervisão fraca programática cria modelos sem dados de treinamento rotulados manualmente, combinando as saídas de rotuladores heurísticos. As estruturas existentes fazem a suposição restritiva de que os rotuladores produzem um único rótulo de classe. Permitir que os usuários criem rotuladores parciais que produzem subconjuntos de possíveis rótulos de classe expandiria enormemente a expressividade da supervisão fraca programática. Introduzimos essa capacidade definindo um modelo generativo probabilístico que pode estimar as precisões subjacentes de múltiplos rotuladores parciais ruidosos sem rótulos de verdade de base. Mostramos como escalar o aprendizado, por exemplo, aprendendo em 100 mil exemplos em um minuto, um aumento de 300× em comparação com uma implementação ingênua. Também provamos que essa classe de modelos é genericamente identificável até a troca de rótulos sob condições brandas. Avaliamos nossa estrutura em três tarefas de classificação de texto e seis tarefas de classificação de objetos. Nas tarefas de texto, adicionar rótulos parciais aumenta a precisão média em 8,6 pontos percentuais. Nas tarefas de imagem, mostramos que rótulos parciais nos permitem abordar alguns problemas de classificação de objetos zero-shot com supervisão fraca programática, utilizando atributos de classe como rotuladores parciais. Nessas tarefas, nossa estrutura tem precisão comparável a métodos recentes de aprendizado zero-shot baseados em incorporação, enquanto utiliza apenas detectores de atributos pré-treinados."
NCK2V7YF,preprint,2019.0,"Boecking, Benedikt; Dubrawski, Artur",Pairwise Feedback for Data Programming,10.48550/arXiv.1912.07685,http://arxiv.org/abs/1912.07685,The scalability of the labeling process and the attainable quality of labels have become limiting factors for many applications of machine learning. The programmatic creation of labeled datasets via the synthesis of noisy heuristics provides a promising avenue to address this problem. We propose to improve modeling of latent class variables in the programmatic creation of labeled datasets by incorporating pairwise feedback into the process. We discuss the ease with which such pairwise feedback can be obtained or generated in many application domains. Our experiments show that even a small number of sources of pairwise feedback can substantially improve the quality of the posterior estimate of the latent class variable.,2019-12-16,arXiv,Feedback Par a Par para Programação de Dados,"A escalabilidade do processo de rotulagem e a qualidade alcançável dos rótulos tornaram-se fatores limitantes para muitas aplicações de aprendizado de máquina. A criação programática de conjuntos de dados rotulados por meio da síntese de heurísticas ruidosas oferece uma avenida promissora para abordar esse problema. Propomos melhorar a modelagem de variáveis de classe latente na criação programática de conjuntos de dados rotulados, incorporando feedback par a par no processo. Discutimos a facilidade com que tal feedback par a par pode ser obtido ou gerado em muitos domínios de aplicação. Nossos experimentos mostram que mesmo um pequeno número de fontes de feedback par a par pode melhorar substancialmente a qualidade da estimativa posterior da variável de classe latente."
82N56P3M,preprint,2022.0,"Zhang, Jieyu; Wang, Bohan; Song, Xiangchen; Wang, Yujing; Yang, Yaming; Bai, Jing; Ratner, Alexander",Creating Training Sets via Weak Indirect Supervision,,http://arxiv.org/abs/2110.03484,"Creating labeled training sets has become one of the major roadblocks in machine learning. To address this, recent \emph{Weak Supervision (WS)} frameworks synthesize training labels from multiple potentially noisy supervision sources. However, existing frameworks are restricted to supervision sources that share the same output space as the target task. To extend the scope of usable sources, we formulate Weak Indirect Supervision (WIS), a new research problem for automatically synthesizing training labels based on indirect supervision sources that have different output label spaces. To overcome the challenge of mismatched output spaces, we develop a probabilistic modeling approach, PLRM, which uses user-provided label relations to model and leverage indirect supervision sources. Moreover, we provide a theoretically-principled test of the distinguishability of PLRM for unseen labels, along with a generalization bound. On both image and text classification tasks as well as an industrial advertising application, we demonstrate the advantages of PLRM by outperforming baselines by a margin of 2%-9%.",2022-03-14,arXiv,Criando Conjuntos de Treinamento por Meio de Supervisão Indireta Fraca,"Criar conjuntos de treinamento rotulados tornou-se um dos principais obstáculos no aprendizado de máquina. Para abordar isso, estruturas recentes de \emph{Supervisão Fraca (WS)} sintetizam rótulos de treinamento a partir de várias fontes de supervisão potencialmente ruidosas. No entanto, as estruturas existentes estão restritas a fontes de supervisão que compartilham o mesmo espaço de saída que a tarefa-alvo. Para ampliar o escopo das fontes utilizáveis, formulamos a Supervisão Indireta Fraca (WIS), um novo problema de pesquisa para sintetizar automaticamente rótulos de treinamento com base em fontes de supervisão indireta que possuem diferentes espaços de rótulos de saída. Para superar o desafio de espaços de saída incompatíveis, desenvolvemos uma abordagem de modelagem probabilística, PLRM, que utiliza relações de rótulos fornecidas pelo usuário para modelar e aproveitar fontes de supervisão indireta. Além disso, fornecemos um teste teoricamente fundamentado da distinguibilidade do PLRM para rótulos não vistos, juntamente com um limite de generalização. Em tarefas de classificação de imagens e textos, bem como em uma aplicação industrial de publicidade, demonstramos as vantagens do PLRM ao superar as linhas de base por uma margem de 2%-9%."
HCF46KYT,preprint,2023.0,"Pukdee, Rattana; Sam, Dylan; Balcan, Maria-Florina; Ravikumar, Pradeep",Label Propagation with Weak Supervision,10.48550/arXiv.2210.03594,http://arxiv.org/abs/2210.03594,"Semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. In this paper, we introduce a novel analysis of the classical label propagation algorithm (LPA) (Zhu & Ghahramani, 2002) that moreover takes advantage of useful prior information, specifically probabilistic hypothesized labels on the unlabeled data. We provide an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. We also propose a framework to incorporate multiple sources of noisy information. In particular, we consider the setting of weak supervision, where our sources of information are weak labelers. We demonstrate the ability of our approach on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.",2023-04-09,arXiv,Propagação de Rótulos com Supervisão Fraca,"O aprendizado semi-supervisionado e o aprendizado fracamente supervisionado são paradigmas importantes que visam reduzir a crescente demanda por dados rotulados nas aplicações atuais de aprendizado de máquina. Neste artigo, introduzimos uma nova análise do algoritmo clássico de propagação de rótulos (LPA) (Zhu & Ghahramani, 2002) que, além disso, aproveita informações prévias úteis, especificamente rótulos hipotéticos probabilísticos sobre os dados não rotulados. Fornecemos um limite de erro que explora tanto as propriedades geométricas locais do grafo subjacente quanto a qualidade da informação prévia. Também propomos uma estrutura para incorporar múltiplas fontes de informação ruidosa. Em particular, consideramos o cenário de supervisão fraca, onde nossas fontes de informação são rotuladores fracos. Demonstramos a capacidade de nossa abordagem em múltiplas tarefas de classificação fracamente supervisionadas de referência, mostrando melhorias em relação aos métodos existentes de aprendizado semi-supervisionado e fracamente supervisionado."
2YSLRA6Z,preprint,2022.0,"Chen, Mayee F.; Fu, Daniel Y.; Adila, Dyah; Zhang, Michael; Sala, Frederic; Fatahalian, Kayvon; Ré, Christopher",Shoring Up the Foundations: Fusing Model Embeddings and Weak Supervision,10.48550/arXiv.2203.13270,http://arxiv.org/abs/2203.13270,"Foundation models offer an exciting new paradigm for constructing models with out-of-the-box embeddings and a few labeled examples. However, it is not clear how to best apply foundation models without labeled data. A potential approach is to fuse foundation models with weak supervision frameworks, which use weak label sources -- pre-trained models, heuristics, crowd-workers -- to construct pseudolabels. The challenge is building a combination that best exploits the signal available in both foundation models and weak sources. We propose Liger, a combination that uses foundation model embeddings to improve two crucial elements of existing weak supervision techniques. First, we produce finer estimates of weak source quality by partitioning the embedding space and learning per-part source accuracies. Second, we improve source coverage by extending source votes in embedding space. Despite the black-box nature of foundation models, we prove results characterizing how our approach improves performance and show that lift scales with the smoothness of label distributions in embedding space. On six benchmark NLP and video tasks, Liger outperforms vanilla weak supervision by 14.1 points, weakly-supervised kNN and adapters by 11.8 points, and kNN and adapters supervised by traditional hand labels by 7.2 points.",2022-08-01,,Fortalecendo as Fundamentos: Fundindo Embeddings de Modelos e Supervisão Fraca,"Modelos de fundação oferecem um novo paradigma empolgante para a construção de modelos com embeddings prontos para uso e alguns exemplos rotulados. No entanto, não está claro como aplicar da melhor forma os modelos de fundação sem dados rotulados. Uma abordagem potencial é fundir modelos de fundação com estruturas de supervisão fraca, que utilizam fontes de rótulos fracos -- modelos pré-treinados, heurísticas, trabalhadores de multidão -- para construir pseudorótulos. O desafio é construir uma combinação que melhor explore o sinal disponível tanto nos modelos de fundação quanto nas fontes fracas. Propomos o Liger, uma combinação que utiliza embeddings de modelos de fundação para melhorar dois elementos cruciais das técnicas existentes de supervisão fraca. Primeiro, produzimos estimativas mais precisas da qualidade das fontes fracas ao particionar o espaço de embeddings e aprender a acurácia das fontes por parte. Em segundo lugar, melhoramos a cobertura das fontes ao estender os votos das fontes no espaço de embeddings. Apesar da natureza de caixa-preta dos modelos de fundação, provamos resultados que caracterizam como nossa abordagem melhora o desempenho e mostramos que o aumento escala com a suavidade das distribuições de rótulos no espaço de embeddings. Em seis tarefas de benchmark de NLP e vídeo, o Liger supera a supervisão fraca convencional em 14,1 pontos, kNN e adaptadores supervisionados de forma fraca em 11,8 pontos, e kNN e adaptadores supervisionados por rótulos manuais tradicionais em 7,2 pontos."
FLH3CAJI,preprint,2022.0,"Kuan, Johnson; Mueller, Jonas",Back to the Basics: Revisiting Out-of-Distribution Detection Baselines,10.48550/arXiv.2207.03061,http://arxiv.org/abs/2207.03061,"We study simple methods for out-of-distribution (OOD) image detection that are compatible with any already trained classifier, relying on only its predictions or learned representations. Evaluating the OOD detection performance of various methods when utilized with ResNet-50 and Swin Transformer models, we find methods that solely consider the model's predictions can be easily outperformed by also considering the learned representations. Based on our analysis, we advocate for a dead-simple approach that has been neglected in other studies: simply flag as OOD images whose average distance to their K nearest neighbors is large (in the representation space of an image classifier trained on the in-distribution data).",2022-07-06,arXiv,De Volta ao Básico: Revisitando as Linhas de Base de Detecção Fora da Distribuição,"Estudamos métodos simples para a detecção de imagens fora da distribuição (OOD) que são compatíveis com qualquer classificador já treinado, dependendo apenas de suas previsões ou representações aprendidas. Avaliando o desempenho da detecção OOD de vários métodos quando utilizados com os modelos ResNet-50 e Swin Transformer, descobrimos que métodos que consideram apenas as previsões do modelo podem ser facilmente superados ao também considerar as representações aprendidas. Com base em nossa análise, defendemos uma abordagem extremamente simples que foi negligenciada em outros estudos: simplesmente sinalizar como OOD imagens cuja distância média para seus K vizinhos mais próximos é grande (no espaço de representação de um classificador de imagens treinado com os dados em distribuição)."
JAFS2QVH,journalArticle,2022.0,"Bernhardt, Mélanie; Castro, Daniel C.; Tanno, Ryutaro; Schwaighofer, Anton; Tezcan, Kerem C.; Monteiro, Miguel; Bannur, Shruthi; Lungren, Matthew P.; Nori, Aditya; Glocker, Ben; Alvarez-Valle, Javier; Oktay, Ozan",Active label cleaning for improved dataset quality under resource constraints,10.1038/s41467-022-28818-3,https://www.nature.com/articles/s41467-022-28818-3,"Imperfections in data annotation, known as label noise, are detrimental to the training of machine learning models and have a confounding effect on the assessment of model performance. Nevertheless, employing experts to remove label noise by fully re-annotating large datasets is infeasible in resource-constrained settings, such as healthcare. This work advocates for a data-driven approach to prioritising samples for re-annotation—which we term “active label cleaning"". We propose to rank instances according to estimated label correctness and labelling difficulty of each sample, and introduce a simulation framework to evaluate relabelling efficacy. Our experiments on natural images and on a specifically-devised medical imaging benchmark show that cleaning noisy labels mitigates their negative impact on model training, evaluation, and selection. Crucially, the proposed approach enables correcting labels up to 4 × more effectively than typical random selection in realistic conditions, making better use of experts’ valuable time for improving dataset quality.",2022-03-04,,Limpeza ativa de rótulos para melhorar a qualidade do conjunto de dados sob restrições de recursos,"Imperfeições na anotação de dados, conhecidas como ruído de rótulo, são prejudiciais ao treinamento de modelos de aprendizado de máquina e têm um efeito confuso na avaliação do desempenho do modelo. No entanto, empregar especialistas para remover o ruído de rótulo por meio da reanotação completa de grandes conjuntos de dados é inviável em ambientes com recursos limitados, como a saúde. Este trabalho defende uma abordagem orientada por dados para priorizar amostras para reanotação — que chamamos de “limpeza ativa de rótulos”. Propomos classificar instâncias de acordo com a correção estimada do rótulo e a dificuldade de rotulagem de cada amostra, e introduzimos uma estrutura de simulação para avaliar a eficácia da reanotação. Nossos experimentos em imagens naturais e em um benchmark de imagem médica especificamente elaborado mostram que a limpeza de rótulos ruidosos mitiga seu impacto negativo no treinamento, avaliação e seleção do modelo. Crucialmente, a abordagem proposta permite corrigir rótulos de forma até 4 vezes mais eficaz do que a seleção aleatória típica em condições realistas, fazendo melhor uso do valioso tempo dos especialistas para melhorar a qualidade do conjunto de dados."
SFM554TH,thesis,2022.0,"Tekumalla, Ramya",When Silver Is As Good As Gold:  Using Weak Supervision to Train Machine Learning Models on Social Media Data,,https://scholarworks.gsu.edu/cs_diss/187,"<p>Over the last decade, advances in machine learning have led to an exponential growth in artificial intelligence i.e., machine learning models capable of learning from vast amounts of data to perform several tasks such as text classification, regression, machine translation, speech recognition, and many others. While massive volumes of data are available, due to the manual curation process involved in the generation of training datasets, only a percentage of the data is used to train machine learning models. The process of labeling data with a ground-truth value is extremely tedious, expensive, and is the major bottleneck of supervised learning. To curtail this, the theory of noisy learning can be employed where data labeled through heuristics, knowledge bases and weak classifiers can be utilized for training, instead of data obtained through manual annotation. The assumption here is that a large volume of training data, which contains noise and acquired through an automated process, can compensate for the lack of manual labels. In this study, we utilize heuristic based approaches to create noisy silver standard datasets. We extensively tested the theory of noisy learning on four different applications by training several machine learning models using the silver standard dataset with several sample sizes and class imbalances and tested the performance using a gold standard dataset. Our evaluations on the four applications indicate the success of silver standard datasets in identifying a gold standard dataset. We conclude the study with evidence that noisy social media data can be utilized for weak supervision</p>",2022,Georgia State University,Quando a Prata É Tão Boa Quanto o Ouro: Usando Supervisão Fraca para Treinar Modelos de Aprendizado de Máquina em Dados de Mídias Sociais,"<p>Ao longo da última década, os avanços em aprendizado de máquina levaram a um crescimento exponencial da inteligência artificial, ou seja, modelos de aprendizado de máquina capazes de aprender com vastas quantidades de dados para realizar várias tarefas, como classificação de texto, regressão, tradução automática, reconhecimento de fala, entre outras. Embora volumes massivos de dados estejam disponíveis, devido ao processo de curadoria manual envolvido na geração de conjuntos de dados de treinamento, apenas uma porcentagem dos dados é utilizada para treinar modelos de aprendizado de máquina. O processo de rotulagem de dados com um valor de verdade fundamental é extremamente tedioso, caro e é o principal gargalo do aprendizado supervisionado. Para contornar isso, a teoria do aprendizado ruidoso pode ser empregada, onde dados rotulados por meio de heurísticas, bases de conhecimento e classificadores fracos podem ser utilizados para treinamento, em vez de dados obtidos por meio de anotação manual. A suposição aqui é que um grande volume de dados de treinamento, que contém ruído e é adquirido por meio de um processo automatizado, pode compensar a falta de rótulos manuais. Neste estudo, utilizamos abordagens baseadas em heurísticas para criar conjuntos de dados de padrão prateado ruidoso. Testamos extensivamente a teoria do aprendizado ruidoso em quatro aplicações diferentes, treinando vários modelos de aprendizado de máquina usando o conjunto de dados de padrão prateado com vários tamanhos de amostra e desbalanceamentos de classe, e testamos o desempenho usando um conjunto de dados de padrão dourado. Nossas avaliações nas quatro aplicações indicam o sucesso dos conjuntos de dados de padrão prateado na identificação de um conjunto de dados de padrão dourado. Concluímos o estudo com evidências de que dados ruidosos de mídias sociais podem ser utilizados para supervisão fraca.</p>"
E6CR2LQI,preprint,2022.0,"Mazumder, Mark; Banbury, Colby; Yao, Xiaozhe; Karlaš, Bojan; Rojas, William Gaviria; Diamos, Sudnya; Diamos, Greg; He, Lynn; Kiela, Douwe; Jurado, David; Kanter, David; Mosquera, Rafael; Ciro, Juan; Aroyo, Lora; Acun, Bilge; Eyuboglu, Sabri; Ghorbani, Amirata; Goodman, Emmett; Kane, Tariq; Kirkpatrick, Christine R.; Kuo, Tzu-Sheng; Mueller, Jonas; Thrush, Tristan; Vanschoren, Joaquin; Warren, Margaret; Williams, Adina; Yeung, Serena; Ardalani, Newsha; Paritosh, Praveen; Zhang, Ce; Zou, James; Wu, Carole-Jean; Coleman, Cody; Ng, Andrew; Mattson, Peter; Reddi, Vijay Janapa",DataPerf: Benchmarks for Data-Centric AI Development,10.48550/arXiv.2207.10062,http://arxiv.org/abs/2207.10062,"Machine learning (ML) research has generally focused on models, while the most prominent datasets have been employed for everyday ML tasks without regard for the breadth, difficulty, and faithfulness of these datasets to the underlying problem. Neglecting the fundamental importance of datasets has caused major problems involving data cascades in real-world applications and saturation of dataset-driven criteria for model quality, hindering research growth. To solve this problem, we present DataPerf, a benchmark package for evaluating ML datasets and dataset-working algorithms. We intend it to enable the ""data ratchet,"" in which training sets will aid in evaluating test sets on the same problems, and vice versa. Such a feedback-driven strategy will generate a virtuous loop that will accelerate development of data-centric AI. The MLCommons Association will maintain DataPerf.",2022-07-20,arXiv,DataPerf: Referências para o Desenvolvimento de IA Centrada em Dados,"A pesquisa em aprendizado de máquina (ML) geralmente se concentrou em modelos, enquanto os conjuntos de dados mais proeminentes foram utilizados para tarefas cotidianas de ML sem considerar a amplitude, dificuldade e fidelidade desses conjuntos de dados em relação ao problema subjacente. Negligenciar a importância fundamental dos conjuntos de dados causou grandes problemas envolvendo cascatas de dados em aplicações do mundo real e saturação de critérios orientados por conjuntos de dados para a qualidade do modelo, dificultando o crescimento da pesquisa. Para resolver esse problema, apresentamos o DataPerf, um pacote de benchmark para avaliar conjuntos de dados de ML e algoritmos que trabalham com conjuntos de dados. Pretendemos que ele possibilite o ""catraca de dados"", na qual conjuntos de treinamento ajudarão na avaliação de conjuntos de teste nos mesmos problemas, e vice-versa. Essa estratégia orientada por feedback gerará um ciclo virtuoso que acelerará o desenvolvimento de IA centrada em dados. A Associação MLCommons manterá o DataPerf."
6LFJHKYH,journalArticle,,"Kuan, Johnson; Mueller, Jonas",Model-Agnostic Label Quality Scoring to Detect Real-World Label Errors,,,"We consider algorithms to find wrongly labeled data, which lurks in many real-world applications and hampers training/evaluation of ML models. We present the first empirical study of various scoring methods for this task on real datasets with naturally-occurring label errors (as opposed to synthetically introduced label errors). The label quality scores considered here can be utilized with arbitrary classification models. We examine five popular image recognition models (and ensembles thereof) to comprehensively characterize how well different scores detect label errors in practice.",,,Pontuação de Qualidade de Rótulo Independente de Modelo para Detectar Erros de Rótulo no Mundo Real,"Consideramos algoritmos para encontrar dados rotulados incorretamente, que estão presentes em muitas aplicações do mundo real e prejudicam o treinamento/avaliação de modelos de ML. Apresentamos o primeiro estudo empírico de vários métodos de pontuação para essa tarefa em conjuntos de dados reais com erros de rotulagem que ocorrem naturalmente (em oposição a erros de rotulagem introduzidos sinteticamente). Os escores de qualidade de rotulagem considerados aqui podem ser utilizados com modelos de classificação arbitrários. Examinamos cinco modelos populares de reconhecimento de imagem (e seus ensembles) para caracterizar de forma abrangente quão bem diferentes escores detectam erros de rotulagem na prática."
HSV6BU87,preprint,2017.0,"Northcutt, Curtis G.; Wu, Tailin; Chuang, Isaac L.",Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels,10.48550/arXiv.1705.01936,http://arxiv.org/abs/1705.01936,"Noisy PN learning is the problem of binary classification when training examples may be mislabeled (flipped) uniformly with noise rate rho1 for positive examples and rho0 for negative examples. We propose Rank Pruning (RP) to solve noisy PN learning and the open problem of estimating the noise rates, i.e. the fraction of wrong positive and negative labels. Unlike prior solutions, RP is time-efficient and general, requiring O(T) for any unrestricted choice of probabilistic classifier with T fitting time. We prove RP has consistent noise estimation and equivalent expected risk as learning with uncorrupted labels in ideal conditions, and derive closed-form solutions when conditions are non-ideal. RP achieves state-of-the-art noise estimation and F1, error, and AUC-PR for both MNIST and CIFAR datasets, regardless of the amount of noise and performs similarly impressively when a large portion of training examples are noise drawn from a third distribution. To highlight, RP with a CNN classifier can predict if an MNIST digit is a ""one""or ""not"" with only 0.25% error, and 0.46 error across all digits, even when 50% of positive examples are mislabeled and 50% of observed positive labels are mislabeled negative examples.",2017-08-09,arXiv,Aprendizado com Exemplos Confiantes: Poda de Classificação para Classificação Robusta com Rótulos Ruins,"O aprendizado PN ruidoso é o problema da classificação binária quando exemplos de treinamento podem estar rotulados incorretamente (invertidos) uniformemente com taxa de ruído rho1 para exemplos positivos e rho0 para exemplos negativos. Propomos o Rank Pruning (RP) para resolver o aprendizado PN ruidoso e o problema em aberto de estimar as taxas de ruído, ou seja, a fração de rótulos positivos e negativos errados. Ao contrário de soluções anteriores, o RP é eficiente em termos de tempo e geral, exigindo O(T) para qualquer escolha irrestrita de classificador probabilístico com tempo de ajuste T. Provamos que o RP tem estimativa de ruído consistente e risco esperado equivalente ao aprendizado com rótulos não corrompidos em condições ideais, e derivamos soluções em forma fechada quando as condições não são ideais. O RP alcança estimativa de ruído de ponta e F1, erro e AUC-PR para os conjuntos de dados MNIST e CIFAR, independentemente da quantidade de ruído, e apresenta desempenho semelhante impressionante quando uma grande parte dos exemplos de treinamento é ruído extraído de uma terceira distribuição. Para destacar, o RP com um classificador CNN pode prever se um dígito MNIST é um ""um"" ou ""não"" com apenas 0,25% de erro, e 0,46 de erro em todos os dígitos, mesmo quando 50% dos exemplos positivos estão rotulados incorretamente e 50% dos rótulos positivos observados são exemplos negativos rotulados incorretamente."
P9A2TMLX,preprint,2022.0,"Song, Hwanjun; Kim, Minseok; Park, Dongmin; Shin, Yooju; Lee, Jae-Gil",Learning from Noisy Labels with Deep Neural Networks: A Survey,10.48550/arXiv.2007.08199,http://arxiv.org/abs/2007.08199,"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies. All the contents will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.",2022-03-09,arXiv,Aprendendo com Rótulos Ruidosos com Redes Neurais Profundas: Uma Revisão,"O aprendizado profundo alcançou um sucesso notável em numerosos domínios com a ajuda de grandes quantidades de big data. No entanto, a qualidade das etiquetas de dados é uma preocupação devido à falta de etiquetas de alta qualidade em muitos cenários do mundo real. Como etiquetas ruidosas degradam severamente o desempenho de generalização das redes neurais profundas, aprender com etiquetas ruidosas (treinamento robusto) está se tornando uma tarefa importante nas aplicações modernas de aprendizado profundo. Neste levantamento, primeiro descrevemos o problema de aprender com ruído nas etiquetas a partir de uma perspectiva de aprendizado supervisionado. Em seguida, fornecemos uma revisão abrangente de 62 métodos de treinamento robusto de última geração, todos os quais são categorizados em cinco grupos de acordo com suas diferenças metodológicas, seguidos por uma comparação sistemática de seis propriedades usadas para avaliar sua superioridade. Subsequentemente, realizamos uma análise aprofundada da estimativa da taxa de ruído e resumimos a metodologia de avaliação tipicamente utilizada, incluindo conjuntos de dados ruidosos públicos e métricas de avaliação. Finalmente, apresentamos várias direções de pesquisa promissoras que podem servir como diretrizes para estudos futuros. Todo o conteúdo estará disponível em https://github.com/songhwanjun/Awesome-Noisy-Labels."
YR9IVCRD,preprint,2020.0,"Jiang, Lu; Huang, Di; Liu, Mason; Yang, Weilong",Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels,10.48550/arXiv.1911.09781,http://arxiv.org/abs/1911.09781,"Performing controlled experiments on noisy data is essential in understanding deep learning across noise levels. Due to the lack of suitable datasets, previous research has only examined deep learning on controlled synthetic label noise, and real-world label noise has never been studied in a controlled setting. This paper makes three contributions. First, we establish the first benchmark of controlled real-world label noise from the web. This new benchmark enables us to study the web label noise in a controlled setting for the first time. The second contribution is a simple but effective method to overcome both synthetic and real noisy labels. We show that our method achieves the best result on our dataset as well as on two public benchmarks (CIFAR and WebVision). Third, we conduct the largest study by far into understanding deep neural networks trained on noisy labels across different noise levels, noise types, network architectures, and training settings. The data and code are released at the following link: http://www.lujiang.info/cnlw.html",2020-08-27,arXiv,Além do Ruído Sintético: Aprendizado Profundo em Rótulos Ruidosos Controlados,"Realizar experimentos controlados em dados ruidosos é essencial para entender o aprendizado profundo em diferentes níveis de ruído. Devido à falta de conjuntos de dados adequados, pesquisas anteriores examinaram apenas o aprendizado profundo em ruído de rótulo sintético controlado, e o ruído de rótulo do mundo real nunca foi estudado em um ambiente controlado. Este artigo faz três contribuições. Primeiro, estabelecemos o primeiro benchmark de ruído de rótulo real controlado da web. Este novo benchmark nos permite estudar o ruído de rótulo da web em um ambiente controlado pela primeira vez. A segunda contribuição é um método simples, mas eficaz, para superar tanto rótulos sintéticos quanto ruidosos reais. Mostramos que nosso método alcança o melhor resultado em nosso conjunto de dados, bem como em dois benchmarks públicos (CIFAR e WebVision). Por fim, realizamos o maior estudo até agora para entender redes neurais profundas treinadas com rótulos ruidosos em diferentes níveis de ruído, tipos de ruído, arquiteturas de rede e configurações de treinamento. Os dados e o código estão disponíveis no seguinte link: http://www.lujiang.info/cnlw.html"
6PWSV8QE,preprint,2023.0,"Yu, Peilin; Bach, Stephen H.",Alfred: A System for Prompted Weak Supervision,10.48550/arXiv.2305.18623,http://arxiv.org/abs/2305.18623,"Alfred is the first system for programmatic weak supervision (PWS) that creates training data for machine learning by prompting. In contrast to typical PWS systems where weak supervision sources are programs coded by experts, Alfred enables users to encode their subject matter expertise via natural language prompts for language and vision-language models. Alfred provides a simple Python interface for the key steps of this emerging paradigm, with a high-throughput backend for large-scale data labeling. Users can quickly create, evaluate, and refine their prompt-based weak supervision sources; map the results to weak labels; and resolve their disagreements with a label model. Alfred enables a seamless local development experience backed by models served from self-managed computing clusters. It automatically optimizes the execution of prompts with optimized batching mechanisms. We find that this optimization improves query throughput by 2.9x versus a naive approach. We present two example use cases demonstrating Alfred on YouTube comment spam detection and pet breeds classification. Alfred is open source, available at https://github.com/BatsResearch/alfred.",2023-05-29,arXiv,Alfred: Um Sistema para Supervisão Fraca com Indicações,"Alfred é o primeiro sistema de supervisão fraca programática (PWS) que cria dados de treinamento para aprendizado de máquina por meio de prompts. Em contraste com sistemas típicos de PWS, onde as fontes de supervisão fraca são programas codificados por especialistas, Alfred permite que os usuários codifiquem sua expertise em assuntos por meio de prompts em linguagem natural para modelos de linguagem e modelos de linguagem-visual. Alfred fornece uma interface Python simples para as etapas-chave desse paradigma emergente, com um backend de alto rendimento para rotulagem de dados em larga escala. Os usuários podem rapidamente criar, avaliar e refinar suas fontes de supervisão fraca baseadas em prompts; mapear os resultados para rótulos fracos; e resolver suas discordâncias com um modelo de rótulo. Alfred permite uma experiência de desenvolvimento local sem costura, apoiada por modelos servidos a partir de clusters de computação autogerenciados. Ele otimiza automaticamente a execução de prompts com mecanismos de agrupamento otimizados. Descobrimos que essa otimização melhora a taxa de consulta em 2,9x em comparação com uma abordagem ingênua. Apresentamos dois casos de uso exemplares demonstrando Alfred na detecção de spam em comentários do YouTube e na classificação de raças de animais de estimação. Alfred é de código aberto, disponível em https://github.com/BatsResearch/alfred."
AWIST87V,preprint,2022.0,"Wang, Wei-Chen; Mueller, Jonas",Detecting Label Errors in Token Classification Data,10.48550/arXiv.2210.03920,http://arxiv.org/abs/2210.03920,"Mislabeled examples are a common issue in real-world data, particularly for tasks like token classification where many labels must be chosen on a fine-grained basis. Here we consider the task of finding sentences that contain label errors in token classification datasets. We study 11 different straightforward methods that score tokens/sentences based on the predicted class probabilities output by a (any) token classification model (trained via any procedure). In precision-recall evaluations based on real-world label errors in entity recognition data from CoNLL-2003, we identify a simple and effective method that consistently detects those sentences containing label errors when applied with different token classification models.",2022-10-08,arXiv,Detectando Erros de Rótulo em Dados de Classificação de Tokens,"Exemplos rotulados incorretamente são um problema comum em dados do mundo real, particularmente para tarefas como classificação de tokens, onde muitos rótulos devem ser escolhidos de forma detalhada. Aqui, consideramos a tarefa de encontrar frases que contêm erros de rótulo em conjuntos de dados de classificação de tokens. Estudamos 11 métodos diferentes e diretos que pontuam tokens/frases com base nas probabilidades de classe previstas geradas por um (qualquer) modelo de classificação de tokens (treinado por qualquer procedimento). Em avaliações de precisão-revocação baseadas em erros de rótulo do mundo real em dados de reconhecimento de entidades do CoNLL-2003, identificamos um método simples e eficaz que detecta consistentemente aquelas frases que contêm erros de rótulo quando aplicado com diferentes modelos de classificação de tokens."
33F2G8LS,conferencePaper,2019.0,"Geva, Mor; Goldberg, Yoav; Berant, Jonathan",Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets,10.18653/v1/D19-1107,https://www.aclweb.org/anthology/D19-1107,"Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identiﬁers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our ﬁndings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.",2019,Association for Computational Linguistics,Estamos Modelando a Tarefa ou o Anotador? Uma Investigação do Viés do Anotador em Conjuntos de Dados de Compreensão de Linguagem Natural,"O crowdsourcing tem sido o paradigma prevalente para a criação de conjuntos de dados de compreensão de linguagem natural nos últimos anos. Uma prática comum de crowdsourcing é recrutar um pequeno número de trabalhadores de alta qualidade e fazer com que eles gerem exemplos em massa. Ter apenas alguns trabalhadores gerando a maioria dos exemplos levanta preocupações sobre a diversidade dos dados, especialmente quando os trabalhadores geram frases livremente. Neste artigo, realizamos uma série de experimentos que mostram que essas preocupações são evidentes em três conjuntos de dados recentes de PLN. Mostramos que o desempenho do modelo melhora quando treinado com identificadores de anotadores como características, e que os modelos são capazes de reconhecer os anotadores mais produtivos. Além disso, mostramos que frequentemente os modelos não generalizam bem para exemplos de anotadores que não contribuíram para o conjunto de treinamento. Nossas descobertas sugerem que o viés dos anotadores deve ser monitorado durante a criação do conjunto de dados, e que os anotadores do conjunto de teste devem ser distintos dos anotadores do conjunto de treinamento."
TWC3HEVG,journalArticle,2015.0,"Aroyo, Lora; Welty, Chris",Truth Is a Lie: Crowd Truth and the Seven Myths of Human Annotation,10.1609/aimag.v36i1.2564,https://onlinelibrary.wiley.com/doi/10.1609/aimag.v36i1.2564,,2015-03,,A Verdade é uma Mentira: A Verdade da Multidão e os Sete Mitos da Anotação Humana,nan
ZIQ7ZIWH,journalArticle,,"Konyushkova, Ksenia; Sznitman, Raphael; Fua, Pascal",Learning Active Learning from Data,,,"In this paper, we suggest a novel data-driven approach to active learning (AL). The key idea is to train a regressor that predicts the expected error reduction for a candidate sample in a particular learning state. By formulating the query selection procedure as a regression problem we are not restricted to working with existing AL heuristics; instead, we learn strategies based on experience from previous AL outcomes. We show that a strategy can be learnt either from simple synthetic 2D datasets or from a subset of domain-speciﬁc data. Our method yields strategies that work well on real data from a wide range of domains.",,,Aprendendo Aprendizagem Ativa a partir de Dados,"Neste artigo, sugerimos uma nova abordagem orientada por dados para aprendizado ativo (AL). A ideia principal é treinar um regressor que prevê a redução esperada do erro para uma amostra candidata em um estado de aprendizado particular. Ao formular o procedimento de seleção de consultas como um problema de regressão, não estamos restritos a trabalhar com heurísticas de AL existentes; em vez disso, aprendemos estratégias com base na experiência de resultados anteriores de AL. Mostramos que uma estratégia pode ser aprendida tanto a partir de conjuntos de dados sintéticos 2D simples quanto de um subconjunto de dados específicos de domínio. Nosso método produz estratégias que funcionam bem em dados reais de uma ampla gama de domínios."
F3KQJY2K,journalArticle,2014.0,"Frenay, Benoit; Verleysen, Michel",Classification in the Presence of Label Noise: A Survey,10.1109/TNNLS.2013.2292894,http://ieeexplore.ieee.org/document/6685834/,"Label noise is an important issue in classiﬁcation, with many potential negative consequences. For example, the accuracy of predictions may decrease, whereas the complexity of inferred models and the number of necessary training samples may increase. Many works in the literature have been devoted to the study of label noise and the development of techniques to deal with label noise. However, the ﬁeld lacks a comprehensive survey on the different types of label noise, their consequences and the algorithms that consider label noise. This paper proposes to ﬁll this gap. First, the deﬁnitions and sources of label noise are considered and a taxonomy of the types of label noise is proposed. Second, the potential consequences of label noise are discussed. Third, label noise-robust, label noise cleansing, and label noise-tolerant algorithms are reviewed. For each category of approaches, a short discussion is proposed to help the practitioner to choose the most suitable technique in its own particular ﬁeld of application. Eventually, the design of experiments is also discussed, what may interest the researchers who would like to test their own algorithms. In this paper, label noise consists of mislabeled instances: no additional information is assumed to be available like e.g. conﬁdences on labels.",2014-05,,Classificação na Presença de Ruído de Rótulo: Uma Revisão,"O ruído de rótulo é uma questão importante na classificação, com muitas consequências negativas potenciais. Por exemplo, a precisão das previsões pode diminuir, enquanto a complexidade dos modelos inferidos e o número de amostras de treinamento necessárias podem aumentar. Muitos trabalhos na literatura foram dedicados ao estudo do ruído de rótulo e ao desenvolvimento de técnicas para lidar com o ruído de rótulo. No entanto, o campo carece de uma pesquisa abrangente sobre os diferentes tipos de ruído de rótulo, suas consequências e os algoritmos que consideram o ruído de rótulo. Este artigo propõe preencher essa lacuna. Primeiro, as definições e fontes de ruído de rótulo são consideradas e uma taxonomia dos tipos de ruído de rótulo é proposta. Em segundo lugar, as potenciais consequências do ruído de rótulo são discutidas. Em terceiro lugar, algoritmos robustos ao ruído de rótulo, de limpeza de ruído de rótulo e tolerantes ao ruído de rótulo são revisados. Para cada categoria de abordagens, uma breve discussão é proposta para ajudar o praticante a escolher a técnica mais adequada em seu próprio campo de aplicação. Eventualmente, o design de experimentos também é discutido, o que pode interessar aos pesquisadores que gostariam de testar seus próprios algoritmos. Neste artigo, o ruído de rótulo consiste em instâncias rotuladas incorretamente: nenhuma informação adicional é assumida como disponível, como, por exemplo, confianças nos rótulos."
QEL72NQB,journalArticle,2017.0,"Prelec, Dražen; Seung, H. Sebastian; McCoy, John",A solution to the single-question crowd wisdom problem,10.1038/nature21054,https://www.nature.com/articles/nature21054,,2017-01,,Uma solução para o problema da sabedoria das multidões com uma única pergunta,nan
TQA6EM6L,conferencePaper,2022.0,"Zhang, Jieyu; Wang, Haonan; Hsieh, Cheng-Yu; Ratner, Alexander J",Understanding Programmatic Weak Supervision via Source-aware Influence Function,,https://proceedings.neurips.cc/paper_files/paper/2022/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf,,2022,"Curran Associates, Inc.",Entendendo a Supervisão Fraca Programática por meio da Função de Influência Consciente da Fonte,nan
IIA64MTQ,journalArticle,2020.0,"Nashaat, Mona; Ghosh, Aindrila; Miller, James; Quader, Shaikh",Asterisk: Generating Large Training Datasets with Automatic Active Supervision,10.1145/3385188,https://dl.acm.org/doi/10.1145/3385188,"Labeling datasets is one of the most expensive bottlenecks in data preprocessing tasks in machine learning. Therefore, organizations, in many domains, are applying weak supervision to produce noisy labels. However, since weak supervision relies on cheaper sources, the quality of the generated labels is problematic. Therefore, in this article, we present Asterisk, an end-to-end framework to generate high-quality, large-scale labeled datasets. The system, first, automatically generates heuristics to assign initial labels. Then, the framework applies a novel data-driven active learning process to enhance the labeling quality. We present an algorithm that learns the selection policy by accommodating the modeled accuracies of the heuristics, along with the outcome of the generative model. Finally, the system employs the output of the active learning process to enhance the quality of the labels. To evaluate the proposed system, we report its performance against four state-of-the-art techniques. In collaboration with our industrial partner, IBM, we test the framework within a wide range of real-world applications. The experiments include 10 datasets of varying sizes with a maximum size of 11 million records. The results illustrate the effectiveness of the framework in producing high-quality labels and achieving high classification accuracy with minimal annotation efforts.",2020-05-30,,Asterisco: Gerando Grandes Conjuntos de Dados de Treinamento com Supervisão Ativa Automática,"A rotulagem de conjuntos de dados é um dos gargalos mais caros nas tarefas de pré-processamento de dados em aprendizado de máquina. Portanto, organizações, em muitos domínios, estão aplicando supervisão fraca para produzir rótulos ruidosos. No entanto, como a supervisão fraca depende de fontes mais baratas, a qualidade dos rótulos gerados é problemática. Portanto, neste artigo, apresentamos o Asterisk, uma estrutura de ponta a ponta para gerar conjuntos de dados rotulados de alta qualidade e em grande escala. O sistema, primeiro, gera automaticamente heurísticas para atribuir rótulos iniciais. Em seguida, a estrutura aplica um novo processo de aprendizado ativo orientado por dados para melhorar a qualidade da rotulagem. Apresentamos um algoritmo que aprende a política de seleção acomodando as precisões modeladas das heurísticas, juntamente com o resultado do modelo generativo. Finalmente, o sistema utiliza a saída do processo de aprendizado ativo para aprimorar a qualidade dos rótulos. Para avaliar o sistema proposto, relatamos seu desempenho em relação a quatro técnicas de ponta. Em colaboração com nosso parceiro industrial, a IBM, testamos a estrutura em uma ampla gama de aplicações do mundo real. Os experimentos incluem 10 conjuntos de dados de tamanhos variados, com um tamanho máximo de 11 milhões de registros. Os resultados ilustram a eficácia da estrutura na produção de rótulos de alta qualidade e na obtenção de alta precisão de classificação com esforços mínimos de anotação."
SVHBQ2EA,preprint,2020.0,"Fu, Daniel Y.; Chen, Mayee F.; Sala, Frederic; Hooper, Sarah M.; Fatahalian, Kayvon; Ré, Christopher",Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods,10.48550/arXiv.2002.11955,http://arxiv.org/abs/2002.11955,"Weak supervision is a popular method for building machine learning models without relying on ground truth annotations. Instead, it generates probabilistic training labels by estimating the accuracies of multiple noisy labeling sources (e.g., heuristics, crowd workers). Existing approaches use latent variable estimation to model the noisy sources, but these methods can be computationally expensive, scaling superlinearly in the data. In this work, we show that, for a class of latent variable models highly applicable to weak supervision, we can find a closed-form solution to model parameters, obviating the need for iterative solutions like stochastic gradient descent (SGD). We use this insight to build FlyingSquid, a weak supervision framework that runs orders of magnitude faster than previous weak supervision approaches and requires fewer assumptions. In particular, we prove bounds on generalization error without assuming that the latent variable model can exactly parameterize the underlying data distribution. Empirically, we validate FlyingSquid on benchmark weak supervision datasets and find that it achieves the same or higher quality compared to previous approaches without the need to tune an SGD procedure, recovers model parameters 170 times faster on average, and enables new video analysis and online learning applications.",2020-07-15,arXiv,Rápido e Três-ioso: Acelerando a Supervisão Fraca com Métodos de Tripleta,"A supervisão fraca é um método popular para construir modelos de aprendizado de máquina sem depender de anotações de verdade de base. Em vez disso, ela gera rótulos de treinamento probabilísticos ao estimar as precisões de várias fontes de rotulagem ruidosas (por exemplo, heurísticas, trabalhadores da multidão). Abordagens existentes usam estimativa de variáveis latentes para modelar as fontes ruidosas, mas esses métodos podem ser computacionalmente caros, escalando de forma superlinear nos dados. Neste trabalho, mostramos que, para uma classe de modelos de variáveis latentes altamente aplicáveis à supervisão fraca, podemos encontrar uma solução em forma fechada para os parâmetros do modelo, eliminando a necessidade de soluções iterativas como o gradiente estocástico (SGD). Usamos essa percepção para construir o FlyingSquid, uma estrutura de supervisão fraca que opera ordens de magnitude mais rápido do que abordagens anteriores de supervisão fraca e requer menos suposições. Em particular, provamos limites sobre o erro de generalização sem assumir que o modelo de variável latente pode parametrizar exatamente a distribuição de dados subjacente. Empiricamente, validamos o FlyingSquid em conjuntos de dados de supervisão fraca de referência e descobrimos que ele alcança a mesma qualidade ou superior em comparação com abordagens anteriores, sem a necessidade de ajustar um procedimento SGD, recupera os parâmetros do modelo 170 vezes mais rápido em média e possibilita novas aplicações de análise de vídeo e aprendizado online."
EGBIA5S6,preprint,2019.0,"Dunnmon, Jared; Ratner, Alexander; Khandwala, Nishith; Saab, Khaled; Markert, Matthew; Sagreiya, Hersh; Goldman, Roger; Lee-Messer, Christopher; Lungren, Matthew; Rubin, Daniel; Ré, Christopher",Cross-Modal Data Programming Enables Rapid Medical Machine Learning,10.48550/arXiv.1903.11101,http://arxiv.org/abs/1903.11101,"Labeling training datasets has become a key barrier to building medical machine learning models. One strategy is to generate training labels programmatically, for example by applying natural language processing pipelines to text reports associated with imaging studies. We propose cross-modal data programming, which generalizes this intuitive strategy in a theoretically-grounded way that enables simpler, clinician-driven input, reduces required labeling time, and improves with additional unlabeled data. In this approach, clinicians generate training labels for models defined over a target modality (e.g. images or time series) by writing rules over an auxiliary modality (e.g. text reports). The resulting technical challenge consists of estimating the accuracies and correlations of these rules; we extend a recent unsupervised generative modeling technique to handle this cross-modal setting in a provably consistent way. Across four applications in radiography, computed tomography, and electroencephalography, and using only several hours of clinician time, our approach matches or exceeds the efficacy of physician-months of hand-labeling with statistical significance, demonstrating a fundamentally faster and more flexible way of building machine learning models in medicine.",2019-03-26,arXiv,A Programação de Dados Cross-Modal Permite Aprendizado de Máquina Médico Rápido,"A rotulagem de conjuntos de dados de treinamento tornou-se uma barreira chave para a construção de modelos de aprendizado de máquina na medicina. Uma estratégia é gerar rótulos de treinamento programaticamente, por exemplo, aplicando pipelines de processamento de linguagem natural a relatórios de texto associados a estudos de imagem. Propomos a programação de dados cross-modal, que generaliza essa estratégia intuitiva de uma maneira teoricamente fundamentada que permite uma entrada mais simples, dirigida por clínicos, reduz o tempo de rotulagem necessário e melhora com dados não rotulados adicionais. Nesta abordagem, os clínicos geram rótulos de treinamento para modelos definidos sobre uma modalidade alvo (por exemplo, imagens ou séries temporais) escrevendo regras sobre uma modalidade auxiliar (por exemplo, relatórios de texto). O desafio técnico resultante consiste em estimar as precisões e correlações dessas regras; estendemos uma técnica recente de modelagem generativa não supervisionada para lidar com esse cenário cross-modal de maneira provadamente consistente. Em quatro aplicações em radiografia, tomografia computadorizada e eletroencefalografia, e utilizando apenas algumas horas de tempo de clínicos, nossa abordagem iguala ou supera a eficácia de meses de rotulagem manual por médicos com significância estatística, demonstrando uma maneira fundamentalmente mais rápida e flexível de construir modelos de aprendizado de máquina na medicina."
CMJ7N875,journalArticle,,"Li, Jeffrey; Zhang, Jieyu; Schmidt, Ludwig; Ratner, Alexander",Characterizing the Impacts of Semi-supervised Learning for Weak Supervision,,https://dmlr.ai/assets/accepted-papers/107/CameraReady/SSL4WS_ICML_Workshop_DMLR.pdf,"Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples.",,,Caracterizando os Impactos do Aprendizado Semi-supervisionado para Supervisão Fraca,"A rotulagem de dados de treinamento é uma etapa crítica e cara na produção de modelos de ML de alta precisão, seja treinando do zero ou fazendo ajuste fino. Para tornar a rotulagem mais eficiente, duas abordagens principais são a supervisão fraca programática (WS) e o aprendizado semi-supervisionado (SSL). Trabalhos mais recentes têm usado, de forma explícita ou implícita, técnicas em sua interseção, mas de maneiras complexas e ad hoc. Neste trabalho, definimos um espaço de design simples e modular para estudar o uso de técnicas de SSL para WS de forma mais sistemática. Surpreendentemente, descobrimos que métodos bastante simples do nosso espaço de design igualam o desempenho de métodos mais complexos de última geração, com um aumento médio de 3 pontos percentuais na precisão/score F1 em 8 benchmarks padrão de WS. Além disso, fornecemos orientações práticas sobre quando diferentes componentes valem sua complexidade e custos de treinamento adicionais. Contrariamente ao entendimento atual, descobrimos que usar SSL não é necessário para obter o melhor desempenho na maioria dos benchmarks de WS, mas é mais eficaz quando: (1) os modelos finais são menores e (2) a WS fornece rótulos para apenas uma pequena parte dos exemplos de treinamento."
39HEVSWV,journalArticle,,"Haim, Niv; Vardi, Gal; Yehudai, Gilad; Shamir, Ohad; Irani, Michal",Reconstructing Training Data from Trained Neural Networks,,,"Understanding to what extent neural networks memorize training data is an intriguing question with practical and theoretical implications. In this paper we show that in some cases a significant fraction of the training data can in fact be reconstructed from the parameters of a trained neural network classifier. We propose a novel reconstruction scheme that stems from recent theoretical results about the implicit bias in training neural networks with gradient-based methods. To the best of our knowledge, our results are the first to show that reconstructing a large portion of the actual training samples from a trained neural network classifier is generally possible. This has negative implications on privacy, as it can be used as an attack for revealing sensitive training data. We demonstrate our method for binary MLP classifiers on a few standard computer vision datasets.",,,Reconstruindo Dados de Treinamento a partir de Redes Neurais Treinadas,"Entender até que ponto as redes neurais memorizam os dados de treinamento é uma questão intrigante com implicações práticas e teóricas. Neste artigo, mostramos que, em alguns casos, uma fração significativa dos dados de treinamento pode, de fato, ser reconstruída a partir dos parâmetros de um classificador de rede neural treinado. Propomos um novo esquema de reconstrução que decorre de resultados teóricos recentes sobre o viés implícito no treinamento de redes neurais com métodos baseados em gradiente. Até onde sabemos, nossos resultados são os primeiros a mostrar que reconstruir uma grande parte das amostras de treinamento reais a partir de um classificador de rede neural treinado é geralmente possível. Isso tem implicações negativas para a privacidade, pois pode ser usado como um ataque para revelar dados de treinamento sensíveis. Demonstramos nosso método para classificadores MLP binários em alguns conjuntos de dados padrão de visão computacional."
UEPIBA7R,journalArticle,2022.0,"Kong, Shuming; Shen, Yanyan; Huang, Linpeng",RESOLVING TRAINING BIASES VIA INFLUENCE- BASED DATA RELABELING,,,"The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Inﬂuence function is a technique that estimates the impacts of a training sample on the model’s predictions. Recent studies on data resampling have employed inﬂuence functions to identify harmful training samples that will degrade model’s test performance. They have shown that discarding or downweighting the identiﬁed harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an inﬂuence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use inﬂuence functions to estimate how relabeling a training sample would affect model’s test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classiﬁcation tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model’s robustness against label noise.",2022,,RESOLUÇÃO DE VIÉS DE TREINAMENTO VIA REETIQUETAGEM DE DADOS BASEADA EM INFLUÊNCIA,"O desempenho dos métodos de aprendizado supervisionado facilmente sofre com o problema de viés de treinamento causado pela discrepância entre as distribuições de treino e teste ou pelo ruído nos rótulos. A função de influência é uma técnica que estima os impactos de uma amostra de treinamento nas previsões do modelo. Estudos recentes sobre reamostragem de dados empregaram funções de influência para identificar amostras de treinamento prejudiciais que degradarão o desempenho do modelo em testes. Eles mostraram que descartar ou reduzir o peso das amostras de treinamento prejudiciais identificadas é uma maneira eficaz de resolver os viéses de treinamento. Neste trabalho, damos um passo adiante e propomos uma estrutura de reetiquetagem baseada em influência chamada RDIA para reutilizar amostras de treinamento prejudiciais em direção a um melhor desempenho do modelo. Para alcançar isso, usamos funções de influência para estimar como a reetiquetagem de uma amostra de treinamento afetaria o desempenho do modelo em testes e desenvolvemos ainda uma nova função de reetiquetagem R. Provamos teoricamente que aplicar R para reetiquetar amostras de treinamento prejudiciais permite que o modelo alcance uma perda de teste menor do que simplesmente descartá-las para qualquer tarefa de classificação usando perda de entropia cruzada. Experimentos extensivos em dez conjuntos de dados do mundo real demonstram que o RDIA supera os métodos de reamostragem de dados de ponta e melhora a robustez do modelo contra ruído nos rótulos."
66AM3T9E,conferencePaper,2019.0,"Koh, Pang Wei W; Ang, Kai-Siang; Teo, Hubert; Liang, Percy S",On the Accuracy of Influence Functions for Measuring Group Effects,,https://proceedings.neurips.cc/paper_files/paper/2019/hash/a78482ce76496fcf49085f2190e675b4-Abstract.html,"Influence functions estimate the effect of removing a training point on a model without the need to retrain. They are based on a first-order Taylor approximation that is guaranteed to be accurate for sufficiently small changes to the model, and so are commonly used to study the effect of individual points in large datasets. However, we often want to study the effects of large groups of training points, e.g., to diagnose batch effects or apportion credit between different data sources. Removing such large groups can result in significant changes to the model. Are influence functions still accurate in this setting? In this paper, we find that across many different types of groups and for a range of real-world datasets, the predicted effect (using influence functions) of a group correlates surprisingly well with its actual effect, even if the absolute and relative errors are large. Our theoretical analysis shows that such strong correlation arises only under certain settings and need not hold in general, indicating that real-world datasets have particular properties that allow the influence approximation to be accurate.",2019,"Curran Associates, Inc.",Sobre a Precisão das Funções de Influência para Medir Efeitos de Grupo,"Funções de influência estimam o efeito de remover um ponto de treinamento em um modelo sem a necessidade de re-treinamento. Elas são baseadas em uma aproximação de Taylor de primeira ordem que é garantida para ser precisa para mudanças suficientemente pequenas no modelo, e por isso são comumente usadas para estudar o efeito de pontos individuais em grandes conjuntos de dados. No entanto, muitas vezes queremos estudar os efeitos de grandes grupos de pontos de treinamento, por exemplo, para diagnosticar efeitos de lote ou distribuir crédito entre diferentes fontes de dados. Remover tais grandes grupos pode resultar em mudanças significativas no modelo. As funções de influência ainda são precisas nesse contexto? Neste artigo, encontramos que, em muitos tipos diferentes de grupos e para uma variedade de conjuntos de dados do mundo real, o efeito previsto (usando funções de influência) de um grupo correlaciona-se surpreendentemente bem com seu efeito real, mesmo que os erros absolutos e relativos sejam grandes. Nossa análise teórica mostra que essa forte correlação surge apenas sob certas condições e não precisa ser válida em geral, indicando que conjuntos de dados do mundo real têm propriedades particulares que permitem que a aproximação de influência seja precisa."
N3Y3LDM5,preprint,2023.0,"Zhu, Yiming; Zhang, Peixian; Haq, Ehsan-Ul; Hui, Pan; Tyson, Gareth",Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks,10.48550/arXiv.2304.10145,http://arxiv.org/abs/2304.10145,"The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to relabel five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average accuracy 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploitation of ChatGPT for human annotation tasks.",2023-04-22,arXiv,O ChatGPT Pode Reproduzir Rótulos Gerados por Humanos? Um Estudo de Tarefas de Computação Social,"O lançamento do ChatGPT revelou uma série de possibilidades pelas quais grandes modelos de linguagem (LLMs) podem substituir a inteligência humana. Neste artigo, buscamos entender se o ChatGPT tem o potencial de reproduzir anotações de rótulos geradas por humanos em tarefas de computação social. Tal conquista poderia reduzir significativamente o custo e a complexidade da pesquisa em computação social. Assim, usamos o ChatGPT para reanotar cinco conjuntos de dados seminais cobrindo detecção de postura (2x), análise de sentimentos, discurso de ódio e detecção de bots. Nossos resultados destacam que o ChatGPT tem, de fato, o potencial de lidar com essas tarefas de anotação de dados, embora vários desafios permaneçam. O ChatGPT obtém uma precisão média de 0,609. O desempenho é mais alto para o conjunto de dados de análise de sentimentos, com o ChatGPT anotando corretamente 64,9% dos tweets. No entanto, mostramos que o desempenho varia substancialmente entre os rótulos individuais. Acreditamos que este trabalho pode abrir novas linhas de análise e servir como base para futuras pesquisas sobre a exploração do ChatGPT para tarefas de anotação humana."
RWWAJ4UN,preprint,2023.0,"Zhou, Hang; Mueller, Jonas; Kumar, Mayank; Wang, Jane-Ling; Lei, Jing",Detecting Errors in Numerical Data via any Regression Model,10.48550/arXiv.2305.16583,http://arxiv.org/abs/2305.16583,"Noise plagues many numerical datasets, where the recorded values in the data may fail to match the true underlying values due to reasons including: erroneous sensors, data entry/processing mistakes, or imperfect human estimates. Here we consider estimating which data values are incorrect along a numerical column. We present a model-agnostic approach that can utilize any regressor (i.e. statistical or machine learning model) which was fit to predict values in this column based on the other variables in the dataset. By accounting for various uncertainties, our approach distinguishes between genuine anomalies and natural data fluctuations, conditioned on the available information in the dataset. We establish theoretical guarantees for our method and show that other approaches like conformal inference struggle to detect errors. We also contribute a new error detection benchmark involving 5 regression datasets with real-world numerical errors (for which the true values are also known). In this benchmark and additional simulation studies, our method identifies incorrect values with better precision/recall than other approaches.",2023-06-02,arXiv,Detectando Erros em Dados Numéricos através de Qualquer Modelo de Regressão,"O ruído afeta muitos conjuntos de dados numéricos, onde os valores registrados nos dados podem não corresponder aos verdadeiros valores subjacentes devido a razões como: sensores errôneos, erros de entrada/processamento de dados ou estimativas humanas imperfeitas. Aqui consideramos estimar quais valores de dados estão incorretos ao longo de uma coluna numérica. Apresentamos uma abordagem independente de modelo que pode utilizar qualquer regressor (ou seja, modelo estatístico ou de aprendizado de máquina) que foi ajustado para prever valores nesta coluna com base nas outras variáveis no conjunto de dados. Ao levar em conta várias incertezas, nossa abordagem distingue entre anomalias genuínas e flutuações naturais dos dados, condicionadas às informações disponíveis no conjunto de dados. Estabelecemos garantias teóricas para nosso método e mostramos que outras abordagens, como inferência conformal, têm dificuldade em detectar erros. Também contribuímos com um novo benchmark de detecção de erros envolvendo 5 conjuntos de dados de regressão com erros numéricos do mundo real (para os quais os valores verdadeiros também são conhecidos). Neste benchmark e em estudos de simulação adicionais, nosso método identifica valores incorretos com melhor precisão/revocação do que outras abordagens."
QNWAYE4N,webpage,2022.0,"Hammoudeh, Zayd; Lowd, Daniel",Training Data Influence Analysis and Estimation: A Survey,,https://arxiv.org/abs/2212.04612v2,"Good models require good training data. For overparameterized deep models, the causal relationship between training data and model predictions is increasingly opaque and poorly understood. Influence analysis partially demystifies training's underlying interactions by quantifying the amount each training instance alters the final model. Measuring the training data's influence exactly can be provably hard in the worst case; this has led to the development and use of influence estimators, which only approximate the true influence. This paper provides the first comprehensive survey of training data influence analysis and estimation. We begin by formalizing the various, and in places orthogonal, definitions of training data influence. We then organize state-of-the-art influence analysis methods into a taxonomy; we describe each of these methods in detail and compare their underlying assumptions, asymptotic complexities, and overall strengths and weaknesses. Finally, we propose future research directions to make influence analysis more useful in practice as well as more theoretically and empirically sound. A curated, up-to-date list of resources related to influence analysis is available at https://github.com/ZaydH/influence_analysis_papers.",2022-12-09,,Análise e Estimativa da Influência dos Dados de Treinamento: Uma Pesquisa,"Modelos bons requerem bons dados de treinamento. Para modelos profundos superparametrizados, a relação causal entre os dados de treinamento e as previsões do modelo é cada vez mais opaca e pouco compreendida. A análise de influência desmistifica parcialmente as interações subjacentes ao treinamento, quantificando a quantidade que cada instância de treinamento altera o modelo final. Medir exatamente a influência dos dados de treinamento pode ser provadamente difícil no pior caso; isso levou ao desenvolvimento e uso de estimadores de influência, que apenas aproximam a verdadeira influência. Este artigo fornece a primeira pesquisa abrangente sobre análise e estimativa da influência dos dados de treinamento. Começamos formalizando as várias definições de influência dos dados de treinamento, que em alguns casos são ortogonais. Em seguida, organizamos os métodos de análise de influência de última geração em uma taxonomia; descrevemos cada um desses métodos em detalhes e comparamos suas suposições subjacentes, complexidades assintóticas e forças e fraquezas gerais. Finalmente, propomos direções de pesquisa futuras para tornar a análise de influência mais útil na prática, bem como mais teoricamente e empiricamente sólida. Uma lista curada e atualizada de recursos relacionados à análise de influência está disponível em https://github.com/ZaydH/influence_analysis_papers."
9GZEWMZG,journalArticle,,"Yao, Yu",On the Importance of Transition Matrix for Learning with Noisy Labels,,,,,,Sobre a Importância da Matriz de Transição para Aprendizado com Rótulos Ruidosos,nan
5WNUNHLX,conferencePaper,2023.0,"Nouretdinov, Ilia; Gammerman, James",Conformal Association Rule Mining (CARM): A novel technique for data error detection and probabilistic correction,,https://proceedings.mlr.press/v204/nouretdinov23a.html,"Conformal prediction (CP) is a modern framework for  reliable machine learning. It is most commonly used  in the context of supervised learning, where in  combination with an underlying algorithm it  generates predicted labels for new, unlabelled  examples and complements each of them with an  individual measure of confidence. Conversely,  association rule mining (ARM) is an unsupervised  learning technique for discovering interesting  relationships in large datasets in the form of  rules. In this work, we integrate CP and ARM to  develop a novel technique termed Conformal  Association Rule Mining (CARM). The technique  enables the identification of probable errors within  a set of binary labels. Subsequently, these probable  errors are analysed using another modern framework  called Venn-ABERS prediction to correct the value in  a probabilistic way.",2023-08-17,PMLR,Mineração de Regras de Associação Conformais (CARM): Uma técnica nova para detecção de erros de dados e correção probabilística,"A previsão conformal (CP) é uma estrutura moderna para aprendizado de máquina confiável. É mais comumente usada no contexto de aprendizado supervisionado, onde, em combinação com um algoritmo subjacente, gera rótulos previstos para novos exemplos não rotulados e complementa cada um deles com uma medida individual de confiança. Por outro lado, a mineração de regras de associação (ARM) é uma técnica de aprendizado não supervisionado para descobrir relacionamentos interessantes em grandes conjuntos de dados na forma de regras. Neste trabalho, integramos CP e ARM para desenvolver uma nova técnica chamada Mineração de Regras de Associação Conformal (CARM). A técnica permite a identificação de erros prováveis dentro de um conjunto de rótulos binários. Subsequentemente, esses erros prováveis são analisados usando outra estrutura moderna chamada previsão Venn-ABERS para corrigir o valor de maneira probabilística."
27D5LDGY,preprint,2023.0,"Loukas, Lefteris; Stogiannidis, Ilias; Malakasiotis, Prodromos; Vassos, Stavros",Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance,,http://arxiv.org/abs/2308.14634,"We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed methods offer a practical solution for few-shot tasks in datasets with limited label availability, and b) our state-of-the-art results can inspire future work in the area.",2023-08-28,arXiv,Quebrando o Banco com ChatGPT: Classificação de Texto Few-Shot para Finanças,"Propomos o uso de modelos de GPT conversacional para classificação de texto fácil e rápida com poucos exemplos no domínio financeiro, utilizando o conjunto de dados Banking77. Nossa abordagem envolve aprendizado em contexto com GPT-3.5 e GPT-4, o que minimiza a expertise técnica necessária e elimina a necessidade de computação cara com GPU, ao mesmo tempo em que produz resultados rápidos e precisos. Além disso, ajustamos outros modelos de linguagem mascarados pré-treinados com SetFit, uma técnica recente de aprendizado contrastivo, para alcançar resultados de ponta tanto em configurações de dados completos quanto em configurações de poucos exemplos. Nossos achados mostram que consultar GPT-3.5 e GPT-4 pode superar modelos não gerativos ajustados, mesmo com menos exemplos. No entanto, as taxas de assinatura associadas a essas soluções podem ser consideradas caras para pequenas organizações. Por fim, descobrimos que modelos generativos têm um desempenho melhor na tarefa dada quando apresentados a amostras representativas selecionadas por um especialista humano, em vez de amostras aleatórias. Concluímos que a) nossos métodos propostos oferecem uma solução prática para tarefas com poucos exemplos em conjuntos de dados com disponibilidade limitada de rótulos, e b) nossos resultados de ponta podem inspirar trabalhos futuros na área."
HN2RIWQG,conferencePaper,2023.0,"Sun, Wei; Ji, Shaoxiong; Denti, Tuulia; Moen, Hans; Kerro, Oleg; Rannikko, Antti; Marttinen, Pekka; Koskinen, Miika",Weak Supervision and Clustering-Based Sample Selection for Clinical Named Entity Recognition,10.1007/978-3-031-43427-3_27,,"One of the central tasks of medical text analysis is to extract and structure meaningful information from plain-text clinical documents. Named Entity Recognition (NER) is a sub-task of information extraction that involves identifying predefined entities from unstructured free text. Notably, NER models require large amounts of human-labeled data to train, but human annotation is costly and laborious and often requires medical training. Here, we aim to overcome the shortage of manually annotated data by introducing a training scheme for NER models that uses an existing medical ontology to assign weak labels to entities and provides enhanced domain-specific model adaptation with in-domain continual pretraining. Due to limited human annotation resources, we develop a specific module to collect a more representative test dataset from the data lake than a random selection. To validate our framework, we invite clinicians to annotate the test set. In this way, we construct two Finnish medical NER datasets based on clinical records retrieved from a hospital’s data lake and evaluate the effectiveness of the proposed methods. The code is available at https://github.com/VRCMF/HAM-net.git.",2023,Springer Nature Switzerland,Supervisão Fraca e Seleção de Amostras Baseada em Agrupamento para Reconhecimento de Entidades Nomeadas Clínicas,"Uma das tarefas centrais da análise de texto médico é extrair e estruturar informações significativas de documentos clínicos em texto simples. O Reconhecimento de Entidades Nomeadas (NER) é uma subtarefa da extração de informações que envolve a identificação de entidades predefinidas a partir de texto livre não estruturado. Notavelmente, os modelos de NER requerem grandes quantidades de dados rotulados por humanos para treinamento, mas a anotação humana é cara e trabalhosa e muitas vezes requer treinamento médico. Aqui, nosso objetivo é superar a escassez de dados anotados manualmente, introduzindo um esquema de treinamento para modelos de NER que utiliza uma ontologia médica existente para atribuir rótulos fracos às entidades e fornece uma adaptação de modelo específica do domínio aprimorada com pré-treinamento contínuo em domínio. Devido a recursos limitados de anotação humana, desenvolvemos um módulo específico para coletar um conjunto de dados de teste mais representativo do lago de dados do que uma seleção aleatória. Para validar nossa estrutura, convidamos clínicos a anotar o conjunto de teste. Dessa forma, construímos dois conjuntos de dados de NER médico finlandês com base em registros clínicos recuperados do lago de dados de um hospital e avaliamos a eficácia dos métodos propostos. O código está disponível em https://github.com/VRCMF/HAM-net.git."
JB7U9XBN,journalArticle,2023.0,"Yin, Yining; Feng, Yang; Weng, Shihao; Liu, Zixi; Yao, Yuan; Zhang, Yichi; Zhao, Zhihong; Chen, Zhenyu",Dynamic Data Fault Localization for Deep Neural Networks,,https://cs.nju.edu.cn/yuanyao/static/fse2023.pdf,"Rich datasets have empowered various deep learning (DL) applications, leading to remarkable success in many fields. However, data faults hidden in the datasets could result in DL applications behaving unpredictably and even cause massive monetary and life losses. To alleviate this problem, in this paper, we propose a dynamic data fault localization approach, namely DFauLo, to locate the mislabeled and noisy data in the deep learning datasets. DFauLo is inspired by the conventional mutation-based code fault localization, but utilizes the differences between DNN mutants to amplify and identify the potential data faults. Specifically, it first generates multiple DNN model mutants of the original trained model. Then it extracts features from these mutants and maps them into a suspiciousness score indicating the probability of the given data being a data fault. Moreover, DFauLo is the first dynamic data fault localization technique, prioritizing the suspected data based on user feedback, and providing the generalizability to unseen data faults during training. To validate DFauLo, we extensively evaluate it on 26 cases with various fault types, data types, and model structures. We also evaluate DFauLo on three widely-used benchmark datasets.",2023,,Localização de Falhas em Dados Dinâmicos para Redes Neurais Profundas,"Conjuntos de dados ricos capacitaram várias aplicações de aprendizado profundo (DL), levando a um sucesso notável em muitos campos. No entanto, falhas de dados ocultas nos conjuntos de dados podem resultar em aplicações de DL se comportando de maneira imprevisível e até causar enormes perdas financeiras e de vidas. Para aliviar esse problema, neste artigo, propomos uma abordagem dinâmica de localização de falhas de dados, chamada DFauLo, para localizar dados rotulados incorretamente e ruidosos nos conjuntos de dados de aprendizado profundo. DFauLo é inspirado na localização de falhas de código baseada em mutação convencional, mas utiliza as diferenças entre mutantes de DNN para amplificar e identificar as potenciais falhas de dados. Especificamente, ele primeiro gera múltiplos mutantes de modelo DNN do modelo treinado original. Em seguida, extrai características desses mutantes e as mapeia em uma pontuação de suspeita que indica a probabilidade de os dados fornecidos serem uma falha de dados. Além disso, DFauLo é a primeira técnica dinâmica de localização de falhas de dados, priorizando os dados suspeitos com base no feedback do usuário e proporcionando a generalização para falhas de dados não vistas durante o treinamento. Para validar o DFauLo, avaliamos extensivamente em 26 casos com vários tipos de falhas, tipos de dados e estruturas de modelo. Também avaliamos o DFauLo em três conjuntos de dados de referência amplamente utilizados."
YSC4W236,preprint,2023.0,"Papadopoulos, Georgios; Silavong, Fran; Moran, Sean",A Benchmark Generative Probabilistic Model for Weak Supervised Learning,10.48550/arXiv.2303.17841,http://arxiv.org/abs/2303.17841,"Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weak Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-the-art performance across four datasets. For example, they achieve 22% points higher F1 score than Snorkel in the class-imbalanced Spouse dataset. PLVMs are plug-and-playable and are a drop-in replacement to existing WSL frameworks (e.g. Snorkel) or they can be used as benchmark models for more complicated algorithms, giving practitioners a compelling accuracy boost.",2023-03-31,arXiv,Um Modelo Probabilístico Generativo de Referência para Aprendizado Supervisionado Fraco,"Encontrar conjuntos de dados relevantes e de alta qualidade para treinar modelos de aprendizado de máquina é um grande gargalo para os profissionais. Além disso, para abordar casos de uso ambiciosos do mundo real, geralmente há a exigência de que os dados venham rotulados com anotações de alta qualidade que possam facilitar o treinamento de um modelo supervisionado. Rotular manualmente dados com rótulos de alta qualidade é geralmente uma tarefa demorada e desafiadora e, muitas vezes, isso se torna o gargalo em um projeto de aprendizado de máquina. Abordagens de Aprendizado Supervisionado Fraco (WSL) foram desenvolvidas para aliviar o ônus da anotação, oferecendo uma maneira automática de atribuir rótulos aproximados (pseudo-rótulos) a dados não rotulados com base em heurísticas, supervisão distante e bases de conhecimento. Aplicamos modelos probabilísticos generativos de variáveis latentes (PLVMs), treinados em representações de rotulagem heurísticas do conjunto de dados original, como uma maneira precisa, rápida e econômica de gerar pseudo-rótulos. Mostramos que os PLVMs alcançam desempenho de ponta em quatro conjuntos de dados. Por exemplo, eles alcançam 22 pontos percentuais a mais no F1 score do que o Snorkel no conjunto de dados Spouse, que tem desequilíbrio de classes. Os PLVMs são plug-and-play e são uma substituição direta para frameworks WSL existentes (por exemplo, Snorkel) ou podem ser usados como modelos de referência para algoritmos mais complicados, proporcionando aos profissionais um impulso significativo na precisão."
5WAZ7R4C,journalArticle,,"Miyaji, Renato O; de Almeida, Felipe V; Corrêa, Pedro L P",Aplicação de Técnicas de Confident Learning para Limpeza de Dados e Melhoria de Desempenho de Classificadores de Aprendizado de Máquina: um Estudo de Caso,,,"Model-Centric techniques, such as hyperparameter selection and regularization, are commonly used in the literature to improve the performance of Machine Learning Classifiers. However, when a dataset with uncertain data is used, Data-Centric approaches have a good potential. These methods aim to systematically engineer data to improve model performance. Thus, Confident Learning (CL) techniques were applied for a study case of Species Distribution Modeling in the Amazon Basin using Machine Learning Classifiers, which aimed to predict the probability of occurrence of a species, given environmental conditions. In comparison with Model-Centric methods, CL techniques presented a 23% improvement of ROC-AUC for Logistic Regression.",,,Aplicação de Técnicas de Confident Learning para Limpeza de Dados e Melhoria de Desempenho de Classificadores de Aprendizado de Máquina: um Estudo de Caso,"Técnicas centradas no modelo, como seleção de hiperparâmetros e regularização, são comumente utilizadas na literatura para melhorar o desempenho de Classificadores de Aprendizado de Máquina. No entanto, quando um conjunto de dados com dados incertos é utilizado, abordagens centradas nos dados têm um bom potencial. Esses métodos visam engenheirar dados de forma sistemática para melhorar o desempenho do modelo. Assim, técnicas de Aprendizado Confiante (CL) foram aplicadas em um estudo de caso de Modelagem de Distribuição de Espécies na Bacia Amazônica usando Classificadores de Aprendizado de Máquina, que visavam prever a probabilidade de ocorrência de uma espécie, dadas as condições ambientais. Em comparação com métodos centrados no modelo, as técnicas CL apresentaram uma melhoria de 23% no ROC-AUC para Regressão Logística."
A9EC8AMG,conferencePaper,2023.0,"Papadopoulos, Georgios; Silavong, Fran; Moran, Sean",A Baseline Generative Probabilistic Model for Weakly Supervised Learning,,,"Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weakly Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-the-art performance across four datasets. For example, they achieve 22% points higher F1 score than Snorkel in the class-imbalanced Spouse dataset. PLVMs are plug-and-playable and are a drop-in replacement to existing WSL frameworks (e.g. Snorkel) or they can be used as baseline high-performance models for more complicated algorithms, giving practitioners a compelling accuracy boost.",2023,Springer Nature Switzerland,Um Modelo Probabilístico Generativo de Linha de Base para Aprendizado Fracamente Supervisionado,"Encontrar conjuntos de dados relevantes e de alta qualidade para treinar modelos de aprendizado de máquina é um grande gargalo para os profissionais. Além disso, para abordar casos de uso ambiciosos do mundo real, geralmente há a exigência de que os dados venham rotulados com anotações de alta qualidade que possam facilitar o treinamento de um modelo supervisionado. Rotular manualmente dados com rótulos de alta qualidade é geralmente uma tarefa demorada e desafiadora e, muitas vezes, isso se torna o gargalo em um projeto de aprendizado de máquina. Abordagens de Aprendizado Fracamente Supervisionado (WSL) foram desenvolvidas para aliviar a carga de anotação, oferecendo uma maneira automática de atribuir rótulos aproximados (pseudo-rótulos) a dados não rotulados com base em heurísticas, supervisão distante e bases de conhecimento. Aplicamos modelos probabilísticos generativos de variáveis latentes (PLVMs), treinados em representações de rotulagem heurística do conjunto de dados original, como uma maneira precisa, rápida e econômica de gerar pseudo-rótulos. Mostramos que os PLVMs alcançam desempenho de ponta em quatro conjuntos de dados. Por exemplo, eles alcançam 22 pontos percentuais a mais de F1 do que o Snorkel no conjunto de dados Spouse, que é desequilibrado em classes. Os PLVMs são plug-and-play e são uma substituição direta para frameworks WSL existentes (por exemplo, Snorkel) ou podem ser usados como modelos de alto desempenho de referência para algoritmos mais complicados, proporcionando aos profissionais um aumento significativo na precisão."
D25F9D3Y,journalArticle,,"Schmarje, Lars; Grossmann, Vasco; Michels, Tim; Nazarenus, Jakob; Santarossa, Monty; Zelenka, Claudius; Koch, Reinhard","Label Smarter, Not Harder: CleverLabel for Faster Annotation of Ambiguous Image Classiﬁcation with Higher Quality",,,"High-quality data is crucial for the success of machine learning, but labeling large datasets is often a time-consuming and costly process. While semi-supervised learning can help mitigate the need for labeled data, label quality remains an open issue due to ambiguity and disagreement among annotators. Thus, we use proposal-guided annotations as one option which leads to more consistency between annotators. However, proposing a label increases the probability of the annotators deciding in favor of this speciﬁc label. This introduces a bias which we can simulate and remove. We propose a new method CleverLabel for Cost-eﬀective LabEling using Validated proposal-guidEd annotations and Repaired LABELs. CleverLabel can reduce labeling costs by up to 30.0%, while achieving a relative improvement in Kullback-Leibler divergence of up to 29.8% compared to the previous state-of-the-art on a multi-domain real-world image classiﬁcation benchmark. CleverLabel offers a novel solution to the challenge of eﬃciently labeling large datasets while also improving the label quality.",,,"Rotule de Forma Mais Inteligente, Não Mais Difícil: CleverLabel para Anotação Mais Rápida de Classificação de Imagens Ambíguas com Maior Qualidade","Dados de alta qualidade são cruciais para o sucesso do aprendizado de máquina, mas rotular grandes conjuntos de dados é frequentemente um processo demorado e custoso. Embora o aprendizado semi-supervisionado possa ajudar a mitigar a necessidade de dados rotulados, a qualidade das etiquetas continua sendo uma questão em aberto devido à ambiguidade e ao desacordo entre os anotadores. Assim, usamos anotações guiadas por propostas como uma opção que leva a mais consistência entre os anotadores. No entanto, propor uma etiqueta aumenta a probabilidade de os anotadores decidirem a favor dessa etiqueta específica. Isso introduz um viés que podemos simular e remover. Propomos um novo método CleverLabel para Rotulagem Custo-efetiva usando anotações guiadas por propostas Validadas e Etiquetas Reparadas. CleverLabel pode reduzir os custos de rotulagem em até 30,0%, enquanto alcança uma melhoria relativa na divergência de Kullback-Leibler de até 29,8% em comparação com o estado da arte anterior em um benchmark de classificação de imagens do mundo real de múltiplos domínios. CleverLabel oferece uma solução inovadora para o desafio de rotular eficientemente grandes conjuntos de dados, ao mesmo tempo em que melhora a qualidade das etiquetas."
YLIHTVLC,preprint,2023.0,"Chiang, Chao-Kai; Sugiyama, Masashi",Unified Risk Analysis for Weakly Supervised Learning,,http://arxiv.org/abs/2309.08216,"Among the flourishing research of weakly supervised learning (WSL), we recognize the lack of a unified interpretation of the mechanism behind the weakly supervised scenarios, let alone a systematic treatment of the risk rewrite problem, a crucial step in the empirical risk minimization approach. In this paper, we introduce a framework providing a comprehensive understanding and a unified methodology for WSL. The formulation component of the framework, leveraging a contamination perspective, provides a unified interpretation of how weak supervision is formed and subsumes fifteen existing WSL settings. The induced reduction graphs offer comprehensive connections over WSLs. The analysis component of the framework, viewed as a decontamination process, provides a systematic method of conducting risk rewrite. In addition to the conventional inverse matrix approach, we devise a novel strategy called marginal chain aiming to decontaminate distributions. We justify the feasibility of the proposed framework by recovering existing rewrites reported in the literature.",2023-09-15,arXiv,Análise de Risco Unificada para Aprendizado Fracamente Supervisionado,"Entre as pesquisas em expansão de aprendizado fraco supervisionado (WSL), reconhecemos a falta de uma interpretação unificada do mecanismo por trás dos cenários de supervisão fraca, muito menos um tratamento sistemático do problema de reescrita de risco, um passo crucial na abordagem de minimização de risco empírico. Neste artigo, introduzimos uma estrutura que fornece uma compreensão abrangente e uma metodologia unificada para WSL. O componente de formulação da estrutura, aproveitando uma perspectiva de contaminação, fornece uma interpretação unificada de como a supervisão fraca é formada e subsume quinze configurações de WSL existentes. Os gráficos de redução induzidos oferecem conexões abrangentes sobre WSLs. O componente de análise da estrutura, visto como um processo de descontaminação, fornece um método sistemático para conduzir a reescrita de risco. Além da abordagem convencional de matriz inversa, elaboramos uma nova estratégia chamada cadeia marginal, visando descontaminar distribuições. Justificamos a viabilidade da estrutura proposta ao recuperar reescritas existentes relatadas na literatura."
R3PJJBI4,preprint,2021.0,"Zhang, Yikai; Zheng, Songzhu; Wu, Pengxiang; Goswami, Mayank; Chen, Chao",Learning with Feature-Dependent Label Noise: A Progressive Approach,10.48550/arXiv.2103.07756,http://arxiv.org/abs/2103.07756,"Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.",2021-03-27,arXiv,Aprendendo com Ruído de Rótulo Dependente de Características: Uma Abordagem Progressiva,"O ruído de rótulo é frequentemente observado em conjuntos de dados em larga escala do mundo real. O ruído é introduzido devido a uma variedade de razões; é heterogêneo e dependente de características. A maioria das abordagens existentes para lidar com rótulos ruidosos se enquadra em duas categorias: ou assumem um ruído ideal independente de características, ou permanecem heurísticas sem garantias teóricas. Neste artigo, propomos direcionar uma nova família de ruído de rótulo dependente de características, que é muito mais geral do que o ruído de rótulo i.i.d. comumente usado e abrange um amplo espectro de padrões de ruído. Focando nesta família de ruído geral, propomos um algoritmo de correção de rótulo progressivo que corrige iterativamente os rótulos e refina o modelo. Fornecemos garantias teóricas mostrando que, para uma ampla variedade de padrões de ruído (desconhecidos), um classificador treinado com essa estratégia converge para ser consistente com o classificador de Bayes. Em experimentos, nosso método supera as linhas de base SOTA e é robusto a vários tipos e níveis de ruído."
YXZU2LHL,conferencePaper,2023.0,"Zhang, Yongqi; Zhang, Hui; Yao, Quanming; Wan, Jun",Combining Self-Supervised and Supervised Learning with Noisy Labels,10.1109/ICIP49359.2023.10221957,,,2023,,Combinando Aprendizado Auto-Supervisionado e Aprendizado Supervisionado com Rótulos Ruins,nan
MIJ3C2VE,journalArticle,2023.0,"Wang, Xingyu; Chi, Xurong; Song, Yanzhi; Yang, Zhouwang",Active learning with label quality control,10.7717/peerj-cs.1480,https://doi.org/10.7717/peerj-cs.1480,"Training deep neural networks requires a large number of labeled samples, which are typically provided by crowdsourced workers or professionals at a high cost. To obtain qualified labels, samples need to be relabeled for inspection to control the quality of the labels, which further increases the cost. Active learning methods aim to select the most valuable samples for labeling to reduce labeling costs. We designed a practical active learning method that adaptively allocates labeling resources to the most valuable unlabeled samples and the most likely mislabeled labeled samples, thus significantly reducing the overall labeling cost. We prove that the probability of our proposed method labeling more than one sample from any redundant sample set in the same batch is less than 1/k, where k is the number of the k-fold experiment used in the method, thus significantly reducing the labeling resources wasted on redundant samples. Our proposed method achieves the best level of results on benchmark datasets, and it performs well in an industrial application of automatic optical inspection.",2023-09,,Aprendizado ativo com controle de qualidade de rótulos,"Treinar redes neurais profundas requer um grande número de amostras rotuladas, que geralmente são fornecidas por trabalhadores crowdsourced ou profissionais a um alto custo. Para obter rótulos qualificados, as amostras precisam ser rotuladas novamente para inspeção a fim de controlar a qualidade dos rótulos, o que aumenta ainda mais o custo. Métodos de aprendizado ativo visam selecionar as amostras mais valiosas para rotulagem a fim de reduzir os custos de rotulagem. Projetamos um método prático de aprendizado ativo que aloca adaptativamente recursos de rotulagem para as amostras não rotuladas mais valiosas e as amostras rotuladas mais propensas a erro, reduzindo assim significativamente o custo total de rotulagem. Provamos que a probabilidade de nosso método proposto rotular mais de uma amostra de qualquer conjunto de amostras redundantes no mesmo lote é menor que 1/k, onde k é o número do experimento k-fold utilizado no método, reduzindo assim significativamente os recursos de rotulagem desperdiçados em amostras redundantes. Nosso método proposto alcança o melhor nível de resultados em conjuntos de dados de referência e apresenta um bom desempenho em uma aplicação industrial de inspeção óptica automática."
AGX3I837,preprint,2022.0,"Zhu, Zhaowei; Dong, Zihao; Liu, Yang",Detecting Corrupted Labels Without Training a Model to Predict,10.48550/arXiv.2110.06283,http://arxiv.org/abs/2110.06283,"Label noise in real-world datasets encodes wrong correlation patterns and impairs the generalization of deep neural networks (DNNs). It is critical to find efficient ways to detect corrupted patterns. Current methods primarily focus on designing robust training techniques to prevent DNNs from memorizing corrupted patterns. These approaches often require customized training processes and may overfit corrupted patterns, leading to a performance drop in detection. In this paper, from a more data-centric perspective, we propose a training-free solution to detect corrupted labels. Intuitively, ``closer'' instances are more likely to share the same clean label. Based on the neighborhood information, we propose two methods: the first one uses ``local voting"" via checking the noisy label consensuses of nearby features. The second one is a ranking-based approach that scores each instance and filters out a guaranteed number of instances that are likely to be corrupted. We theoretically analyze how the quality of features affects the local voting and provide guidelines for tuning neighborhood size. We also prove the worst-case error bound for the ranking-based method. Experiments with both synthetic and real-world label noise demonstrate our training-free solutions consistently and significantly improve most of the training-based baselines. Code is available at github.com/UCSC-REAL/SimiFeat.",2022-06-17,,Detectando Rótulos Corrompidos Sem Treinar um Modelo para Prever,"O ruído de rótulo em conjuntos de dados do mundo real codifica padrões de correlação errados e prejudica a generalização de redes neurais profundas (DNNs). É crítico encontrar maneiras eficientes de detectar padrões corrompidos. Os métodos atuais se concentram principalmente em projetar técnicas de treinamento robustas para evitar que as DNNs memorizem padrões corrompidos. Essas abordagens muitas vezes exigem processos de treinamento personalizados e podem se ajustar excessivamente a padrões corrompidos, levando a uma queda de desempenho na detecção. Neste artigo, de uma perspectiva mais centrada nos dados, propomos uma solução sem treinamento para detectar rótulos corrompidos. Intuitivamente, instâncias ""mais próximas"" têm maior probabilidade de compartilhar o mesmo rótulo limpo. Com base nas informações de vizinhança, propomos dois métodos: o primeiro utiliza ""votação local"" por meio da verificação dos consensos de rótulo ruidoso de características próximas. O segundo é uma abordagem baseada em classificação que pontua cada instância e filtra um número garantido de instâncias que provavelmente estão corrompidas. Analisamos teoricamente como a qualidade das características afeta a votação local e fornecemos diretrizes para ajustar o tamanho da vizinhança. Também provamos o limite de erro no pior caso para o método baseado em classificação. Experimentos com ruído de rótulo sintético e do mundo real demonstram que nossas soluções sem treinamento melhoram consistentemente e significativamente a maioria das linhas de base baseadas em treinamento. O código está disponível em github.com/UCSC-REAL/SimiFeat."
IWBNVZLF,preprint,2023.0,"Zha, Daochen; Bhat, Zaid Pervaiz; Lai, Kwei-Herng; Yang, Fan; Jiang, Zhimeng; Zhong, Shaochen; Hu, Xia",Data-centric Artificial Intelligence: A Survey,10.48550/arXiv.2303.10158,http://arxiv.org/abs/2303.10158,"Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI",2023-06-11,arXiv,Inteligência Artificial Centrada em Dados: Uma Revisão,"A Inteligência Artificial (IA) está tendo um impacto profundo em quase todos os domínios. Um fator vital para seu grande sucesso é a disponibilidade de dados abundantes e de alta qualidade para a construção de modelos de aprendizado de máquina. Recentemente, o papel dos dados na IA foi significativamente ampliado, dando origem ao conceito emergente de IA centrada em dados. A atenção de pesquisadores e profissionais mudou gradualmente do avanço do design de modelos para a melhoria da qualidade e quantidade dos dados. Neste levantamento, discutimos a necessidade da IA centrada em dados, seguida de uma visão holística de três objetivos gerais centrados em dados (desenvolvimento de dados de treinamento, desenvolvimento de dados de inferência e manutenção de dados) e os métodos representativos. Também organizamos a literatura existente a partir das perspectivas de automação e colaboração, discutimos os desafios e tabulamos os benchmarks para várias tarefas. Acreditamos que este é o primeiro levantamento abrangente que fornece uma visão global de um espectro de tarefas em várias etapas do ciclo de vida dos dados. Esperamos que isso possa ajudar os leitores a compreender de forma eficiente um panorama amplo deste campo e equipá-los com as técnicas e ideias de pesquisa adicionais para engenheirar sistematicamente dados para a construção de sistemas de IA. Uma lista complementar de recursos de IA centrada em dados será atualizada regularmente em https://github.com/daochenzha/data-centric-AI"
J3NAH8WK,preprint,2022.0,"Gao, Zhengqi; Sun, Fan-Keng; Yang, Mingran; Ren, Sucheng; Xiong, Zikai; Engeler, Marc; Burazer, Antonio; Wildling, Linda; Daniel, Luca; Boning, Duane S.",Learning from Multiple Annotator Noisy Labels via Sample-wise Label Fusion,10.48550/arXiv.2207.11327,http://arxiv.org/abs/2207.11327,"Data lies at the core of modern deep learning. The impressive performance of supervised learning is built upon a base of massive accurately labeled data. However, in some real-world applications, accurate labeling might not be viable; instead, multiple noisy labels (instead of one accurate label) are provided by several annotators for each data sample. Learning a classifier on such a noisy training dataset is a challenging task. Previous approaches usually assume that all data samples share the same set of parameters related to annotator errors, while we demonstrate that label error learning should be both annotator and data sample dependent. Motivated by this observation, we propose a novel learning algorithm. The proposed method displays superiority compared with several state-of-the-art baseline methods on MNIST, CIFAR-100, and ImageNet-100. Our code is available at: https://github.com/zhengqigao/Learning-from-Multiple-Annotator-Noisy-Labels.",2022-07-22,,Aprendendo com Rótulos Ruins de Múltiplos Anotadores por Meio da Fusão de Rótulos por Amostra,"Os dados estão no cerne do aprendizado profundo moderno. O desempenho impressionante do aprendizado supervisionado é construído sobre uma base de dados massiva e precisamente rotulada. No entanto, em algumas aplicações do mundo real, a rotulagem precisa pode não ser viável; em vez disso, múltiplos rótulos ruidosos (em vez de um rótulo preciso) são fornecidos por vários anotadores para cada amostra de dados. Aprender um classificador em um conjunto de dados de treinamento tão ruidoso é uma tarefa desafiadora. Abordagens anteriores geralmente assumem que todas as amostras de dados compartilham o mesmo conjunto de parâmetros relacionados aos erros dos anotadores, enquanto demonstramos que o aprendizado de erro de rótulo deve ser dependente tanto do anotador quanto da amostra de dados. Motivados por essa observação, propomos um novo algoritmo de aprendizado. O método proposto demonstra superioridade em comparação com vários métodos de referência de última geração no MNIST, CIFAR-100 e ImageNet-100. Nosso código está disponível em: https://github.com/zhengqigao/Learning-from-Multiple-Annotator-Noisy-Labels."
CDRU8AXJ,preprint,2023.0,"Shin, Changho; Cromp, Sonia; Adila, Dyah; Sala, Frederic",Mitigating Source Bias for Fairer Weak Supervision,10.48550/arXiv.2303.17713,http://arxiv.org/abs/2303.17713,"Weak supervision overcomes the label bottleneck, enabling efficient development of training sets. Millions of models trained on such datasets have been deployed in the real world and interact with users on a daily basis. However, the techniques that make weak supervision attractive -- such as integrating any source of signal to estimate unknown labels -- also ensure that the pseudolabels it produces are highly biased. Surprisingly, given everyday use and the potential for increased bias, weak supervision has not been studied from the point of view of fairness. This work begins such a study. Our departure point is the observation that even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair. Fortunately, not all is lost: we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can mitigate these biases. Theoretically, we show that it is possible for our approach to simultaneously improve both accuracy and fairness metrics -- in contrast to standard fairness approaches that suffer from tradeoffs. Empirically, we show that our technique improves accuracy on weak supervision baselines by as much as 32% while reducing demographic parity gap by 82.5%.",2023-03-30,arXiv,Mitigando o Viés de Fonte para uma Supervisão Fraca Mais Justa,"A supervisão fraca supera o gargalo de rotulagem, permitindo o desenvolvimento eficiente de conjuntos de treinamento. Milhões de modelos treinados em tais conjuntos de dados foram implantados no mundo real e interagem com os usuários diariamente. No entanto, as técnicas que tornam a supervisão fraca atraente -- como integrar qualquer fonte de sinal para estimar rótulos desconhecidos -- também garantem que os pseudorótulos que ela produz sejam altamente tendenciosos. Surpreendentemente, dado o uso cotidiano e o potencial para aumento do viés, a supervisão fraca não foi estudada do ponto de vista da equidade. Este trabalho inicia tal estudo. Nosso ponto de partida é a observação de que, mesmo quando um modelo justo pode ser construído a partir de um conjunto de dados com acesso a rótulos verdadeiros, o conjunto de dados correspondente rotulado via supervisão fraca pode ser arbitrariamente injusto. Felizmente, nem tudo está perdido: propomos e validamos empiricamente um modelo para a injustiça de origem na supervisão fraca, e então introduzimos uma técnica simples baseada em equidade contrafactual que pode mitigar esses viéses. Teoricamente, mostramos que é possível que nossa abordagem melhore simultaneamente tanto a precisão quanto as métricas de equidade -- em contraste com as abordagens padrão de equidade que sofrem de compensações. Empiricamente, mostramos que nossa técnica melhora a precisão em bases de supervisão fraca em até 32% enquanto reduz a lacuna de paridade demográfica em 82,5%."
2A39CV6F,preprint,2023.0,"Guu, Kelvin; Webson, Albert; Pavlick, Ellie; Dixon, Lucas; Tenney, Ian; Bolukbasi, Tolga",Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs,10.48550/arXiv.2303.08114,http://arxiv.org/abs/2303.08114,"Training data attribution (TDA) methods offer to trace a model's prediction on any given example back to specific influential training examples. Existing approaches do so by assigning a scalar influence score to each training example, under a simplifying assumption that influence is additive. But in reality, we observe that training examples interact in highly non-additive ways due to factors such as inter-example redundancy, training order, and curriculum learning effects. To study such interactions, we propose Simfluence, a new paradigm for TDA where the goal is not to produce a single influence score per example, but instead a training run simulator: the user asks, ``If my model had trained on example $z_1$, then $z_2$, ..., then $z_n$, how would it behave on $z_{test}$?''; the simulator should then output a simulated training run, which is a time series predicting the loss on $z_{test}$ at every step of the simulated run. This enables users to answer counterfactual questions about what their model would have learned under different training curricula, and to directly see where in training that learning would occur. We present a simulator, Simfluence-Linear, that captures non-additive interactions and is often able to predict the spiky trajectory of individual example losses with surprising fidelity. Furthermore, we show that existing TDA methods such as TracIn and influence functions can be viewed as special cases of Simfluence-Linear. This enables us to directly compare methods in terms of their simulation accuracy, subsuming several prior TDA approaches to evaluation. In experiments on large language model (LLM) fine-tuning, we show that our method predicts loss trajectories with much higher accuracy than existing TDA methods (doubling Spearman's correlation and reducing mean-squared error by 75%) across several tasks, models, and training methods.",2023-03-14,,Simfluence: Modelando a Influência de Exemplos de Treinamento Individuais ao Simular Execuções de Treinamento,"Métodos de atribuição de dados de treinamento (TDA) oferecem a possibilidade de rastrear a previsão de um modelo em um dado exemplo de volta a exemplos de treinamento específicos e influentes. Abordagens existentes fazem isso atribuindo uma pontuação de influência escalar a cada exemplo de treinamento, sob a suposição simplificadora de que a influência é aditiva. Mas, na realidade, observamos que os exemplos de treinamento interagem de maneiras altamente não aditivas devido a fatores como redundância entre exemplos, ordem de treinamento e efeitos de aprendizado curricular. Para estudar tais interações, propomos o Simfluence, um novo paradigma para TDA onde o objetivo não é produzir uma única pontuação de influência por exemplo, mas sim um simulador de execução de treinamento: o usuário pergunta: ""Se meu modelo tivesse sido treinado no exemplo $z_1$, depois $z_2$, ..., depois $z_n$, como ele se comportaria em $z_{test}$?""; o simulador deve então gerar uma execução de treinamento simulada, que é uma série temporal prevendo a perda em $z_{test}$ em cada passo da execução simulada. Isso permite que os usuários respondam a perguntas contrafactuais sobre o que seu modelo teria aprendido sob diferentes currículos de treinamento e vejam diretamente onde, no treinamento, esse aprendizado ocorreria. Apresentamos um simulador, Simfluence-Linear, que captura interações não aditivas e é frequentemente capaz de prever a trajetória espinhosa das perdas de exemplos individuais com surpreendente fidelidade. Além disso, mostramos que métodos TDA existentes, como TracIn e funções de influência, podem ser vistos como casos especiais do Simfluence-Linear. Isso nos permite comparar diretamente métodos em termos de sua precisão de simulação, englobando várias abordagens TDA anteriores para avaliação. Em experimentos de ajuste fino de grandes modelos de linguagem (LLM), mostramos que nosso método prevê trajetórias de perda com muito mais precisão do que métodos TDA existentes (dobrando a correlação de Spearman e reduzindo o erro quadrático médio em 75%) em várias tarefas, modelos e métodos de treinamento."
LWTUJ5EJ,preprint,2022.0,"Stephan, Andreas; Roth, Benjamin",WeaNF: Weak Supervision with Normalizing Flows,10.48550/arXiv.2204.13409,http://arxiv.org/abs/2204.13409,"A popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias. Methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to model the output of the automatic annotation process. In this work, we explore a novel direction of generative modeling for weak supervision: Instead of modeling the output of the annotation process (the labeling function matches), we generatively model the input-side data distributions (the feature space) covered by labeling functions. Specifically, we estimate a density for each weak labeling source, or labeling function, by using normalizing flows. An integral part of our method is the flow-based modeling of multiple simultaneously matching labeling functions, and therefore phenomena such as labeling function overlap and correlations are captured. We analyze the effectiveness and modeling capabilities on various commonly used weak supervision data sets, and show that weakly supervised normalizing flows compare favorably to standard weak supervision baselines.",2022-05-02,arXiv,WeaNF: Supervisão Fraca com Fluxos Normalizadores,"Uma abordagem popular para diminuir a necessidade de anotação manual cara de grandes conjuntos de dados é a supervisão fraca, que introduz problemas de rótulos ruidosos, cobertura e viés. Métodos para superar esses problemas têm se baseado em modelos discriminativos, treinados com funções de custo específicas para supervisão fraca, e mais recentemente, em modelos generativos, tentando modelar a saída do processo de anotação automática. Neste trabalho, exploramos uma nova direção de modelagem generativa para supervisão fraca: em vez de modelar a saída do processo de anotação (as correspondências da função de rotulagem), modelamos generativamente as distribuições de dados do lado de entrada (o espaço de características) cobertas pelas funções de rotulagem. Especificamente, estimamos uma densidade para cada fonte de rotulagem fraca, ou função de rotulagem, usando fluxos normalizadores. Uma parte integral do nosso método é a modelagem baseada em fluxo de múltiplas funções de rotulagem que correspondem simultaneamente, e, portanto, fenômenos como sobreposição de funções de rotulagem e correlações são capturados. Analisamos a eficácia e as capacidades de modelagem em vários conjuntos de dados de supervisão fraca comumente utilizados e mostramos que os fluxos normalizadores com supervisão fraca se comparam favoravelmente a linhas de base padrão de supervisão fraca."
W6M2989A,conferencePaper,2019.0,"Amershi, Saleema; Weld, Dan; Vorvoreanu, Mihaela; Fourney, Adam; Nushi, Besmira; Collisson, Penny; Suh, Jina; Iqbal, Shamsi; Bennett, Paul N.; Inkpen, Kori; Teevan, Jaime; Kikin-Gil, Ruth; Horvitz, Eric",Guidelines for Human-AI Interaction,10.1145/3290605.3300233,https://dl.acm.org/doi/10.1145/3290605.3300233,"Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for humanAI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.",2019-05-02,ACM,Diretrizes para Interação Humano-IA,"Avanços em inteligência artificial (IA) apresentam oportunidades e desafios para o design de interfaces de usuário. Princípios para a interação humano-IA têm sido discutidos na comunidade de interação humano-computador por mais de duas décadas, mas mais estudos e inovações são necessários à luz dos avanços em IA e dos crescentes usos de tecnologias de IA em aplicações voltadas para humanos. Propomos 18 diretrizes de design geralmente aplicáveis para a interação humano-IA. Essas diretrizes são validadas por meio de múltiplas rodadas de avaliação, incluindo um estudo com usuários com 49 profissionais de design que testaram as diretrizes em relação a 20 produtos populares infundidos com IA. Os resultados verificam a relevância das diretrizes em um espectro de cenários de interação e revelam lacunas em nosso conhecimento, destacando oportunidades para pesquisas adicionais. Com base nas avaliações, acreditamos que o conjunto de diretrizes de design pode servir como um recurso para profissionais que trabalham no design de aplicações e recursos que aproveitam tecnologias de IA, e para pesquisadores interessados no desenvolvimento adicional de diretrizes para o design de interação humano-IA."
PQQPM9BU,conferencePaper,2019.0,"Geva, Mor; Goldberg, Yoav; Berant, Jonathan",Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets,10.18653/v1/D19-1107,https://www.aclweb.org/anthology/D19-1107,"Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identiﬁers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our ﬁndings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.",2019,Association for Computational Linguistics,Estamos Modelando a Tarefa ou o Anotador? Uma Investigação do Viés do Anotador em Conjuntos de Dados de Compreensão de Linguagem Natural,"O crowdsourcing tem sido o paradigma predominante para a criação de conjuntos de dados de compreensão da linguagem natural nos últimos anos. Uma prática comum de crowdsourcing é recrutar um pequeno número de trabalhadores de alta qualidade e fazer com que eles gerem exemplos em massa. Ter apenas alguns trabalhadores gerando a maioria dos exemplos levanta preocupações sobre a diversidade dos dados, especialmente quando os trabalhadores geram frases livremente. Neste artigo, realizamos uma série de experimentos que mostram que essas preocupações são evidentes em três conjuntos de dados recentes de PLN. Mostramos que o desempenho do modelo melhora quando treinado com identificadores de anotadores como características, e que os modelos são capazes de reconhecer os anotadores mais produtivos. Além disso, mostramos que muitas vezes os modelos não generalizam bem para exemplos de anotadores que não contribuíram para o conjunto de treinamento. Nossas descobertas sugerem que o viés dos anotadores deve ser monitorado durante a criação do conjunto de dados, e que os anotadores do conjunto de teste devem ser distintos dos anotadores do conjunto de treinamento."
UNAGEFZ4,journalArticle,2019.0,"Bansal, Gagan; Nushi, Besmira; Kamar, Ece; Lasecki, Walter S.; Weld, Daniel S.; Horvitz, Eric",Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance,10.1609/hcomp.v7i1.5285,https://ojs.aaai.org/index.php/HCOMP/article/view/5285,"Decisions made by human-AI teams (e.g., AI-advised humans) are increasingly common in high-stakes domains such as healthcare, criminal justice, and ﬁnance. Achieving high team performance depends on more than just the accuracy of the AI system: Since the human and the AI may have different expertise, the highest team performance is often reached when they both know how and when to complement one another. We focus on a factor that is crucial to supporting such complementary: the human’s mental model of the AI capabilities, speciﬁcally the AI system’s error boundary (i.e. knowing “When does the AI err?”). Awareness of this lets the human decide when to accept or override the AI’s recommendation. We highlight two key properties of an AI’s error boundary, parsimony and stochasticity, and a property of the task, dimensionality. We show experimentally how these properties affect humans’ mental models of AI capabilities and the resulting team performance. We connect our evaluations to related work and propose goals, beyond accuracy, that merit consideration during model selection and optimization to improve overall human-AI team performance.",2019-10-28,,Além da Precisão: O Papel dos Modelos Mentais no Desempenho de Equipes Humanas e de IA,"Decisões tomadas por equipes humano-IA (por exemplo, humanos aconselhados por IA) são cada vez mais comuns em domínios de alto risco, como saúde, justiça criminal e finanças. Alcançar um alto desempenho da equipe depende de mais do que apenas a precisão do sistema de IA: como o humano e a IA podem ter diferentes especializações, o maior desempenho da equipe é frequentemente alcançado quando ambos sabem como e quando se complementar. Focamos em um fator que é crucial para apoiar essa complementaridade: o modelo mental do humano sobre as capacidades da IA, especificamente o limite de erro do sistema de IA (ou seja, saber ""Quando a IA erra?""). A conscientização sobre isso permite que o humano decida quando aceitar ou ignorar a recomendação da IA. Destacamos duas propriedades-chave do limite de erro de uma IA, parcimônia e estocasticidade, e uma propriedade da tarefa, dimensionalidade. Mostramos experimentalmente como essas propriedades afetam os modelos mentais dos humanos sobre as capacidades da IA e o desempenho da equipe resultante. Conectamos nossas avaliações a trabalhos relacionados e propomos objetivos, além da precisão, que merecem consideração durante a seleção e otimização de modelos para melhorar o desempenho geral da equipe humano-IA."
N7BFT6AQ,conferencePaper,2020.0,"Barshan, Elnaz; Brunet, Marc-Etienne; Dziugaite, Gintare Karolina",RelatIF: Identifying Explanatory Training Samples via Relative Influence,,https://proceedings.mlr.press/v108/barshan20a.html,"In this work, we focus on the use of influence functions to identify relevant training examples that one might hope “explain” the predictions of a machine learning model. One shortcoming of influence functions is that the training examples deemed most “influential” are often outliers or mislabelled, making them poor choices for explanation. In order to address this shortcoming, we separate the role of global versus local influence. We introduce RelatIF, a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence. RelatIF considers the local influence that an explanatory example has on a prediction relative to its global effects on the model. In empirical evaluations, we find that the examples returned by RelatIF are more intuitive when compared to those found using influence functions.",2020-06-03,PMLR,RelatIF: Identificando Amostras de Treinamento Explicativas via Influência Relativa,"Neste trabalho, focamos no uso de funções de influência para identificar exemplos de treinamento relevantes que se espera que ""explique"" as previsões de um modelo de aprendizado de máquina. Uma limitação das funções de influência é que os exemplos de treinamento considerados mais ""influentes"" são frequentemente outliers ou rotulados incorretamente, tornando-os escolhas ruins para explicação. Para abordar essa limitação, separamos o papel da influência global em relação à influência local. Introduzimos o RelatIF, uma nova classe de critérios para escolher exemplos de treinamento relevantes por meio de um objetivo de otimização que impõe uma restrição sobre a influência global. O RelatIF considera a influência local que um exemplo explicativo tem sobre uma previsão em relação aos seus efeitos globais no modelo. Em avaliações empíricas, descobrimos que os exemplos retornados pelo RelatIF são mais intuitivos quando comparados àqueles encontrados usando funções de influência."
7RJBRIEX,preprint,2022.0,"Chen, Yuanyuan; Li, Boyang; Yu, Han; Wu, Pengcheng; Miao, Chunyan",HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks,10.48550/arXiv.2102.02515,http://arxiv.org/abs/2102.02515,"The behaviors of deep neural networks (DNNs) are notoriously resistant to human interpretations. In this paper, we propose Hypergradient Data Relevance Analysis, or HYDRA, which interprets the predictions made by DNNs as effects of their training data. Existing approaches generally estimate data contributions around the final model parameters and ignore how the training data shape the optimization trajectory. By unrolling the hypergradient of test loss w.r.t. the weights of training data, HYDRA assesses the contribution of training data toward test data points throughout the training trajectory. In order to accelerate computation, we remove the Hessian from the calculation and prove that, under moderate conditions, the approximation error is bounded. Corroborating this theoretical claim, empirical results indicate the error is indeed small. In addition, we quantitatively demonstrate that HYDRA outperforms influence functions in accurately estimating data contribution and detecting noisy data labels. The source code is available at https://github.com/cyyever/aaai_hydra_8686.",2022-12-29,arXiv,HYDRA: Análise de Relevância de Dados Hipergradientes para Interpretação de Redes Neurais Profundas,"Os comportamentos de redes neurais profundas (DNNs) são notoriamente resistentes a interpretações humanas. Neste artigo, propomos a Análise de Relevância de Dados por Hipergradiente, ou HYDRA, que interpreta as previsões feitas por DNNs como efeitos de seus dados de treinamento. Abordagens existentes geralmente estimam as contribuições dos dados em torno dos parâmetros finais do modelo e ignoram como os dados de treinamento moldam a trajetória de otimização. Ao desenrolar o hipergradiente da perda de teste em relação aos pesos dos dados de treinamento, a HYDRA avalia a contribuição dos dados de treinamento em relação aos pontos de dados de teste ao longo da trajetória de treinamento. Para acelerar o cálculo, removemos o Hessiano da equação e provamos que, sob condições moderadas, o erro de aproximação é limitado. Corroborando essa afirmação teórica, resultados empíricos indicam que o erro é de fato pequeno. Além disso, demonstramos quantitativamente que a HYDRA supera funções de influência na estimativa precisa da contribuição dos dados e na detecção de rótulos de dados ruidosos. O código-fonte está disponível em https://github.com/cyyever/aaai_hydra_8686."
86K94CLB,journalArticle,2018.0,"Varma, Paroma; Ré, Christopher",Snuba: automating weak supervision to label training data,10.14778/3291264.3291268,https://dl.acm.org/doi/10.14778/3291264.3291268,"As deep learning models are applied to increasingly diverse problems, a key bottleneck is gathering enough high-quality training labels tailored to each task. Users therefore turn to weak supervision, relying on imperfect sources of labels like pattern matching and user-deﬁned heuristics. Unfortunately, users have to design these sources for each task. This process can be time consuming and expensive: domain experts often perform repetitive steps like guessing optimal numerical thresholds and developing informative text patterns. To address these challenges, we present Snuba, a system to automatically generate heuristics using a small labeled dataset to assign training labels to a large, unlabeled dataset in the weak supervision setting. Snuba generates heuristics that each labels the subset of the data it is accurate for, and iteratively repeats this process until the heuristics together label a large portion of the unlabeled data. We develop a statistical measure that guarantees the iterative process will automatically terminate before it degrades training label quality. Snuba automatically generates heuristics in under ﬁve minutes and performs up to 9.74 F1 points better than the best known user-deﬁned heuristics developed over many days. In collaborations with users at research labs, Stanford Hospital, and on open source datasets, Snuba outperforms other automated approaches like semisupervised learning by up to 14.35 F1 points.",2018-11,,Snuba: automatizando a supervisão fraca para rotular dados de treinamento,"À medida que modelos de aprendizado profundo são aplicados a problemas cada vez mais diversos, um gargalo chave é reunir rótulos de treinamento de alta qualidade suficientes, adaptados a cada tarefa. Os usuários, portanto, recorrem à supervisão fraca, confiando em fontes imperfeitas de rótulos, como correspondência de padrões e heurísticas definidas pelo usuário. Infelizmente, os usuários têm que projetar essas fontes para cada tarefa. Esse processo pode ser demorado e caro: especialistas em domínio frequentemente realizam etapas repetitivas, como adivinhar limites numéricos ideais e desenvolver padrões de texto informativos. Para abordar esses desafios, apresentamos o Snuba, um sistema para gerar automaticamente heurísticas usando um pequeno conjunto de dados rotulados para atribuir rótulos de treinamento a um grande conjunto de dados não rotulados no contexto de supervisão fraca. O Snuba gera heurísticas que rotulam cada subconjunto dos dados para os quais são precisas e repete iterativamente esse processo até que as heurísticas juntas rotulem uma grande parte dos dados não rotulados. Desenvolvemos uma medida estatística que garante que o processo iterativo será automaticamente encerrado antes que degrade a qualidade dos rótulos de treinamento. O Snuba gera automaticamente heurísticas em menos de cinco minutos e apresenta até 9,74 pontos F1 a mais do que as melhores heurísticas definidas pelo usuário, desenvolvidas ao longo de muitos dias. Em colaborações com usuários em laboratórios de pesquisa, no Hospital de Stanford e em conjuntos de dados de código aberto, o Snuba supera outras abordagens automatizadas, como aprendizado semissupervisionado, em até 14,35 pontos F1."
PCPJI5PC,journalArticle,2022.0,"Denham, Benjamin; Lai, Edmund M-K.; Sinha, Roopak; Naeem, M. Asif",Witan: unsupervised labelling function generation for assisted data programming,10.14778/3551793.3551797,https://dl.acm.org/doi/10.14778/3551793.3551797,"Effective supervised training of modern machine learning models often requires large labelled training datasets, which could be prohibitively costly to acquire for many practical applications. Research addressing this problem has sought ways to leverage               weak supervision               sources, such as the user-defined heuristic labelling functions used in the               data programming               paradigm, which are cheaper and easier to acquire. Automatic generation of these functions can make data programming even more efficient and effective. However, existing approaches rely on initial supervision in the form of small labelled datasets or interactive user feedback. In this paper, we propose Witan, an algorithm for generating labelling functions without any initial supervision. This flexibility affords many interaction modes, including unsupervised dataset exploration before the user even defines a set of classes. Experiments in binary and multi-class classification demonstrate the efficiency and classification accuracy of Witan compared to alternative labelling approaches.",2022-07,,Witan: geração de função de rotulagem não supervisionada para programação de dados assistida,"O treinamento supervisionado eficaz de modelos modernos de aprendizado de máquina muitas vezes requer grandes conjuntos de dados rotulados, que podem ser proibitivamente caros de adquirir para muitas aplicações práticas. Pesquisas que abordam esse problema têm buscado maneiras de aproveitar fontes de supervisão fraca, como as funções de rotulagem heurísticas definidas pelo usuário usadas no paradigma de programação de dados, que são mais baratas e mais fáceis de adquirir. A geração automática dessas funções pode tornar a programação de dados ainda mais eficiente e eficaz. No entanto, as abordagens existentes dependem de supervisão inicial na forma de pequenos conjuntos de dados rotulados ou feedback interativo do usuário. Neste artigo, propomos o Witan, um algoritmo para gerar funções de rotulagem sem qualquer supervisão inicial. Essa flexibilidade oferece muitos modos de interação, incluindo exploração de conjuntos de dados não supervisionados antes que o usuário defina um conjunto de classes. Experimentos em classificação binária e multiclasse demonstram a eficiência e a precisão de classificação do Witan em comparação com abordagens alternativas de rotulagem."
R6J8GBGX,preprint,2022.0,"Seedat, Nabeel; Crabbé, Jonathan; Bica, Ioana; van der Schaar, Mihaela",Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data,10.48550/arXiv.2210.13043,http://arxiv.org/abs/2210.13043,"High model performance, on average, can hide that models may systematically underperform on subgroups of the data. We consider the tabular setting, which surfaces the unique issue of outcome heterogeneity - this is prevalent in areas such as healthcare, where patients with similar features can have different outcomes, thus making reliable predictions challenging. To tackle this, we propose Data-IQ, a framework to systematically stratify examples into subgroups with respect to their outcomes. We do this by analyzing the behavior of individual examples during training, based on their predictive confidence and, importantly, the aleatoric (data) uncertainty. Capturing the aleatoric uncertainty permits a principled characterization and then subsequent stratification of data examples into three distinct subgroups (Easy, Ambiguous, Hard). We experimentally demonstrate the benefits of Data-IQ on four real-world medical datasets. We show that Data-IQ's characterization of examples is most robust to variation across similarly performant (yet different) models, compared to baselines. Since Data-IQ can be used with any ML model (including neural networks, gradient boosting etc.), this property ensures consistency of data characterization, while allowing flexible model selection. Taking this a step further, we demonstrate that the subgroups enable us to construct new approaches to both feature acquisition and dataset selection. Furthermore, we highlight how the subgroups can inform reliable model usage, noting the significant impact of the Ambiguous subgroup on model generalization.",2022-10-24,arXiv,Data-IQ: Caracterizando subgrupos com resultados heterogêneos em dados tabulares,"O alto desempenho do modelo, em média, pode ocultar que os modelos podem ter um desempenho sistematicamente inferior em subgrupos dos dados. Consideramos o cenário tabular, que revela a questão única da heterogeneidade dos resultados - isso é prevalente em áreas como a saúde, onde pacientes com características semelhantes podem ter resultados diferentes, tornando assim desafiadoras as previsões confiáveis. Para abordar isso, propomos o Data-IQ, uma estrutura para estratificar sistematicamente exemplos em subgrupos com relação aos seus resultados. Fazemos isso analisando o comportamento de exemplos individuais durante o treinamento, com base em sua confiança preditiva e, importante, na incerteza aleatória (dos dados). Capturar a incerteza aleatória permite uma caracterização fundamentada e, em seguida, a estratificação subsequente de exemplos de dados em três subgrupos distintos (Fácil, Ambíguo, Difícil). Demonstramos experimentalmente os benefícios do Data-IQ em quatro conjuntos de dados médicos do mundo real. Mostramos que a caracterização de exemplos pelo Data-IQ é mais robusta à variação entre modelos com desempenho semelhante (mas diferentes), em comparação com as linhas de base. Como o Data-IQ pode ser usado com qualquer modelo de ML (incluindo redes neurais, boosting de gradiente etc.), essa propriedade garante consistência na caracterização dos dados, enquanto permite uma seleção flexível de modelos. Levando isso um passo adiante, demonstramos que os subgrupos nos permitem construir novas abordagens tanto para aquisição de características quanto para seleção de conjuntos de dados. Além disso, destacamos como os subgrupos podem informar o uso confiável do modelo, observando o impacto significativo do subgrupo Ambíguo na generalização do modelo."
FH6LGZ8X,journalArticle,2020.0,"Ratner, Alexander; Bach, Stephen H.; Ehrenberg, Henry; Fries, Jason; Wu, Sen; Ré, Christopher",Snorkel: rapid training data creation with weak supervision,10.1007/s00778-019-00552-1,http://link.springer.com/10.1007/s00778-019-00552-1,"Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a ﬁrst-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the ﬁrst end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a ﬂexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research laboratories. In a user study, subject matter experts build models 2.8× faster and increase predictive performance an average 45.5% versus seven hours of hand labeling. We study the modeling trade-offs in this new setting and propose an optimizer for automating trade-off decisions that gives up to 1.8× speedup per pipeline execution. In two collaborations, with the US Department of Veterans Affairs and the US Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60% of the predictive performance of large hand-curated training sets.",2020-05,,Snorkel: criação rápida de dados de treinamento com supervisão fraca,"A rotulagem de dados de treinamento é cada vez mais o maior gargalo na implementação de sistemas de aprendizado de máquina. Apresentamos o Snorkel, um sistema pioneiro que permite aos usuários treinar modelos de ponta sem rotular manualmente nenhum dado de treinamento. Em vez disso, os usuários escrevem funções de rotulagem que expressam heurísticas arbitrárias, que podem ter precisões e correlações desconhecidas. O Snorkel remove o ruído de suas saídas sem acesso à verdade fundamental, incorporando a primeira implementação de ponta a ponta do nosso paradigma de aprendizado de máquina recentemente proposto, programação de dados. Apresentamos uma camada de interface flexível para escrever funções de rotulagem com base em nossa experiência ao longo do último ano colaborando com empresas, agências e laboratórios de pesquisa. Em um estudo com usuários, especialistas em assuntos construíram modelos 2,8 vezes mais rápido e aumentaram o desempenho preditivo em média 45,5% em comparação com sete horas de rotulagem manual. Estudamos os trade-offs de modelagem nesse novo cenário e propomos um otimizador para automatizar decisões de trade-off que proporciona até 1,8 vezes mais rapidez por execução de pipeline. Em duas colaborações, com o Departamento de Assuntos de Veteranos dos EUA e a Administração de Alimentos e Medicamentos dos EUA, e em quatro conjuntos de dados abertos de texto e imagem representativos de outras implementações, o Snorkel oferece melhorias médias de 132% no desempenho preditivo em relação a abordagens heurísticas anteriores e chega a uma média de 3,60% do desempenho preditivo de grandes conjuntos de treinamento cuidadosamente selecionados."
BJ5D97ZM,preprint,2022.0,"Thyagarajan, Aditya; Snorrason, Elías; Northcutt, Curtis; Mueller, Jonas",Identifying Incorrect Annotations in Multi-Label Classification Data,10.48550/arXiv.2211.13895,http://arxiv.org/abs/2211.13895,"In multi-label classification, each example in a dataset may be annotated as belonging to one or more classes (or none of the classes). Example applications include image (or document) tagging where each possible tag either applies to a particular image (or document) or not. With many possible classes to consider, data annotators are likely to make errors when labeling such data in practice. Here we consider algorithms for finding mislabeled examples in multi-label classification datasets. We propose an extension of the Confident Learning framework to this setting, as well as a label quality score that ranks examples with label errors much higher than those which are correctly labeled. Both approaches can utilize any trained classifier. After demonstrating that our methodology empirically outperforms other algorithms for label error detection, we apply our approach to discover many label errors in the CelebA image tagging dataset.",2022-11-25,arXiv,Identificando Anotações Incorretas em Dados de Classificação Multirrótulo,"Na classificação multi-rótulo, cada exemplo em um conjunto de dados pode ser anotado como pertencente a uma ou mais classes (ou nenhuma das classes). Exemplos de aplicações incluem a marcação de imagens (ou documentos), onde cada possível rótulo se aplica a uma imagem (ou documento) específico ou não. Com muitas classes possíveis a considerar, é provável que os anotadores de dados cometam erros ao rotular esses dados na prática. Aqui, consideramos algoritmos para encontrar exemplos rotulados incorretamente em conjuntos de dados de classificação multi-rótulo. Propomos uma extensão da estrutura de Aprendizado Confiante para esse contexto, bem como uma pontuação de qualidade de rótulo que classifica exemplos com erros de rótulo muito mais alto do que aqueles que estão corretamente rotulados. Ambas as abordagens podem utilizar qualquer classificador treinado. Após demonstrar que nossa metodologia supera empiricamente outros algoritmos para detecção de erros de rótulo, aplicamos nossa abordagem para descobrir muitos erros de rótulo no conjunto de dados de marcação de imagens CelebA."
R3NHATFK,conferencePaper,2022.0,"Zeng, Ziqian; Ni, Weimin; Fang, Tianqing; Li, Xiang; Zhao, Xinran; Song, Yangqiu",Weakly Supervised Text Classification using Supervision Signals from a Language Model,10.18653/v1/2022.findings-naacl.176,https://aclanthology.org/2022.findings-naacl.176,"Solving text classification in a weakly supervised manner is important for real-world applications where human annotations are scarce. In this paper, we propose to query a masked language model with cloze style prompts to obtain supervision signals. We design a prompt which combines the document itself and “this article is talking about [MASK].” A masked language model can generate words for the [MASK] token. The generated words which summarize the content of a document can be utilized as supervision signals. We propose a latent variable model to learn a word distribution learner which associates generated words to pre-defined categories and a document classifier simultaneously without using any annotated data. Evaluation on three datasets, AGNews, 20Newsgroups, and UCINews, shows that our method can outperform baselines by 2%, 4%, and 3%.",2022-07,Association for Computational Linguistics,Classificação de Texto Fracamente Supervisionada usando Sinais de Supervisão de um Modelo de Linguagem,"Resolver a classificação de texto de maneira fracamente supervisionada é importante para aplicações do mundo real onde as anotações humanas são escassas. Neste artigo, propomos consultar um modelo de linguagem mascarado com prompts no estilo cloze para obter sinais de supervisão. Projetamos um prompt que combina o próprio documento e ""este artigo está falando sobre [MASK]."" Um modelo de linguagem mascarado pode gerar palavras para o token [MASK]. As palavras geradas que resumem o conteúdo de um documento podem ser utilizadas como sinais de supervisão. Propomos um modelo de variável latente para aprender um aprendiz de distribuição de palavras que associa palavras geradas a categorias predefinidas e um classificador de documentos simultaneamente, sem usar dados anotados. A avaliação em três conjuntos de dados, AGNews, 20Newsgroups e UCINews, mostra que nosso método pode superar as linhas de base em 2%, 4% e 3%."
UR2KKBCV,preprint,2023.0,"Sedova, Anastasiia; Roth, Benjamin",ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision,10.48550/arXiv.2204.06863,http://arxiv.org/abs/2204.06863,"A cost-effective alternative to manual data labeling is weak supervision (WS), where data samples are automatically annotated using a predefined set of labeling functions (LFs), rule-based mechanisms that generate artificial labels for the associated classes. In this work, we investigate noise reduction techniques for WS based on the principle of k-fold cross-validation. We introduce a new algorithm ULF for Unsupervised Labeling Function correction, which denoises WS data by leveraging models trained on all but some LFs to identify and correct biases specific to the held-out LFs. Specifically, ULF refines the allocation of LFs to classes by re-estimating this assignment on highly reliable cross-validated samples. Evaluation on multiple datasets confirms ULF's effectiveness in enhancing WS learning without the need for manual labeling.",2023-10-24,arXiv,ULF: Correção de Função de Rotulagem Não Supervisionada usando Validação Cruzada para Supervisão Fraca,"Uma alternativa econômica à rotulagem manual de dados é a supervisão fraca (WS), onde amostras de dados são automaticamente anotadas usando um conjunto pré-definido de funções de rotulagem (LFs), mecanismos baseados em regras que geram rótulos artificiais para as classes associadas. Neste trabalho, investigamos técnicas de redução de ruído para WS com base no princípio da validação cruzada k-fold. Introduzimos um novo algoritmo ULF para correção de Funções de Rotulagem Não Supervisionadas, que remove o ruído dos dados de WS aproveitando modelos treinados em todas, exceto algumas LFs, para identificar e corrigir vieses específicos das LFs retidas. Especificamente, o ULF refina a alocação de LFs para classes reestimando essa atribuição em amostras altamente confiáveis validadas cruzadamente. A avaliação em múltiplos conjuntos de dados confirma a eficácia do ULF em aprimorar o aprendizado de WS sem a necessidade de rotulagem manual."
EUFIU6XB,book,2023.0,"Sedova, Anastasiia; Zellinger, Lena; Roth, Benjamin",Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal,,http://arxiv.org/abs/2306.04502,"An accurate and substantial dataset is essential for training a reliable and well-performing model. However, even manually annotated datasets contain label errors, not to mention automatically labeled ones. Previous methods for label denoising have primarily focused on detecting outliers and their permanent removal - a process that is likely to over- or underfilter the dataset. In this work, we propose AGRA: a new method for learning with noisy labels by using Adaptive GRAdient-based outlier removal. Instead of cleaning the dataset prior to model training, the dataset is dynamically adjusted during the training process. By comparing the aggregated gradient of a batch of samples and an individual example gradient, our method dynamically decides whether a corresponding example is helpful for the model at this point or is counter-productive and should be left out for the current update. Extensive evaluation on several datasets demonstrates AGRA's effectiveness, while a comprehensive results analysis supports our initial hypothesis: permanent hard outlier removal is not always what model benefits the most from.",2023,,Aprendizado com Rótulos Ruidosos por Remoção de Outliers Baseada em Gradiente Adaptativo,"Um conjunto de dados preciso e substancial é essencial para treinar um modelo confiável e de bom desempenho. No entanto, mesmo conjuntos de dados anotados manualmente contêm erros de rotulagem, sem mencionar os rotulados automaticamente. Métodos anteriores para remoção de ruído de rótulos focaram principalmente na detecção de outliers e sua remoção permanente - um processo que provavelmente super ou subfiltra o conjunto de dados. Neste trabalho, propomos o AGRA: um novo método para aprender com rótulos ruidosos usando remoção de outliers baseada em Gradiente Adaptativo. Em vez de limpar o conjunto de dados antes do treinamento do modelo, o conjunto de dados é ajustado dinamicamente durante o processo de treinamento. Ao comparar o gradiente agregado de um lote de amostras e o gradiente de um exemplo individual, nosso método decide dinamicamente se um exemplo correspondente é útil para o modelo neste ponto ou é contraproducente e deve ser excluído da atualização atual. Uma avaliação extensa em vários conjuntos de dados demonstra a eficácia do AGRA, enquanto uma análise abrangente dos resultados apoia nossa hipótese inicial: a remoção permanente de outliers difíceis nem sempre é o que mais beneficia o modelo."
Q3LYZWMP,conferencePaper,2019.0,"Awasthi, Abhijeet; Ghosh, Sabyasachi; Goyal, Rasna; Sarawagi, Sunita",Learning from Rules Generalizing Labeled Exemplars,,https://openreview.net/forum?id=SkeuexBtDr,"In many applications labeled data is not readily available, and needs to be collected via pain-staking human supervision. We propose a rule-exemplar method for collecting human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. We propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that (1) our algorithm is more accurate than several existing methods of learning from a mix of clean and noisy supervision, and (2) the coupled rule-exemplar supervision is effective in denoising rules.",2019-09-25,,Aprendendo com Regras Generalizando Exemplares Rotulados,"Em muitas aplicações, dados rotulados não estão prontamente disponíveis e precisam ser coletados por meio de uma supervisão humana meticulosa. Propomos um método de regra-exemplar para coletar supervisão humana que combina a eficiência das regras com a qualidade das etiquetas de instância. A supervisão é acoplada de forma que seja natural para os humanos e sinérgica para o aprendizado. Propomos um algoritmo de treinamento que desruída regras conjuntamente por meio de variáveis de cobertura latente e treina o modelo através de uma perda de implicação suave sobre as variáveis de cobertura e etiqueta. As regras desruídas e o modelo treinado são usados conjuntamente para inferência. A avaliação empírica em cinco tarefas diferentes mostra que (1) nosso algoritmo é mais preciso do que vários métodos existentes de aprendizado a partir de uma mistura de supervisão limpa e ruidosa, e (2) a supervisão acoplada de regra-exemplar é eficaz na desruído das regras."
56VSSQTV,preprint,2019.0,"Wang, Zihan; Shang, Jingbo; Liu, Liyuan; Lu, Lihao; Liu, Jiacheng; Han, Jiawei",CrossWeigh: Training Named Entity Tagger from Imperfect Annotations,10.48550/arXiv.1909.01441,http://arxiv.org/abs/1909.01441,"Everyone makes mistakes. So do human annotators when curating labels for named entity recognition (NER). Such label mistakes might hurt model training and interfere model comparison. In this study, we dive deep into one of the widely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identify label mistakes in about 5.38% test sentences, which is a significant ratio considering that the state-of-the-art test F1 score is already around 93%. Therefore, we manually correct these label mistakes and form a cleaner test set. Our re-evaluation of popular models on this corrected test set leads to more accurate assessments, compared to those on the original test set. More importantly, we propose a simple yet effective framework, CrossWeigh, to handle label mistakes during NER model training. Specifically, it partitions the training data into several folds and train independent NER models to identify potential mistakes in each fold. Then it adjusts the weights of training data accordingly to train the final NER model. Extensive experiments demonstrate significant improvements of plugging various NER models into our proposed framework on three datasets. All implementations and corrected test set are available at our Github repo: https://github.com/ZihanWangKi/CrossWeigh.",2019-09-03,arXiv,CrossWeigh: Treinamento de Etiquetador de Entidades Nomeadas a partir de Anotações Imperfeitas,"Todos cometem erros. Assim como os anotadores humanos ao curar rótulos para o reconhecimento de entidades nomeadas (NER). Esses erros de rótulo podem prejudicar o treinamento do modelo e interferir na comparação do modelo. Neste estudo, mergulhamos profundamente em um dos conjuntos de dados de referência de NER amplamente adotados, o CoNLL03 NER. Conseguimos identificar erros de rótulo em cerca de 5,38% das frases de teste, o que é uma proporção significativa considerando que a pontuação F1 de teste de última geração já está em torno de 93%. Portanto, corrigimos manualmente esses erros de rótulo e formamos um conjunto de teste mais limpo. Nossa reavaliação de modelos populares neste conjunto de teste corrigido leva a avaliações mais precisas, em comparação com aquelas no conjunto de teste original. Mais importante, propomos uma estrutura simples, mas eficaz, chamada CrossWeigh, para lidar com erros de rótulo durante o treinamento do modelo NER. Especificamente, ela particiona os dados de treinamento em vários grupos e treina modelos NER independentes para identificar possíveis erros em cada grupo. Em seguida, ajusta os pesos dos dados de treinamento de acordo para treinar o modelo NER final. Experimentos extensivos demonstram melhorias significativas ao integrar vários modelos NER em nossa estrutura proposta em três conjuntos de dados. Todas as implementações e o conjunto de teste corrigido estão disponíveis em nosso repositório do Github: https://github.com/ZihanWangKi/CrossWeigh."
2IB6NS2I,preprint,2021.0,"Cheng, Hao; Zhu, Zhaowei; Li, Xingyu; Gong, Yifei; Sun, Xing; Liu, Yang",Learning with Instance-Dependent Label Noise: A Sample Sieve Approach,10.48550/arXiv.2010.02347,http://arxiv.org/abs/2010.02347,"Human-annotated labels are often prone to noise, and the presence of such noise will degrade the performance of the resulting deep neural network (DNN) models. Much of the literature (with several recent exceptions) of learning with noisy labels focuses on the case when the label noise is independent of features. Practically, annotations errors tend to be instance-dependent and often depend on the difficulty levels of recognizing a certain task. Applying existing results from instance-independent settings would require a significant amount of estimation of noise rates. Therefore, providing theoretically rigorous solutions for learning with instance-dependent label noise remains a challenge. In this paper, we propose CORES$^{2}$ (COnfidence REgularized Sample Sieve), which progressively sieves out corrupted examples. The implementation of CORES$^{2}$ does not require specifying noise rates and yet we are able to provide theoretical guarantees of CORES$^{2}$ in filtering out the corrupted examples. This high-quality sample sieve allows us to treat clean examples and the corrupted ones separately in training a DNN solution, and such a separation is shown to be advantageous in the instance-dependent noise setting. We demonstrate the performance of CORES$^{2}$ on CIFAR10 and CIFAR100 datasets with synthetic instance-dependent label noise and Clothing1M with real-world human noise. As of independent interests, our sample sieve provides a generic machinery for anatomizing noisy datasets and provides a flexible interface for various robust training techniques to further improve the performance. Code is available at https://github.com/UCSC-REAL/cores.",2021-03-22,arXiv,Aprendizado com Ruído de Rótulo Dependente da Instância: Uma Abordagem de Peneira de Amostras,"Rótulos anotados por humanos são frequentemente suscetíveis a ruídos, e a presença de tais ruídos degradará o desempenho dos modelos resultantes de redes neurais profundas (DNN). Grande parte da literatura (com várias exceções recentes) sobre aprendizado com rótulos ruidosos foca no caso em que o ruído dos rótulos é independente das características. Praticamente, erros de anotação tendem a ser dependentes da instância e muitas vezes dependem dos níveis de dificuldade de reconhecer uma determinada tarefa. Aplicar resultados existentes de configurações independentes de instâncias exigiria uma quantidade significativa de estimativa das taxas de ruído. Portanto, fornecer soluções teoricamente rigorosas para aprendizado com ruído de rótulo dependente da instância continua sendo um desafio. Neste artigo, propomos o CORES$^{2}$ (COnfidence REgularized Sample Sieve), que progressivamente filtra exemplos corrompidos. A implementação do CORES$^{2}$ não requer a especificação das taxas de ruído e, ainda assim, conseguimos fornecer garantias teóricas do CORES$^{2}$ na filtragem dos exemplos corrompidos. Este filtro de amostras de alta qualidade nos permite tratar exemplos limpos e os corrompidos separadamente ao treinar uma solução DNN, e tal separação se mostra vantajosa no cenário de ruído dependente da instância. Demonstramos o desempenho do CORES$^{2}$ nos conjuntos de dados CIFAR10 e CIFAR100 com ruído de rótulo sintético dependente da instância e Clothing1M com ruído humano do mundo real. Como interesse independente, nosso filtro de amostras fornece uma maquinaria genérica para anatomizar conjuntos de dados ruidosos e oferece uma interface flexível para várias técnicas de treinamento robustas para melhorar ainda mais o desempenho. O código está disponível em https://github.com/UCSC-REAL/cores."
N9UICERA,preprint,2022.0,"Zhu, Zhaowei; Wang, Jialu; Liu, Yang",Beyond Images: Label Noise Transition Matrix Estimation for Tasks with Lower-Quality Features,10.48550/arXiv.2202.01273,http://arxiv.org/abs/2202.01273,"The label noise transition matrix, denoting the transition probabilities from clean labels to noisy labels, is crucial for designing statistically robust solutions. Existing estimators for noise transition matrices, e.g., using either anchor points or clusterability, focus on computer vision tasks that are relatively easier to obtain high-quality representations. We observe that tasks with lower-quality features fail to meet the anchor-point or clusterability condition, due to the coexistence of both uninformative and informative representations. To handle this issue, we propose a generic and practical information-theoretic approach to down-weight the less informative parts of the lower-quality features. This improvement is crucial to identifying and estimating the label noise transition matrix. The salient technical challenge is to compute the relevant information-theoretical metrics using only noisy labels instead of clean ones. We prove that the celebrated $f$-mutual information measure can often preserve the order when calculated using noisy labels. We then build our transition matrix estimator using this distilled version of features. The necessity and effectiveness of the proposed method are also demonstrated by evaluating the estimation error on a varied set of tabular data and text classification tasks with lower-quality features. Code is available at github.com/UCSC-REAL/BeyondImages.",2022-06-17,arXiv,Além das Imagens: Estimativa da Matriz de Transição de Ruído de Rótulo para Tarefas com Recursos de Baixa Qualidade,"A matriz de transição de ruído de rótulo, que denota as probabilidades de transição de rótulos limpos para rótulos ruidosos, é crucial para o design de soluções estatisticamente robustas. Estimadores existentes para matrizes de transição de ruído, por exemplo, usando pontos âncora ou clusterização, concentram-se em tarefas de visão computacional que são relativamente mais fáceis de obter representações de alta qualidade. Observamos que tarefas com características de menor qualidade não conseguem atender à condição de ponto âncora ou clusterização, devido à coexistência de representações não informativas e informativas. Para lidar com esse problema, propomos uma abordagem genérica e prática de teoria da informação para reduzir o peso das partes menos informativas das características de menor qualidade. Essa melhoria é crucial para identificar e estimar a matriz de transição de ruído de rótulo. O desafio técnico saliente é calcular as métricas relevantes da teoria da informação usando apenas rótulos ruidosos em vez de rótulos limpos. Provamos que a célebre medida de informação mútua $f$ pode muitas vezes preservar a ordem quando calculada usando rótulos ruidosos. Em seguida, construímos nosso estimador de matriz de transição usando essa versão destilada das características. A necessidade e a eficácia do método proposto também são demonstradas pela avaliação do erro de estimativa em um conjunto variado de dados tabulares e tarefas de classificação de texto com características de menor qualidade. O código está disponível em github.com/UCSC-REAL/BeyondImages."
JH4PNKBX,preprint,2022.0,"Liu, Yang; Cheng, Hao; Zhang, Kun",Identifiability of Label Noise Transition Matrix,10.48550/arXiv.2202.02016,http://arxiv.org/abs/2202.02016,"The noise transition matrix plays a central role in the problem of learning with noisy labels. Among many other reasons, a large number of existing solutions rely on access to it. Identifying and estimating the transition matrix without ground truth labels is a critical and challenging task. When label noise transition depends on each instance, the problem of identifying the instance-dependent noise transition matrix becomes substantially more challenging. Despite recent works proposing solutions for learning from instance-dependent noisy labels, the field lacks a unified understanding of when such a problem remains identifiable. The goal of this paper is to characterize the identifiability of the label noise transition matrix. Building on Kruskal's identifiability results, we are able to show the necessity of multiple noisy labels in identifying the noise transition matrix for the generic case at the instance level. We further instantiate the results to explain the successes of the state-of-the-art solutions and how additional assumptions alleviated the requirement of multiple noisy labels. Our result also reveals that disentangled features are helpful in the above identification task and we provide empirical evidence.",2022-07-04,arXiv,Identificabilidade da Matriz de Transição de Ruído de Rótulo,"A matriz de transição de ruído desempenha um papel central no problema de aprendizado com rótulos ruidosos. Entre muitas outras razões, um grande número de soluções existentes depende do acesso a ela. Identificar e estimar a matriz de transição sem rótulos de verdade de base é uma tarefa crítica e desafiadora. Quando a transição de ruído do rótulo depende de cada instância, o problema de identificar a matriz de transição de ruído dependente da instância se torna substancialmente mais desafiador. Apesar de trabalhos recentes proporem soluções para aprender com rótulos ruidosos dependentes da instância, o campo carece de uma compreensão unificada de quando tal problema permanece identificável. O objetivo deste artigo é caracterizar a identificabilidade da matriz de transição de ruído do rótulo. Baseando-se nos resultados de identificabilidade de Kruskal, conseguimos mostrar a necessidade de múltiplos rótulos ruidosos na identificação da matriz de transição de ruído para o caso genérico no nível da instância. Além disso, instanciamos os resultados para explicar os sucessos das soluções de ponta e como suposições adicionais aliviaram a exigência de múltiplos rótulos ruidosos. Nosso resultado também revela que características desencadeadas são úteis na tarefa de identificação acima e fornecemos evidências empíricas."
R2U8DTBJ,preprint,2021.0,"Zhu, Zhaowei; Song, Yiwen; Liu, Yang",Clusterability as an Alternative to Anchor Points When Learning with Noisy Labels,10.48550/arXiv.2102.05291,http://arxiv.org/abs/2102.05291,"The label noise transition matrix, characterizing the probabilities of a training instance being wrongly annotated, is crucial to designing popular solutions to learning with noisy labels. Existing works heavily rely on finding ""anchor points"" or their approximates, defined as instances belonging to a particular class almost surely. Nonetheless, finding anchor points remains a non-trivial task, and the estimation accuracy is also often throttled by the number of available anchor points. In this paper, we propose an alternative option to the above task. Our main contribution is the discovery of an efficient estimation procedure based on a clusterability condition. We prove that with clusterable representations of features, using up to third-order consensuses of noisy labels among neighbor representations is sufficient to estimate a unique transition matrix. Compared with methods using anchor points, our approach uses substantially more instances and benefits from a much better sample complexity. We demonstrate the estimation accuracy and advantages of our estimates using both synthetic noisy labels (on CIFAR-10/100) and real human-level noisy labels (on Clothing1M and our self-collected human-annotated CIFAR-10). Our code and human-level noisy CIFAR-10 labels are available at https://github.com/UCSC-REAL/HOC.",2021-07-13,arXiv,Clusterabilidade como uma Alternativa a Pontos de Ancoragem ao Aprender com Rótulos Ruins,"A matriz de transição de rótulos ruidosos, que caracteriza as probabilidades de uma instância de treinamento ser anotada incorretamente, é crucial para o desenvolvimento de soluções populares para aprendizado com rótulos ruidosos. Trabalhos existentes dependem fortemente da identificação de ""pontos âncora"" ou suas aproximações, definidos como instâncias que pertencem a uma classe particular quase com certeza. No entanto, encontrar pontos âncora continua sendo uma tarefa não trivial, e a precisão da estimativa também é frequentemente limitada pelo número de pontos âncora disponíveis. Neste artigo, propomos uma opção alternativa para a tarefa acima. Nossa principal contribuição é a descoberta de um procedimento de estimativa eficiente baseado em uma condição de agrupamento. Provamos que, com representações agrupáveis de características, usar consensos de rótulos ruidosos de até terceira ordem entre representações vizinhas é suficiente para estimar uma matriz de transição única. Comparado com métodos que usam pontos âncora, nossa abordagem utiliza substancialmente mais instâncias e se beneficia de uma complexidade de amostra muito melhor. Demonstramos a precisão da estimativa e as vantagens de nossas estimativas usando tanto rótulos ruidosos sintéticos (no CIFAR-10/100) quanto rótulos ruidosos reais em nível humano (no Clothing1M e em nosso CIFAR-10 anotado por humanos coletado por nós). Nosso código e rótulos ruidosos em nível humano do CIFAR-10 estão disponíveis em https://github.com/UCSC-REAL/HOC."
DEN9ZCH2,journalArticle,2015.0,"Stowell, Dan; Giannoulis, Dimitrios; Benetos, Emmanouil; Lagrange, Mathieu; Plumbley, Mark D.",Detection and Classification of Acoustic Scenes and Events,10.1109/TMM.2015.2428998,http://ieeexplore.ieee.org/document/7100934/,"While there is the saying of two heads are better than one, having multiple opinions brings the problem of finding a common ground. For data, multiple annotator opinions are usually aggregated into a single set of labels, regarded as the ground truth. With this ground truth, classification models can be trained in a supervised way to learn the annotated data categories. Finding a suitable aggregation for multiple annotator opinions is the topic of research in many domains. In this work we investigate the use of raw data obtained from multiple annotators with various levels of reliability, to train a model for audio classification. The model sees all the individual annotator opinions and learns the categories without the need of aggregating the information. The results show that using a fullyconnected layer that models individual annotators, it is possible to leverage the data distribution and learn to classify sounds without the need for aggregation of labels.",2015-10,,Detecção e Classificação de Cenários e Eventos Acústicos,"Embora exista o ditado de que duas cabeças pensam melhor do que uma, ter múltiplas opiniões traz o problema de encontrar um terreno comum. Para dados, as opiniões de múltiplos anotadores são geralmente agregadas em um único conjunto de rótulos, considerado como a verdade fundamental. Com essa verdade fundamental, modelos de classificação podem ser treinados de maneira supervisionada para aprender as categorias de dados anotados. Encontrar uma agregação adequada para as opiniões de múltiplos anotadores é um tema de pesquisa em muitos domínios. Neste trabalho, investigamos o uso de dados brutos obtidos de múltiplos anotadores com vários níveis de confiabilidade, para treinar um modelo para classificação de áudio. O modelo vê todas as opiniões individuais dos anotadores e aprende as categorias sem a necessidade de agregar as informações. Os resultados mostram que, usando uma camada totalmente conectada que modela os anotadores individuais, é possível aproveitar a distribuição dos dados e aprender a classificar sons sem a necessidade de agregação de rótulos."
5AKW8MED,conferencePaper,2023.0,"Zhang, Yunyi; Jiang, Minhao; Meng, Yu; Zhang, Yu; Han, Jiawei",PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training,,https://aclanthology.org/2023.emnlp-main.780,"Weakly-supervised text classification trains a classifier using the label name of each target class as the only supervision, which largely reduces human annotation efforts. Most existing methods first use the label names as static keyword-based features to generate pseudo labels, which are then used for final classifier training. While reasonable, such a commonly adopted framework suffers from two limitations: (1) keywords can have different meanings in different contexts and some text may not have any keyword, so keyword matching can induce noisy and inadequate pseudo labels; (2) the errors made in the pseudo label generation stage will directly propagate to the classifier training stage without a chance of being corrected. In this paper, we propose a new method, PIEClass, consisting of two modules: (1) a pseudo label acquisition module that uses zero-shot prompting of pre-trained language models (PLM) to get pseudo labels based on contextualized text understanding beyond static keyword matching, and (2) a noise-robust iterative ensemble training module that iteratively trains classifiers and updates pseudo labels by utilizing two PLM fine-tuning methods that regularize each other. Extensive experiments show that PIEClass achieves overall better performance than existing strong baselines on seven benchmark datasets and even achieves similar performance to fully-supervised classifiers on sentiment classification tasks.",2023-12,Association for Computational Linguistics,PIEClass: Classificação de Texto Fracamente Supervisionada com Prompting e Treinamento Iterativo de Conjunto Robusto ao Ruído,"A classificação de texto com supervisão fraca treina um classificador usando o nome do rótulo de cada classe alvo como a única supervisão, o que reduz amplamente os esforços de anotação humana. A maioria dos métodos existentes usa primeiro os nomes dos rótulos como características baseadas em palavras-chave estáticas para gerar rótulos pseudo, que são então usados para o treinamento final do classificador. Embora razoável, tal estrutura comumente adotada sofre de duas limitações: (1) palavras-chave podem ter significados diferentes em diferentes contextos e alguns textos podem não ter nenhuma palavra-chave, portanto, a correspondência de palavras-chave pode induzir rótulos pseudo ruidosos e inadequados; (2) os erros cometidos na fase de geração de rótulos pseudo se propagam diretamente para a fase de treinamento do classificador sem a chance de serem corrigidos. Neste artigo, propomos um novo método, PIEClass, que consiste em dois módulos: (1) um módulo de aquisição de rótulos pseudo que usa prompting zero-shot de modelos de linguagem pré-treinados (PLM) para obter rótulos pseudo com base na compreensão contextualizada do texto além da correspondência estática de palavras-chave, e (2) um módulo de treinamento em conjunto iterativo robusto ao ruído que treina iterativamente classificadores e atualiza rótulos pseudo utilizando dois métodos de ajuste fino de PLM que se regularizam mutuamente. Experimentos extensivos mostram que o PIEClass alcança um desempenho geral melhor do que as bases fortes existentes em sete conjuntos de dados de referência e até mesmo alcança desempenho semelhante ao de classificadores totalmente supervisionados em tarefas de classificação de sentimentos."
LPGR3F8P,journalArticle,,"Zhang, Mengtian; Jiang, Bo; Ling, Yuye; Wang, Xinbing",LEARNING WITH NON-UNIFORM LABEL NOISE: A CLUSTER-DEPENDENT WEAKLY SUPERVISED APPROACH,,,"Learning with noisy labels is a challenging task in machine learning. Furthermore in reality, label noise can be highly non-uniform in feature space, e.g. with higher error rate for more difficult samples. Some recent works consider instance-dependent label noise but they require additional information such as some cleanly labeled data and confidence scores, which are usually unavailable or costly to obtain. In this paper, we consider learning with non-uniform label noise that requires no such additional information. Inspired by stratified sampling, we propose a cluster-dependent sample selection algorithm followed by a contrastive training mechanism based on the cluster-dependent label noise. Despite its simplicity, the proposed method can distinguish clean data from the corrupt ones more precisely and achieve state-of-the-art performance on most image classification benchmarks, especially when the number of training samples is small and the noise rate is high. The code is released at https://github.com/MattZ-99/ClusterCL.",,,APRENDIZAGEM COM RUÍDO DE RÓTULO NÃO UNIFORME: UMA ABORDAGEM FRACA SUPERVISIONADA DEPENDENTE DE CLUSTERS,"Aprender com rótulos ruidosos é uma tarefa desafiadora em aprendizado de máquina. Além disso, na realidade, o ruído de rótulo pode ser altamente não uniforme no espaço de características, por exemplo, com uma taxa de erro maior para amostras mais difíceis. Alguns trabalhos recentes consideram o ruído de rótulo dependente da instância, mas eles exigem informações adicionais, como alguns dados rotulados de forma limpa e pontuações de confiança, que geralmente estão indisponíveis ou são caros de obter. Neste artigo, consideramos o aprendizado com ruído de rótulo não uniforme que não requer tais informações adicionais. Inspirados pela amostragem estratificada, propomos um algoritmo de seleção de amostras dependente de cluster seguido por um mecanismo de treinamento contrastivo baseado no ruído de rótulo dependente de cluster. Apesar de sua simplicidade, o método proposto pode distinguir dados limpos dos corrompidos de forma mais precisa e alcançar desempenho de ponta na maioria dos benchmarks de classificação de imagens, especialmente quando o número de amostras de treinamento é pequeno e a taxa de ruído é alta. O código está disponível em https://github.com/MattZ-99/ClusterCL."
GVJRTUDW,journalArticle,2024.0,"Ding, Jiaman; Zhang, Yihang; Jia, Lianyin; Fu, Xiaodong; Jiang, Ying",Noisy feature decomposition-based multi-label learning with missing labels,10.1016/j.ins.2024.120228,https://www.sciencedirect.com/science/article/pii/S0020025524001415,"In recent years, multi-label learning with missing labels (MLML) has become a popular topic. The major challenge for MLML is enhancing the performance of classifiers in the presence of missing labels. Most existing algorithms focus on recovering missing labels using label correlations. However, incomplete label correlations in the early stages of recovery may adversely affect the results. To address this problem, we focus on the original task of finding the mapping between labels and features and propose a Noisy Feature Decomposition-based Multi-label learning with Missing Labels (NFDMML) method. Specifically, the label information is assumed to be integral, and the features corresponding to missing labels are defined as noisy features. Not recovering the missing labels, we reduce the interference of noisy features in the classifications. Accordingly, the MLML problem is converted into a feature decomposition problem. Based on label correlation, a low-rank relationship is used to eliminate the features caused by missing labels, and reverse mapping is employed to preserve the features corresponding to the relevant labels. We conduct detailed experiments on multiple datasets, and the results clearly demonstrate that the proposed method achieves competitive performance over other algorithms.",2024-03-01,,Decomposição de características barulhentas baseada em aprendizado multi-rótulo com rótulos ausentes,"Nos últimos anos, o aprendizado multi-rótulo com rótulos ausentes (MLML) tornou-se um tópico popular. O principal desafio do MLML é melhorar o desempenho dos classificadores na presença de rótulos ausentes. A maioria dos algoritmos existentes se concentra em recuperar rótulos ausentes usando correlações de rótulos. No entanto, correlações de rótulos incompletas nas fases iniciais de recuperação podem afetar negativamente os resultados. Para resolver esse problema, focamos na tarefa original de encontrar o mapeamento entre rótulos e características e propomos um método de Aprendizado Multi-rótulo com Rótulos Ausentes baseado em Decomposição de Características Ruidosas (NFDMML). Especificamente, assume-se que a informação dos rótulos é integral, e as características correspondentes aos rótulos ausentes são definidas como características ruinosas. Ao não recuperar os rótulos ausentes, reduzimos a interferência das características ruinosas nas classificações. Assim, o problema do MLML é convertido em um problema de decomposição de características. Com base na correlação de rótulos, uma relação de baixa classificação é usada para eliminar as características causadas por rótulos ausentes, e o mapeamento reverso é empregado para preservar as características correspondentes aos rótulos relevantes. Realizamos experimentos detalhados em múltiplos conjuntos de dados, e os resultados demonstram claramente que o método proposto alcança um desempenho competitivo em relação a outros algoritmos."
XDZTC7WS,preprint,2023.0,"Chen, Jiuhai; Mueller, Jonas",Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness,10.48550/arXiv.2308.16175,http://arxiv.org/abs/2308.16175,"We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training data remains unknown. By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that cautions when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps. In applications involving automated evaluation with LLMs, accounting for our confidence scores leads to more reliable evaluation in both human-in-the-loop and fully-automated settings (across both GPT 3.5 and 4).",2023-10-04,arXiv,Quantificando a Incerteza nas Respostas de Qualquer Modelo de Linguagem e Aumentando sua Confiabilidade,"Apresentamos o BSDetector, um método para detectar respostas ruins e especulativas de um Modelo de Linguagem Grande pré-treinado, estimando uma pontuação de confiança numérica para qualquer saída que ele gerar. Nossa técnica de quantificação de incerteza funciona para qualquer LLM acessível apenas por meio de uma API de caixa-preta, cujos dados de treinamento permanecem desconhecidos. Ao despender um pouco de computação extra, os usuários de qualquer API de LLM agora podem obter a mesma resposta que obteriam normalmente, bem como uma estimativa de confiança que alerta quando não confiar nessa resposta. Experimentos em benchmarks de Pergunta-Resposta, tanto fechados quanto abertos, revelam que o BSDetector identifica com mais precisão respostas incorretas de LLM do que procedimentos alternativos de estimativa de incerteza (tanto para GPT-3 quanto para ChatGPT). Ao amostrar múltiplas respostas do LLM e considerar a que possui a maior pontuação de confiança, podemos adicionalmente obter respostas mais precisas do mesmo LLM, sem etapas de treinamento extras. Em aplicações que envolvem avaliação automatizada com LLMs, levar em conta nossas pontuações de confiança resulta em uma avaliação mais confiável em configurações tanto com humanos no loop quanto totalmente automatizadas (em ambos os GPT 3.5 e 4)."
